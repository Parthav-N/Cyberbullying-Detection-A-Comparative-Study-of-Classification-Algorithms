{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1ncdCfgcWnUrpdULEqhgffb6M-4uHpwb-","authorship_tag":"ABX9TyMrThu+75kAByyVmAtfDFcs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"a2105973ac474a2a8575b70a0de1356d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_940e6a02cab045c6990436b7d48384c0","IPY_MODEL_0e559d690bb64af39a4e9888b846f39d","IPY_MODEL_9b49e4ec5d53474f9adcf380fa84c0cd"],"layout":"IPY_MODEL_e2dfc91e87f942648aec26ad13a6fc8a"}},"940e6a02cab045c6990436b7d48384c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f70b73b4f78b41c7b2570fe7e84f7728","placeholder":"​","style":"IPY_MODEL_50024503941445029b5db57a4940a76e","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"0e559d690bb64af39a4e9888b846f39d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b4b6881667842298cb953180c284357","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0e42369cfeaa42a0ae0ff5ddb197ed2c","value":231508}},"9b49e4ec5d53474f9adcf380fa84c0cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a608f1d8343a40b1a1b28188e701705a","placeholder":"​","style":"IPY_MODEL_f79930077db54d349e780c046c9d63a8","value":" 232k/232k [00:00&lt;00:00, 1.41MB/s]"}},"e2dfc91e87f942648aec26ad13a6fc8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f70b73b4f78b41c7b2570fe7e84f7728":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50024503941445029b5db57a4940a76e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b4b6881667842298cb953180c284357":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e42369cfeaa42a0ae0ff5ddb197ed2c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a608f1d8343a40b1a1b28188e701705a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f79930077db54d349e780c046c9d63a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c460b7ce7fb4110b5969ca5c52810d2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ae9734e19cef4cec8c0e8d7cce90592c","IPY_MODEL_aabcfb6dd80b43d6a6b930bfb7b8913e","IPY_MODEL_d6c9db141f7047f58e5081ae1196538c"],"layout":"IPY_MODEL_1d629fd3afe445468475bb86449660b0"}},"ae9734e19cef4cec8c0e8d7cce90592c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a5de65b77334ff89d739f477ca06248","placeholder":"​","style":"IPY_MODEL_6f4b327ce31b48d18d46a21f2264fbc5","value":"Downloading (…)okenizer_config.json: 100%"}},"aabcfb6dd80b43d6a6b930bfb7b8913e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_af3033c55c7c4f57b7d27282a60635cd","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ef7c6c44d34f43e1a3251a3e6c01c1ce","value":28}},"d6c9db141f7047f58e5081ae1196538c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8af0a7bf95144fcaad54159cb7c00235","placeholder":"​","style":"IPY_MODEL_d2f56efb0c644c39ab5615848c0b3667","value":" 28.0/28.0 [00:00&lt;00:00, 2.08kB/s]"}},"1d629fd3afe445468475bb86449660b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a5de65b77334ff89d739f477ca06248":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f4b327ce31b48d18d46a21f2264fbc5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af3033c55c7c4f57b7d27282a60635cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef7c6c44d34f43e1a3251a3e6c01c1ce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8af0a7bf95144fcaad54159cb7c00235":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2f56efb0c644c39ab5615848c0b3667":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98a805fcdae04837aae4e36d0604962c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3dc570e817db4b5b82c3aaac23c831e8","IPY_MODEL_b22d302261d34b4ebde1c0d635dacd72","IPY_MODEL_42667c286e6f4b19baf104c541dea2bc"],"layout":"IPY_MODEL_6c239cf46dcc4ff8ab1d16574418e771"}},"3dc570e817db4b5b82c3aaac23c831e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1388081f0c74afc9fe7dbeae80dd631","placeholder":"​","style":"IPY_MODEL_854ca46a7955423e9ac5652a710d3468","value":"Downloading (…)lve/main/config.json: 100%"}},"b22d302261d34b4ebde1c0d635dacd72":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e7c8409e6744c619e08fc934902f588","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a77aeb658fc942038495e668cdfa52be","value":570}},"42667c286e6f4b19baf104c541dea2bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43684f7cdf894b65bf449555611a4ec6","placeholder":"​","style":"IPY_MODEL_141f5409866e4708a43a1f35e833b87f","value":" 570/570 [00:00&lt;00:00, 28.9kB/s]"}},"6c239cf46dcc4ff8ab1d16574418e771":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1388081f0c74afc9fe7dbeae80dd631":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"854ca46a7955423e9ac5652a710d3468":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e7c8409e6744c619e08fc934902f588":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a77aeb658fc942038495e668cdfa52be":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"43684f7cdf894b65bf449555611a4ec6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"141f5409866e4708a43a1f35e833b87f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae30eb1c358d418f8e71146c19ac3320":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_64932557b5d444fba1df58ec8c8ccd71","IPY_MODEL_e968d3a1c10b4ad7942a555eb385f207","IPY_MODEL_54fe3f8c47084313b616ae3efbea69ba"],"layout":"IPY_MODEL_9c23277ce0db4a12a1dd1a11e4f2d426"}},"64932557b5d444fba1df58ec8c8ccd71":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9aab8a739b64eb5b688fa60d6e230f8","placeholder":"​","style":"IPY_MODEL_9d70a4a76032469da816f7bdb2bdd9fc","value":"Downloading tf_model.h5: 100%"}},"e968d3a1c10b4ad7942a555eb385f207":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc3ce726a4934099928abcd7cbadb345","max":536063208,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f22c08ac5e9d415aa7cc83d0402645bb","value":536063208}},"54fe3f8c47084313b616ae3efbea69ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_11589c81d22746478a47e05a71353bc7","placeholder":"​","style":"IPY_MODEL_04dfa0ec049d485e960411fb0917dc5d","value":" 536M/536M [00:02&lt;00:00, 265MB/s]"}},"9c23277ce0db4a12a1dd1a11e4f2d426":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9aab8a739b64eb5b688fa60d6e230f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d70a4a76032469da816f7bdb2bdd9fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc3ce726a4934099928abcd7cbadb345":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f22c08ac5e9d415aa7cc83d0402645bb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"11589c81d22746478a47e05a71353bc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04dfa0ec049d485e960411fb0917dc5d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aWinV6t343Kq","executionInfo":{"status":"ok","timestamp":1683443860470,"user_tz":-330,"elapsed":4173,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"b8e8656b-f2fe-4104-b595-4fcb83c3a610"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.2)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.54.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.3.3)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n","Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n","Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.8)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n","Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n","Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"]}],"source":["!pip install tensorflow"]},{"cell_type":"code","source":["!pip install keras"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q-by70ae4-A4","executionInfo":{"status":"ok","timestamp":1681377505671,"user_tz":-330,"elapsed":6017,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"16af096d-8803-407c-bc1a-bfc49d42c26e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: keras in /usr/local/lib/python3.9/dist-packages (2.12.0)\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iyKqzRtS6JXj","executionInfo":{"status":"ok","timestamp":1683541949712,"user_tz":-330,"elapsed":24245,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"4d5513f1-14e9-4a13-d395-adc010e60ad7"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I_SZWo-S6izf","executionInfo":{"status":"ok","timestamp":1681582534462,"user_tz":-330,"elapsed":10,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"9d82681d-a53d-47fe-ccfd-5468a7863cc4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/Minor Project(NLP)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u7GBP1We6lGL","executionInfo":{"status":"ok","timestamp":1681582549219,"user_tz":-330,"elapsed":348,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"4895abe5-dcfd-4ca0-d29e-39ebf5efb5e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Minor Project(NLP)\n"]}]},{"cell_type":"code","source":["from keras.datasets import imdb\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.layers.convolutional import Conv1D\n","from keras.layers.convolutional import MaxPooling1D\n","from keras.layers import Embedding\n","from keras.preprocessing import sequence"],"metadata":{"id":"X_xbKH6A4_eH","executionInfo":{"status":"ok","timestamp":1683542088596,"user_tz":-330,"elapsed":3213,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"XatQ0WBV5Sby","executionInfo":{"status":"ok","timestamp":1683542089108,"user_tz":-330,"elapsed":518,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["data = pd.read_csv('./cyberbullying_tweets.csv',encoding = 'ISO-8859-1')"],"metadata":{"id":"YejrL4AO5ver"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(data.head(2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AyhPKf4K7Fbs","executionInfo":{"status":"ok","timestamp":1681471326424,"user_tz":-330,"elapsed":6,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"d98a8339-9854-4b98-9409-60e1a51b46dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                          tweet_text cyberbullying_type\n","0  In other words #katandandre, your food was cra...  not_cyberbullying\n","1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying\n"]}]},{"cell_type":"code","source":["data['cyberbullying_type'].unique() "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Li8lQbj7HpU","executionInfo":{"status":"ok","timestamp":1681471326424,"user_tz":-330,"elapsed":6,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"b10803ba-ff92-4092-b006-7a9c39a2caa4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['not_cyberbullying', 'gender', 'religion', 'other_cyberbullying',\n","       'age', 'ethnicity'], dtype=object)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["data['cyberbullying_type'] = data['cyberbullying_type'].replace({'not_cyberbullying':0,'gender':1,'religion':1,'age':1,'ethnicity':1,'other_cyberbullying':1})\n","print(data['cyberbullying_type'].unique())\n","X = data['tweet_text'].values\n","Y = data['cyberbullying_type'].values\n","print(Y[:2])\n","print(data.head(2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cTBMGpudChxz","executionInfo":{"status":"ok","timestamp":1681451720581,"user_tz":-330,"elapsed":16,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"3a9f9558-ef3f-46bd-c508-ab1e99e2fc39"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1]\n","[0 0]\n","                                          tweet_text  cyberbullying_type\n","0  In other words #katandandre, your food was cra...                   0\n","1  Why is #aussietv so white? #MKR #theblock #ImA...                   0\n"]}]},{"cell_type":"code","source":["import nltk\n","import re\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer\n","nltk.download(\"stopwords\")\n","ps = PorterStemmer()\n","corpus = []\n","for i in range(len(X)):\n","  print(i)\n","  news = re.sub('[^a-zA-Z]', ' ', X[i])\n","  news = news.lower()\n","  news = news.split()\n","  news = [ps.stem(word) for word in news if word not in stopwords.words('english')]\n","  news = ' '.join(news)\n","  corpus.append(news)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"id":"IA_Rj6gUBkyd","executionInfo":{"status":"error","timestamp":1681473246172,"user_tz":-330,"elapsed":927,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"6116b2ef-3b67-4903-fc5d-9edcca066663"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-82294fd04ced>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mnews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[^a-zA-Z]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"]}]},{"cell_type":"code","source":["print(X[0],'\\n',corpus[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h38uNLftFOnX","executionInfo":{"status":"ok","timestamp":1681451884103,"user_tz":-330,"elapsed":11,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"5334b498-96a0-442f-8981-625fa9c70da4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["In other words #katandandre, your food was crapilicious! #mkr \n"," word katandandr food crapilici mkr\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split"],"metadata":{"id":"tootVKvvGfou"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Xtrain,Xtest,Ytrain,Ytest = train_test_split(corpus,Y,test_size = 0.25,random_state=99)\n","print(Xtrain[:2])\n","print(Xtest[:2])\n","print(Ytrain[:2])\n","print(Ytest[:2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dyJLo_9AFXef","executionInfo":{"status":"ok","timestamp":1681451884104,"user_tz":-330,"elapsed":9,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"9d3a1ce6-ea07-4887-c682-51ac2fa7b6f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['rt fruitondabottom idontneedfemin hate manipul feminist entertain womenagainstfemin letstalkmen h', 'bulli school self explanatori']\n","['archibaldcran lostsailorni fuck insult mlk wow', 'went high school major black white hispan surpris news racist white cop slam hispan girl ground gay guy school got bulli white kid lacross team']\n","[1 1]\n","[1 1]\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n","from tensorflow.keras.models import Sequential"],"metadata":{"id":"Aa-OKNs1IOdt","executionInfo":{"status":"ok","timestamp":1683542090555,"user_tz":-330,"elapsed":5,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["tokenizer = Tokenizer(num_words=5000, lower=True)\n","tokenizer.fit_on_texts(Xtrain)\n","train_sequences = tokenizer.texts_to_sequences(Xtrain)\n","test_sequences = tokenizer.texts_to_sequences(Xtest)"],"metadata":{"id":"jfYdjk8kMDas"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_len = 100\n","train_sequences = pad_sequences(train_sequences, maxlen=max_len)\n","test_sequences = pad_sequences(test_sequences, maxlen=max_len)"],"metadata":{"id":"eFA_94KGMWZv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","model.add(Embedding(input_dim=5000, output_dim=32, input_length=max_len))\n","model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(8,activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(1, activation='sigmoid'))"],"metadata":{"id":"TeGTq3tnMXC3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"],"metadata":{"id":"7kou9CqvNJPD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.fit(train_sequences, Ytrain, epochs=100, batch_size=512)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JOWGYzGLNYcJ","executionInfo":{"status":"ok","timestamp":1681452683591,"user_tz":-330,"elapsed":71042,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"c753fd82-8f01-4154-e2aa-653beaff0bd9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0806 - accuracy: 0.9516\n","Epoch 2/100\n","70/70 [==============================] - 2s 22ms/step - loss: 0.0797 - accuracy: 0.9513\n","Epoch 3/100\n","70/70 [==============================] - 1s 8ms/step - loss: 0.0788 - accuracy: 0.9517\n","Epoch 4/100\n","70/70 [==============================] - 1s 14ms/step - loss: 0.0785 - accuracy: 0.9519\n","Epoch 5/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0777 - accuracy: 0.9525\n","Epoch 6/100\n","70/70 [==============================] - 1s 14ms/step - loss: 0.0776 - accuracy: 0.9517\n","Epoch 7/100\n","70/70 [==============================] - 1s 12ms/step - loss: 0.0776 - accuracy: 0.9524\n","Epoch 8/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0764 - accuracy: 0.9533\n","Epoch 9/100\n","70/70 [==============================] - 1s 14ms/step - loss: 0.0757 - accuracy: 0.9545\n","Epoch 10/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0767 - accuracy: 0.9523\n","Epoch 11/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0761 - accuracy: 0.9533\n","Epoch 12/100\n","70/70 [==============================] - 1s 14ms/step - loss: 0.0757 - accuracy: 0.9531\n","Epoch 13/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0752 - accuracy: 0.9529\n","Epoch 14/100\n","70/70 [==============================] - 1s 12ms/step - loss: 0.0765 - accuracy: 0.9532\n","Epoch 15/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0776 - accuracy: 0.9519\n","Epoch 16/100\n","70/70 [==============================] - 1s 11ms/step - loss: 0.0773 - accuracy: 0.9533\n","Epoch 17/100\n","70/70 [==============================] - 1s 13ms/step - loss: 0.0783 - accuracy: 0.9532\n","Epoch 18/100\n","70/70 [==============================] - 1s 12ms/step - loss: 0.0759 - accuracy: 0.9535\n","Epoch 19/100\n","70/70 [==============================] - 1s 17ms/step - loss: 0.0771 - accuracy: 0.9525\n","Epoch 20/100\n","70/70 [==============================] - 1s 13ms/step - loss: 0.0754 - accuracy: 0.9535\n","Epoch 21/100\n","70/70 [==============================] - 1s 12ms/step - loss: 0.0762 - accuracy: 0.9533\n","Epoch 22/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0766 - accuracy: 0.9520\n","Epoch 23/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0746 - accuracy: 0.9535\n","Epoch 24/100\n","70/70 [==============================] - 1s 11ms/step - loss: 0.0756 - accuracy: 0.9533\n","Epoch 25/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0754 - accuracy: 0.9535\n","Epoch 26/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0773 - accuracy: 0.9523\n","Epoch 27/100\n","70/70 [==============================] - 1s 11ms/step - loss: 0.0756 - accuracy: 0.9531\n","Epoch 28/100\n","70/70 [==============================] - 0s 6ms/step - loss: 0.0744 - accuracy: 0.9536\n","Epoch 29/100\n","70/70 [==============================] - 1s 12ms/step - loss: 0.0751 - accuracy: 0.9540\n","Epoch 30/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0735 - accuracy: 0.9534\n","Epoch 31/100\n","70/70 [==============================] - 0s 6ms/step - loss: 0.0731 - accuracy: 0.9529\n","Epoch 32/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0739 - accuracy: 0.9523\n","Epoch 33/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0753 - accuracy: 0.9531\n","Epoch 34/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0735 - accuracy: 0.9533\n","Epoch 35/100\n","70/70 [==============================] - 1s 12ms/step - loss: 0.0751 - accuracy: 0.9524\n","Epoch 36/100\n","70/70 [==============================] - 1s 8ms/step - loss: 0.0736 - accuracy: 0.9532\n","Epoch 37/100\n","70/70 [==============================] - 1s 19ms/step - loss: 0.0735 - accuracy: 0.9539\n","Epoch 38/100\n","70/70 [==============================] - 1s 14ms/step - loss: 0.0732 - accuracy: 0.9539\n","Epoch 39/100\n","70/70 [==============================] - 2s 25ms/step - loss: 0.0746 - accuracy: 0.9534\n","Epoch 40/100\n","70/70 [==============================] - 1s 18ms/step - loss: 0.0735 - accuracy: 0.9540\n","Epoch 41/100\n","70/70 [==============================] - 1s 11ms/step - loss: 0.0767 - accuracy: 0.9516\n","Epoch 42/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0766 - accuracy: 0.9523\n","Epoch 43/100\n","70/70 [==============================] - 0s 6ms/step - loss: 0.0729 - accuracy: 0.9534\n","Epoch 44/100\n","70/70 [==============================] - 0s 6ms/step - loss: 0.0762 - accuracy: 0.9526\n","Epoch 45/100\n","70/70 [==============================] - 1s 11ms/step - loss: 0.0757 - accuracy: 0.9532\n","Epoch 46/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0744 - accuracy: 0.9531\n","Epoch 47/100\n","70/70 [==============================] - 0s 6ms/step - loss: 0.0749 - accuracy: 0.9527\n","Epoch 48/100\n","70/70 [==============================] - 0s 7ms/step - loss: 0.0748 - accuracy: 0.9532\n","Epoch 49/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0762 - accuracy: 0.9534\n","Epoch 50/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0735 - accuracy: 0.9536\n","Epoch 51/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0722 - accuracy: 0.9537\n","Epoch 52/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0738 - accuracy: 0.9532\n","Epoch 53/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0755 - accuracy: 0.9525\n","Epoch 54/100\n","70/70 [==============================] - 0s 7ms/step - loss: 0.0754 - accuracy: 0.9520\n","Epoch 55/100\n","70/70 [==============================] - 0s 6ms/step - loss: 0.0732 - accuracy: 0.9538\n","Epoch 56/100\n","70/70 [==============================] - 1s 12ms/step - loss: 0.0728 - accuracy: 0.9538\n","Epoch 57/100\n","70/70 [==============================] - 1s 13ms/step - loss: 0.0735 - accuracy: 0.9526\n","Epoch 58/100\n","70/70 [==============================] - 1s 13ms/step - loss: 0.0765 - accuracy: 0.9528\n","Epoch 59/100\n","70/70 [==============================] - 1s 13ms/step - loss: 0.0760 - accuracy: 0.9536\n","Epoch 60/100\n","70/70 [==============================] - 1s 8ms/step - loss: 0.0723 - accuracy: 0.9538\n","Epoch 61/100\n","70/70 [==============================] - 0s 6ms/step - loss: 0.0737 - accuracy: 0.9543\n","Epoch 62/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0736 - accuracy: 0.9526\n","Epoch 63/100\n","70/70 [==============================] - 0s 6ms/step - loss: 0.0726 - accuracy: 0.9533\n","Epoch 64/100\n","70/70 [==============================] - 0s 6ms/step - loss: 0.0724 - accuracy: 0.9533\n","Epoch 65/100\n","70/70 [==============================] - 0s 6ms/step - loss: 0.0728 - accuracy: 0.9537\n","Epoch 66/100\n","70/70 [==============================] - 0s 7ms/step - loss: 0.0753 - accuracy: 0.9517\n","Epoch 67/100\n","70/70 [==============================] - 1s 14ms/step - loss: 0.0732 - accuracy: 0.9536\n","Epoch 68/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0735 - accuracy: 0.9529\n","Epoch 69/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0721 - accuracy: 0.9536\n","Epoch 70/100\n","70/70 [==============================] - 0s 6ms/step - loss: 0.0727 - accuracy: 0.9533\n","Epoch 71/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0728 - accuracy: 0.9549\n","Epoch 72/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0738 - accuracy: 0.9545\n","Epoch 73/100\n","70/70 [==============================] - 0s 6ms/step - loss: 0.0739 - accuracy: 0.9531\n","Epoch 74/100\n","70/70 [==============================] - 0s 6ms/step - loss: 0.0750 - accuracy: 0.9525\n","Epoch 75/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0744 - accuracy: 0.9533\n","Epoch 76/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0746 - accuracy: 0.9539\n","Epoch 77/100\n","70/70 [==============================] - 0s 6ms/step - loss: 0.0737 - accuracy: 0.9536\n","Epoch 78/100\n","70/70 [==============================] - 0s 6ms/step - loss: 0.0725 - accuracy: 0.9533\n","Epoch 79/100\n","70/70 [==============================] - 1s 10ms/step - loss: 0.0757 - accuracy: 0.9516\n","Epoch 80/100\n","70/70 [==============================] - 1s 21ms/step - loss: 0.0735 - accuracy: 0.9540\n","Epoch 81/100\n","70/70 [==============================] - 1s 17ms/step - loss: 0.0721 - accuracy: 0.9548\n","Epoch 82/100\n","70/70 [==============================] - 1s 12ms/step - loss: 0.0719 - accuracy: 0.9543\n","Epoch 83/100\n","70/70 [==============================] - 1s 8ms/step - loss: 0.0742 - accuracy: 0.9528\n","Epoch 84/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0734 - accuracy: 0.9535\n","Epoch 85/100\n","70/70 [==============================] - 0s 6ms/step - loss: 0.0725 - accuracy: 0.9537\n","Epoch 86/100\n","70/70 [==============================] - 1s 12ms/step - loss: 0.0737 - accuracy: 0.9536\n","Epoch 87/100\n","70/70 [==============================] - 1s 12ms/step - loss: 0.0720 - accuracy: 0.9542\n","Epoch 88/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0725 - accuracy: 0.9542\n","Epoch 89/100\n","70/70 [==============================] - 0s 6ms/step - loss: 0.0725 - accuracy: 0.9536\n","Epoch 90/100\n","70/70 [==============================] - 0s 6ms/step - loss: 0.0722 - accuracy: 0.9547\n","Epoch 91/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0720 - accuracy: 0.9535\n","Epoch 92/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0761 - accuracy: 0.9527\n","Epoch 93/100\n","70/70 [==============================] - 0s 6ms/step - loss: 0.0727 - accuracy: 0.9546\n","Epoch 94/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0718 - accuracy: 0.9539\n","Epoch 95/100\n","70/70 [==============================] - 0s 6ms/step - loss: 0.0723 - accuracy: 0.9540\n","Epoch 96/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0722 - accuracy: 0.9526\n","Epoch 97/100\n","70/70 [==============================] - 1s 9ms/step - loss: 0.0728 - accuracy: 0.9535\n","Epoch 98/100\n","70/70 [==============================] - 1s 12ms/step - loss: 0.0718 - accuracy: 0.9549\n","Epoch 99/100\n","70/70 [==============================] - 1s 7ms/step - loss: 0.0726 - accuracy: 0.9542\n","Epoch 100/100\n","70/70 [==============================] - 1s 13ms/step - loss: 0.0728 - accuracy: 0.9534\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f1285f14190>"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["# Evaluate the  (binary classification)\n","test_loss, test_acc = model.evaluate(test_sequences, Ytest, verbose=2)\n","print('Test accuracy:', test_acc)"],"metadata":{"id":"5NZMYYnFOyVc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681452694025,"user_tz":-330,"elapsed":1732,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"03fd7515-f49a-4ced-e6bc-b0d7b1b70900"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["373/373 - 1s - loss: 2.9543 - accuracy: 0.8401 - 709ms/epoch - 2ms/step\n","Test accuracy: 0.8401408791542053\n"]}]},{"cell_type":"code","source":["#10 epochs ----- train acc = 93; test acc = 82.9\n","#20 epochs ----- train acc = 95; test acc = 83.6\n","#100 epochs ---- train acc = 95.3 ; test acc = 84"],"metadata":{"id":"n-Uh33hWXoMz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#CNN model for multiclass classification\n","multidata = pd.read_csv('./cyberbullying_tweets.csv',encoding='ISO-8859-1')\n","multidata.head(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"id":"xl_qaJtc0dwR","executionInfo":{"status":"ok","timestamp":1681476214776,"user_tz":-330,"elapsed":573,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"d85ae42e-b202-4e5a-965e-3f289d60659f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                          tweet_text cyberbullying_type\n","0  In other words #katandandre, your food was cra...  not_cyberbullying\n","1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying"],"text/html":["\n","  <div id=\"df-3ea39b72-9cbf-4633-9ebf-482ed1990c0b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet_text</th>\n","      <th>cyberbullying_type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>In other words #katandandre, your food was cra...</td>\n","      <td>not_cyberbullying</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n","      <td>not_cyberbullying</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ea39b72-9cbf-4633-9ebf-482ed1990c0b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3ea39b72-9cbf-4633-9ebf-482ed1990c0b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3ea39b72-9cbf-4633-9ebf-482ed1990c0b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":101}]},{"cell_type":"code","source":["import nltk\n","import re\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer\n","nltk.download(\"stopwords\")\n","def gen_corpus(X):\n","  ps = PorterStemmer()\n","  corpus = []\n","  for i in range(len(X)):\n","    print(i)\n","    news = re.sub('[^a-zA-Z]', ' ', X[i])\n","    news = news.lower()\n","    news = news.split()\n","    news = [ps.stem(word) for word in news if word not in stopwords.words('english')]\n","    news = ' '.join(news)\n","    corpus.append(news)\n","  return corpus"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C3E01h7X1UvD","executionInfo":{"status":"ok","timestamp":1681473288919,"user_tz":-330,"elapsed":4,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"00896a94-0aac-4ca3-b993-ce651dbb6155"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"code","source":["multiX = multidata['tweet_text'].values\n","multidata['cyberbullying_type'] = multidata['cyberbullying_type'].replace({'not_cyberbullying':0,'gender':1,'religion':2,'age':3,'ethnicity':4,'other_cyberbullying':5})\n","multidata[:2]\n","mcorpus = gen_corpus(multiX)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"id":"_abc6lY72ZmH","executionInfo":{"status":"ok","timestamp":1681476220814,"user_tz":-330,"elapsed":3,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"2e066eb6-3932-43ae-e300-dda0cb1dbdd5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                          tweet_text  cyberbullying_type\n","0  In other words #katandandre, your food was cra...                   0\n","1  Why is #aussietv so white? #MKR #theblock #ImA...                   0"],"text/html":["\n","  <div id=\"df-fc197a81-150f-490c-8991-093c45f846d4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet_text</th>\n","      <th>cyberbullying_type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>In other words #katandandre, your food was cra...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc197a81-150f-490c-8991-093c45f846d4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fc197a81-150f-490c-8991-093c45f846d4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fc197a81-150f-490c-8991-093c45f846d4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":102}]},{"cell_type":"code","source":["multiXtrain,multiXtest,multiYtrain,multiYtest = train_test_split(mcorpus,multidata['cyberbullying_type'],test_size=0.2,random_state=42)\n","\n","print(multiYtrain[2])\n","\n","tokenizer = Tokenizer(num_words=5000, lower=True)\n","tokenizer.fit_on_texts(multiXtrain)\n","train_sequences_multi = tokenizer.texts_to_sequences(multiXtrain)\n","test_sequences_multi = tokenizer.texts_to_sequences(multiXtest)"],"metadata":{"id":"-m5P5QMw4Xyc","executionInfo":{"status":"ok","timestamp":1681476638978,"user_tz":-330,"elapsed":614,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c1f6a2b6-3460-4fda-8677-21b9c907a403"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n"]}]},{"cell_type":"code","source":["max_len = 100\n","train_sequences_multi = pad_sequences(train_sequences_multi, maxlen=max_len)\n","test_sequences_multi = pad_sequences(test_sequences_multi, maxlen=max_len)"],"metadata":{"id":"xWxYerQO4sOj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","model.add(Embedding(input_dim=5000, output_dim=32, input_length=max_len))\n","model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(3,activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(6, activation='softmax'))"],"metadata":{"id":"fAAdbGUw42N6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","print(multiXtrain[:2])\n","print(multiYtrain[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AxH38QIF4-0u","executionInfo":{"status":"ok","timestamp":1681476668096,"user_tz":-330,"elapsed":3,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"858919ae-4216-4085-9f94-0b80fc73364e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['rt avatast freebsdgirl also anyon never written x c java lt insert languag assign alway ret', 'questionni di joke gay rape babe rape']\n","0\n"]}]},{"cell_type":"code","source":["# Convert labels to one-hot encoded format\n","train_labels = tf.keras.utils.to_categorical(multiYtrain, num_classes=6)\n","test_labels = tf.keras.utils.to_categorical(multiYtest, num_classes=6)"],"metadata":{"id":"BUYELlB24kCV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.fit(train_sequences_multi, train_labels, epochs=10, batch_size=32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZFQ4HVtHy8TZ","executionInfo":{"status":"ok","timestamp":1681476818237,"user_tz":-330,"elapsed":142967,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"65fd4543-2872-4294-d194-aacb28f38c09"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","1193/1193 [==============================] - 27s 21ms/step - loss: 1.4670 - accuracy: 0.3691\n","Epoch 2/10\n","1193/1193 [==============================] - 8s 7ms/step - loss: 1.3403 - accuracy: 0.4301\n","Epoch 3/10\n","1193/1193 [==============================] - 7s 6ms/step - loss: 1.2913 - accuracy: 0.4571\n","Epoch 4/10\n","1193/1193 [==============================] - 8s 7ms/step - loss: 1.2191 - accuracy: 0.5179\n","Epoch 5/10\n","1193/1193 [==============================] - 10s 9ms/step - loss: 1.1709 - accuracy: 0.5480\n","Epoch 6/10\n","1193/1193 [==============================] - 9s 7ms/step - loss: 1.1595 - accuracy: 0.5510\n","Epoch 7/10\n","1193/1193 [==============================] - 6s 5ms/step - loss: 1.1399 - accuracy: 0.5629\n","Epoch 8/10\n","1193/1193 [==============================] - 7s 6ms/step - loss: 1.1325 - accuracy: 0.5736\n","Epoch 9/10\n","1193/1193 [==============================] - 5s 5ms/step - loss: 1.1034 - accuracy: 0.5958\n","Epoch 10/10\n","1193/1193 [==============================] - 6s 5ms/step - loss: 1.0879 - accuracy: 0.6040\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8811166850>"]},"metadata":{},"execution_count":119}]},{"cell_type":"code","source":["test_loss, test_acc = model.evaluate(test_sequences_multi, test_labels, verbose=2)\n","print('Test accuracy:', test_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WWWX6j6Qzg7B","executionInfo":{"status":"ok","timestamp":1681476823443,"user_tz":-330,"elapsed":961,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"77667cd5-5240-4ae1-b6cc-6b5507280c9a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["299/299 - 1s - loss: 0.9144 - accuracy: 0.7844 - 1s/epoch - 4ms/step\n","Test accuracy: 0.7843589186668396\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n","from tensorflow.keras.models import Sequential\n","\n","# Load the dataset\n","datamodel2 = pd.read_csv('./cyberbullying_tweets.csv')\n","datamodel2['cyberbullying_type'] = datamodel2['cyberbullying_type'].replace({'not_cyberbullying':0,'gender':1,'religion':2,'age':3,'ethnicity':4,'other_cyberbullying':5})\n","\n","# Split the dataset into training and testing sets\n","train_data = datamodel2.sample(frac=0.8, random_state=42)\n","test_data = datamodel2.drop(train_data.index)\n","\n","# Tokenize the text data\n","tokenizer = Tokenizer(num_words=5000, lower=True)\n","tokenizer.fit_on_texts(train_data['tweet_text'])\n","train_sequences = tokenizer.texts_to_sequences(train_data['tweet_text'])\n","test_sequences = tokenizer.texts_to_sequences(test_data['tweet_text'])\n","\n","# Pad the sequences to make them of equal length\n","max_len = 100\n","train_sequences = pad_sequences(train_sequences, maxlen=max_len)\n","test_sequences = pad_sequences(test_sequences, maxlen=max_len)\n","\n","# Define the CNN model\n","model2 = Sequential()\n","model2.add(Embedding(input_dim=5000, output_dim=32, input_length=max_len))\n","model2.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n","model2.add(MaxPooling1D(pool_size=2))\n","model2.add(Flatten())\n","model2.add(Dense(128, activation='relu'))\n","model2.add(Dropout(0.5))\n","model2.add(Dense(6, activation='softmax'))\n","\n","# Compile the model\n","model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Convert labels to one-hot encoded format\n","train_labels = tf.keras.utils.to_categorical(train_data['cyberbullying_type'], num_classes=6)\n","test_labels = tf.keras.utils.to_categorical(test_data['cyberbullying_type'], num_classes=6)\n","# Train the model\n","model2.fit(train_sequences, train_labels, epochs=10, batch_size=32)\n","\n","# Evaluate the model\n","test_loss, test_acc = model2.evaluate(test_sequences, test_labels, verbose=2)\n","print('Test accuracy:', test_acc)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S5wbb3Yu0kvi","executionInfo":{"status":"ok","timestamp":1681477104047,"user_tz":-330,"elapsed":145880,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"c08d9cfe-d9d1-47e4-bcec-a39a88f4c62c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","1193/1193 [==============================] - 30s 24ms/step - loss: 0.6117 - accuracy: 0.7330\n","Epoch 2/10\n","1193/1193 [==============================] - 8s 7ms/step - loss: 0.3747 - accuracy: 0.8435\n","Epoch 3/10\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.3262 - accuracy: 0.8672\n","Epoch 4/10\n","1193/1193 [==============================] - 7s 6ms/step - loss: 0.2860 - accuracy: 0.8825\n","Epoch 5/10\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.2600 - accuracy: 0.8919\n","Epoch 6/10\n","1193/1193 [==============================] - 8s 7ms/step - loss: 0.2269 - accuracy: 0.9047\n","Epoch 7/10\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.2023 - accuracy: 0.9149\n","Epoch 8/10\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.1791 - accuracy: 0.9248\n","Epoch 9/10\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.1601 - accuracy: 0.9320\n","Epoch 10/10\n","1193/1193 [==============================] - 5s 5ms/step - loss: 0.1448 - accuracy: 0.9374\n","299/299 - 1s - loss: 0.7817 - accuracy: 0.8127 - 722ms/epoch - 2ms/step\n","Test accuracy: 0.8127490282058716\n"]}]},{"cell_type":"code","source":["# Train the model\n","model2.fit(train_sequences, train_labels, epochs=200, batch_size=512)\n","\n","# Evaluate the model\n","test_loss, test_acc = model2.evaluate(test_sequences, test_labels, verbose=2)\n","print('Test accuracy:', test_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TaN4294x1LH_","executionInfo":{"status":"ok","timestamp":1681477566437,"user_tz":-330,"elapsed":203692,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"ef350210-397c-4acf-8589-3ef3e1754b34"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","75/75 [==============================] - 12s 160ms/step - loss: 0.1093 - accuracy: 0.9515\n","Epoch 2/200\n","75/75 [==============================] - 8s 101ms/step - loss: 0.1041 - accuracy: 0.9527\n","Epoch 3/200\n","75/75 [==============================] - 6s 79ms/step - loss: 0.0994 - accuracy: 0.9543\n","Epoch 4/200\n","75/75 [==============================] - 2s 33ms/step - loss: 0.0967 - accuracy: 0.9551\n","Epoch 5/200\n","75/75 [==============================] - 5s 64ms/step - loss: 0.0942 - accuracy: 0.9552\n","Epoch 6/200\n","75/75 [==============================] - 3s 40ms/step - loss: 0.0915 - accuracy: 0.9568\n","Epoch 7/200\n","75/75 [==============================] - 3s 35ms/step - loss: 0.0892 - accuracy: 0.9570\n","Epoch 8/200\n","75/75 [==============================] - 2s 23ms/step - loss: 0.0881 - accuracy: 0.9564\n","Epoch 9/200\n","75/75 [==============================] - 2s 22ms/step - loss: 0.0866 - accuracy: 0.9578\n","Epoch 10/200\n","75/75 [==============================] - 2s 32ms/step - loss: 0.0857 - accuracy: 0.9575\n","Epoch 11/200\n","75/75 [==============================] - 2s 26ms/step - loss: 0.0829 - accuracy: 0.9579\n","Epoch 12/200\n","75/75 [==============================] - 1s 17ms/step - loss: 0.0826 - accuracy: 0.9584\n","Epoch 13/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0820 - accuracy: 0.9584\n","Epoch 14/200\n","75/75 [==============================] - 1s 19ms/step - loss: 0.0805 - accuracy: 0.9576\n","Epoch 15/200\n","75/75 [==============================] - 1s 18ms/step - loss: 0.0792 - accuracy: 0.9588\n","Epoch 16/200\n","75/75 [==============================] - 1s 19ms/step - loss: 0.0781 - accuracy: 0.9592\n","Epoch 17/200\n","75/75 [==============================] - 1s 14ms/step - loss: 0.0770 - accuracy: 0.9593\n","Epoch 18/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0758 - accuracy: 0.9611\n","Epoch 19/200\n","75/75 [==============================] - 1s 17ms/step - loss: 0.0752 - accuracy: 0.9597\n","Epoch 20/200\n","75/75 [==============================] - 1s 19ms/step - loss: 0.0754 - accuracy: 0.9596\n","Epoch 21/200\n","75/75 [==============================] - 1s 12ms/step - loss: 0.0751 - accuracy: 0.9591\n","Epoch 22/200\n","75/75 [==============================] - 1s 10ms/step - loss: 0.0734 - accuracy: 0.9606\n","Epoch 23/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0731 - accuracy: 0.9603\n","Epoch 24/200\n","75/75 [==============================] - 1s 13ms/step - loss: 0.0712 - accuracy: 0.9609\n","Epoch 25/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0707 - accuracy: 0.9614\n","Epoch 26/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0707 - accuracy: 0.9612\n","Epoch 27/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0701 - accuracy: 0.9609\n","Epoch 28/200\n","75/75 [==============================] - 1s 13ms/step - loss: 0.0698 - accuracy: 0.9613\n","Epoch 29/200\n","75/75 [==============================] - 1s 13ms/step - loss: 0.0691 - accuracy: 0.9614\n","Epoch 30/200\n","75/75 [==============================] - 1s 13ms/step - loss: 0.0679 - accuracy: 0.9614\n","Epoch 31/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0680 - accuracy: 0.9613\n","Epoch 32/200\n","75/75 [==============================] - 1s 13ms/step - loss: 0.0680 - accuracy: 0.9612\n","Epoch 33/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0668 - accuracy: 0.9608\n","Epoch 34/200\n","75/75 [==============================] - 1s 10ms/step - loss: 0.0669 - accuracy: 0.9605\n","Epoch 35/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0648 - accuracy: 0.9620\n","Epoch 36/200\n","75/75 [==============================] - 1s 16ms/step - loss: 0.0650 - accuracy: 0.9623\n","Epoch 37/200\n","75/75 [==============================] - 1s 12ms/step - loss: 0.0661 - accuracy: 0.9621\n","Epoch 38/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0646 - accuracy: 0.9620\n","Epoch 39/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0636 - accuracy: 0.9624\n","Epoch 40/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0637 - accuracy: 0.9616\n","Epoch 41/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0625 - accuracy: 0.9622\n","Epoch 42/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0629 - accuracy: 0.9633\n","Epoch 43/200\n","75/75 [==============================] - 1s 9ms/step - loss: 0.0619 - accuracy: 0.9631\n","Epoch 44/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0618 - accuracy: 0.9632\n","Epoch 45/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0616 - accuracy: 0.9634\n","Epoch 46/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0617 - accuracy: 0.9629\n","Epoch 47/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0609 - accuracy: 0.9635\n","Epoch 48/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0607 - accuracy: 0.9635\n","Epoch 49/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0609 - accuracy: 0.9630\n","Epoch 50/200\n","75/75 [==============================] - 1s 10ms/step - loss: 0.0601 - accuracy: 0.9622\n","Epoch 51/200\n","75/75 [==============================] - 2s 24ms/step - loss: 0.0602 - accuracy: 0.9634\n","Epoch 52/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0593 - accuracy: 0.9630\n","Epoch 53/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0590 - accuracy: 0.9640\n","Epoch 54/200\n","75/75 [==============================] - 1s 16ms/step - loss: 0.0582 - accuracy: 0.9647\n","Epoch 55/200\n","75/75 [==============================] - 1s 17ms/step - loss: 0.0585 - accuracy: 0.9633\n","Epoch 56/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0584 - accuracy: 0.9635\n","Epoch 57/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0575 - accuracy: 0.9646\n","Epoch 58/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0574 - accuracy: 0.9637\n","Epoch 59/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0572 - accuracy: 0.9645\n","Epoch 60/200\n","75/75 [==============================] - 1s 9ms/step - loss: 0.0567 - accuracy: 0.9633\n","Epoch 61/200\n","75/75 [==============================] - 1s 13ms/step - loss: 0.0567 - accuracy: 0.9635\n","Epoch 62/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0563 - accuracy: 0.9647\n","Epoch 63/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0551 - accuracy: 0.9647\n","Epoch 64/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0557 - accuracy: 0.9639\n","Epoch 65/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0555 - accuracy: 0.9651\n","Epoch 66/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0557 - accuracy: 0.9652\n","Epoch 67/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0556 - accuracy: 0.9640\n","Epoch 68/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0549 - accuracy: 0.9652\n","Epoch 69/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0553 - accuracy: 0.9650\n","Epoch 70/200\n","75/75 [==============================] - 1s 7ms/step - loss: 0.0547 - accuracy: 0.9649\n","Epoch 71/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0541 - accuracy: 0.9640\n","Epoch 72/200\n","75/75 [==============================] - 1s 15ms/step - loss: 0.0546 - accuracy: 0.9645\n","Epoch 73/200\n","75/75 [==============================] - 1s 12ms/step - loss: 0.0544 - accuracy: 0.9636\n","Epoch 74/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0542 - accuracy: 0.9658\n","Epoch 75/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0546 - accuracy: 0.9652\n","Epoch 76/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0533 - accuracy: 0.9658\n","Epoch 77/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0537 - accuracy: 0.9651\n","Epoch 78/200\n","75/75 [==============================] - 1s 9ms/step - loss: 0.0532 - accuracy: 0.9651\n","Epoch 79/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0532 - accuracy: 0.9663\n","Epoch 80/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0529 - accuracy: 0.9653\n","Epoch 81/200\n","75/75 [==============================] - 1s 9ms/step - loss: 0.0533 - accuracy: 0.9651\n","Epoch 82/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0530 - accuracy: 0.9659\n","Epoch 83/200\n","75/75 [==============================] - 1s 9ms/step - loss: 0.0530 - accuracy: 0.9662\n","Epoch 84/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0531 - accuracy: 0.9653\n","Epoch 85/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0533 - accuracy: 0.9655\n","Epoch 86/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0532 - accuracy: 0.9643\n","Epoch 87/200\n","75/75 [==============================] - 1s 14ms/step - loss: 0.0520 - accuracy: 0.9655\n","Epoch 88/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0524 - accuracy: 0.9664\n","Epoch 89/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0528 - accuracy: 0.9652\n","Epoch 90/200\n","75/75 [==============================] - 1s 15ms/step - loss: 0.0527 - accuracy: 0.9656\n","Epoch 91/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0524 - accuracy: 0.9658\n","Epoch 92/200\n","75/75 [==============================] - 1s 7ms/step - loss: 0.0527 - accuracy: 0.9654\n","Epoch 93/200\n","75/75 [==============================] - 1s 13ms/step - loss: 0.0529 - accuracy: 0.9665\n","Epoch 94/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0524 - accuracy: 0.9658\n","Epoch 95/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0521 - accuracy: 0.9657\n","Epoch 96/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0519 - accuracy: 0.9662\n","Epoch 97/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0520 - accuracy: 0.9661\n","Epoch 98/200\n","75/75 [==============================] - 1s 9ms/step - loss: 0.0521 - accuracy: 0.9660\n","Epoch 99/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0522 - accuracy: 0.9662\n","Epoch 100/200\n","75/75 [==============================] - 1s 9ms/step - loss: 0.0522 - accuracy: 0.9668\n","Epoch 101/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0522 - accuracy: 0.9658\n","Epoch 102/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0514 - accuracy: 0.9669\n","Epoch 103/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0516 - accuracy: 0.9666\n","Epoch 104/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0517 - accuracy: 0.9665\n","Epoch 105/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0518 - accuracy: 0.9668\n","Epoch 106/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0517 - accuracy: 0.9665\n","Epoch 107/200\n","75/75 [==============================] - 1s 9ms/step - loss: 0.0514 - accuracy: 0.9667\n","Epoch 108/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0513 - accuracy: 0.9662\n","Epoch 109/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0513 - accuracy: 0.9667\n","Epoch 110/200\n","75/75 [==============================] - 1s 10ms/step - loss: 0.0516 - accuracy: 0.9656\n","Epoch 111/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0520 - accuracy: 0.9661\n","Epoch 112/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0517 - accuracy: 0.9664\n","Epoch 113/200\n","75/75 [==============================] - 1s 12ms/step - loss: 0.0520 - accuracy: 0.9655\n","Epoch 114/200\n","75/75 [==============================] - 1s 7ms/step - loss: 0.0512 - accuracy: 0.9652\n","Epoch 115/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0521 - accuracy: 0.9655\n","Epoch 116/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0516 - accuracy: 0.9667\n","Epoch 117/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0512 - accuracy: 0.9671\n","Epoch 118/200\n","75/75 [==============================] - 1s 9ms/step - loss: 0.0510 - accuracy: 0.9663\n","Epoch 119/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0514 - accuracy: 0.9661\n","Epoch 120/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0513 - accuracy: 0.9665\n","Epoch 121/200\n","75/75 [==============================] - 1s 9ms/step - loss: 0.0508 - accuracy: 0.9669\n","Epoch 122/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0513 - accuracy: 0.9662\n","Epoch 123/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0519 - accuracy: 0.9669\n","Epoch 124/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0519 - accuracy: 0.9666\n","Epoch 125/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0511 - accuracy: 0.9664\n","Epoch 126/200\n","75/75 [==============================] - 1s 9ms/step - loss: 0.0510 - accuracy: 0.9672\n","Epoch 127/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0526 - accuracy: 0.9674\n","Epoch 128/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0511 - accuracy: 0.9651\n","Epoch 129/200\n","75/75 [==============================] - 1s 9ms/step - loss: 0.0510 - accuracy: 0.9668\n","Epoch 130/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0509 - accuracy: 0.9669\n","Epoch 131/200\n","75/75 [==============================] - 1s 9ms/step - loss: 0.0504 - accuracy: 0.9668\n","Epoch 132/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0502 - accuracy: 0.9678\n","Epoch 133/200\n","75/75 [==============================] - 1s 15ms/step - loss: 0.0516 - accuracy: 0.9660\n","Epoch 134/200\n","75/75 [==============================] - 1s 16ms/step - loss: 0.0503 - accuracy: 0.9668\n","Epoch 135/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0502 - accuracy: 0.9665\n","Epoch 136/200\n","75/75 [==============================] - 1s 12ms/step - loss: 0.0506 - accuracy: 0.9670\n","Epoch 137/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0503 - accuracy: 0.9673\n","Epoch 138/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0502 - accuracy: 0.9668\n","Epoch 139/200\n","75/75 [==============================] - 1s 9ms/step - loss: 0.0502 - accuracy: 0.9672\n","Epoch 140/200\n","75/75 [==============================] - 1s 9ms/step - loss: 0.0504 - accuracy: 0.9673\n","Epoch 141/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0514 - accuracy: 0.9673\n","Epoch 142/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0503 - accuracy: 0.9676\n","Epoch 143/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0505 - accuracy: 0.9669\n","Epoch 144/200\n","75/75 [==============================] - 1s 9ms/step - loss: 0.0509 - accuracy: 0.9671\n","Epoch 145/200\n","75/75 [==============================] - 1s 9ms/step - loss: 0.0502 - accuracy: 0.9670\n","Epoch 146/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0498 - accuracy: 0.9678\n","Epoch 147/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0502 - accuracy: 0.9679\n","Epoch 148/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0500 - accuracy: 0.9671\n","Epoch 149/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0505 - accuracy: 0.9669\n","Epoch 150/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0500 - accuracy: 0.9665\n","Epoch 151/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0501 - accuracy: 0.9668\n","Epoch 152/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0502 - accuracy: 0.9680\n","Epoch 153/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0502 - accuracy: 0.9672\n","Epoch 154/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0505 - accuracy: 0.9668\n","Epoch 155/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0511 - accuracy: 0.9663\n","Epoch 156/200\n","75/75 [==============================] - 1s 7ms/step - loss: 0.0507 - accuracy: 0.9671\n","Epoch 157/200\n","75/75 [==============================] - 1s 15ms/step - loss: 0.0501 - accuracy: 0.9659\n","Epoch 158/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0507 - accuracy: 0.9681\n","Epoch 159/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0504 - accuracy: 0.9672\n","Epoch 160/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0501 - accuracy: 0.9668\n","Epoch 161/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0502 - accuracy: 0.9672\n","Epoch 162/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0502 - accuracy: 0.9669\n","Epoch 163/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0502 - accuracy: 0.9673\n","Epoch 164/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0496 - accuracy: 0.9675\n","Epoch 165/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0495 - accuracy: 0.9678\n","Epoch 166/200\n","75/75 [==============================] - 1s 9ms/step - loss: 0.0491 - accuracy: 0.9681\n","Epoch 167/200\n","75/75 [==============================] - 1s 9ms/step - loss: 0.0496 - accuracy: 0.9675\n","Epoch 168/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0501 - accuracy: 0.9679\n","Epoch 169/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0502 - accuracy: 0.9670\n","Epoch 170/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0510 - accuracy: 0.9679\n","Epoch 171/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0504 - accuracy: 0.9661\n","Epoch 172/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0501 - accuracy: 0.9662\n","Epoch 173/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0505 - accuracy: 0.9667\n","Epoch 174/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0506 - accuracy: 0.9678\n","Epoch 175/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0504 - accuracy: 0.9661\n","Epoch 176/200\n","75/75 [==============================] - 1s 7ms/step - loss: 0.0496 - accuracy: 0.9673\n","Epoch 177/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0489 - accuracy: 0.9678\n","Epoch 178/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0497 - accuracy: 0.9669\n","Epoch 179/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0503 - accuracy: 0.9671\n","Epoch 180/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0504 - accuracy: 0.9668\n","Epoch 181/200\n","75/75 [==============================] - 1s 7ms/step - loss: 0.0497 - accuracy: 0.9673\n","Epoch 182/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0505 - accuracy: 0.9673\n","Epoch 183/200\n","75/75 [==============================] - 1s 9ms/step - loss: 0.0501 - accuracy: 0.9675\n","Epoch 184/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0506 - accuracy: 0.9664\n","Epoch 185/200\n","75/75 [==============================] - 1s 9ms/step - loss: 0.0501 - accuracy: 0.9665\n","Epoch 186/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0507 - accuracy: 0.9667\n","Epoch 187/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0508 - accuracy: 0.9669\n","Epoch 188/200\n","75/75 [==============================] - 1s 9ms/step - loss: 0.0494 - accuracy: 0.9668\n","Epoch 189/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0492 - accuracy: 0.9674\n","Epoch 190/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0495 - accuracy: 0.9670\n","Epoch 191/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0504 - accuracy: 0.9666\n","Epoch 192/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0514 - accuracy: 0.9655\n","Epoch 193/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0510 - accuracy: 0.9668\n","Epoch 194/200\n","75/75 [==============================] - 1s 9ms/step - loss: 0.0506 - accuracy: 0.9670\n","Epoch 195/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0495 - accuracy: 0.9663\n","Epoch 196/200\n","75/75 [==============================] - 1s 8ms/step - loss: 0.0505 - accuracy: 0.9659\n","Epoch 197/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0502 - accuracy: 0.9667\n","Epoch 198/200\n","75/75 [==============================] - 0s 6ms/step - loss: 0.0504 - accuracy: 0.9658\n","Epoch 199/200\n","75/75 [==============================] - 1s 11ms/step - loss: 0.0507 - accuracy: 0.9676\n","Epoch 200/200\n","75/75 [==============================] - 1s 12ms/step - loss: 0.0507 - accuracy: 0.9661\n","299/299 - 1s - loss: 3.3167 - accuracy: 0.7906 - 909ms/epoch - 3ms/step\n","Test accuracy: 0.7906269431114197\n"]}]},{"cell_type":"code","source":["# Train the model\n","model2.fit(train_sequences, train_labels, epochs=100, batch_size=64)\n","\n","# Evaluate the model\n","test_loss, test_acc = model2.evaluate(test_sequences, test_labels, verbose=2)\n","print('Test accuracy:', test_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ew7knOXt4NDb","executionInfo":{"status":"ok","timestamp":1681478049870,"user_tz":-330,"elapsed":383884,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"cac61973-e6cc-406a-b87b-814ca0d8b731"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","597/597 [==============================] - 34s 56ms/step - loss: 0.0830 - accuracy: 0.9584\n","Epoch 2/100\n","597/597 [==============================] - 7s 12ms/step - loss: 0.0732 - accuracy: 0.9622\n","Epoch 3/100\n","597/597 [==============================] - 5s 8ms/step - loss: 0.0620 - accuracy: 0.9636\n","Epoch 4/100\n","597/597 [==============================] - 5s 9ms/step - loss: 0.0588 - accuracy: 0.9645\n","Epoch 5/100\n","597/597 [==============================] - 4s 7ms/step - loss: 0.0601 - accuracy: 0.9639\n","Epoch 6/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0616 - accuracy: 0.9638\n","Epoch 7/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0605 - accuracy: 0.9653\n","Epoch 8/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0570 - accuracy: 0.9659\n","Epoch 9/100\n","597/597 [==============================] - 3s 6ms/step - loss: 0.0592 - accuracy: 0.9645\n","Epoch 10/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0590 - accuracy: 0.9647\n","Epoch 11/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0575 - accuracy: 0.9651\n","Epoch 12/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0579 - accuracy: 0.9659\n","Epoch 13/100\n","597/597 [==============================] - 4s 6ms/step - loss: 0.0597 - accuracy: 0.9641\n","Epoch 14/100\n","597/597 [==============================] - 3s 4ms/step - loss: 0.0605 - accuracy: 0.9652\n","Epoch 15/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0569 - accuracy: 0.9650\n","Epoch 16/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0557 - accuracy: 0.9650\n","Epoch 17/100\n","597/597 [==============================] - 4s 7ms/step - loss: 0.0591 - accuracy: 0.9650\n","Epoch 18/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0573 - accuracy: 0.9647\n","Epoch 19/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0560 - accuracy: 0.9653\n","Epoch 20/100\n","597/597 [==============================] - 3s 6ms/step - loss: 0.0579 - accuracy: 0.9654\n","Epoch 21/100\n","597/597 [==============================] - 4s 6ms/step - loss: 0.0567 - accuracy: 0.9657\n","Epoch 22/100\n","597/597 [==============================] - 3s 4ms/step - loss: 0.0542 - accuracy: 0.9649\n","Epoch 23/100\n","597/597 [==============================] - 3s 4ms/step - loss: 0.0578 - accuracy: 0.9651\n","Epoch 24/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0572 - accuracy: 0.9650\n","Epoch 25/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0560 - accuracy: 0.9660\n","Epoch 26/100\n","597/597 [==============================] - 4s 6ms/step - loss: 0.0582 - accuracy: 0.9651\n","Epoch 27/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0565 - accuracy: 0.9658\n","Epoch 28/100\n","597/597 [==============================] - 3s 4ms/step - loss: 0.0559 - accuracy: 0.9650\n","Epoch 29/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0557 - accuracy: 0.9660\n","Epoch 30/100\n","597/597 [==============================] - 3s 6ms/step - loss: 0.0572 - accuracy: 0.9656\n","Epoch 31/100\n","597/597 [==============================] - 2s 4ms/step - loss: 0.0603 - accuracy: 0.9642\n","Epoch 32/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0576 - accuracy: 0.9652\n","Epoch 33/100\n","597/597 [==============================] - 3s 4ms/step - loss: 0.0586 - accuracy: 0.9643\n","Epoch 34/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0561 - accuracy: 0.9662\n","Epoch 35/100\n","597/597 [==============================] - 3s 6ms/step - loss: 0.0555 - accuracy: 0.9662\n","Epoch 36/100\n","597/597 [==============================] - 3s 4ms/step - loss: 0.0548 - accuracy: 0.9659\n","Epoch 37/100\n","597/597 [==============================] - 4s 6ms/step - loss: 0.0586 - accuracy: 0.9657\n","Epoch 38/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0563 - accuracy: 0.9657\n","Epoch 39/100\n","597/597 [==============================] - 3s 6ms/step - loss: 0.0550 - accuracy: 0.9657\n","Epoch 40/100\n","597/597 [==============================] - 3s 4ms/step - loss: 0.0551 - accuracy: 0.9656\n","Epoch 41/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0581 - accuracy: 0.9655\n","Epoch 42/100\n","597/597 [==============================] - 2s 4ms/step - loss: 0.0555 - accuracy: 0.9655\n","Epoch 43/100\n","597/597 [==============================] - 3s 6ms/step - loss: 0.0546 - accuracy: 0.9660\n","Epoch 44/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0570 - accuracy: 0.9656\n","Epoch 45/100\n","597/597 [==============================] - 3s 4ms/step - loss: 0.0563 - accuracy: 0.9661\n","Epoch 46/100\n","597/597 [==============================] - 3s 4ms/step - loss: 0.0590 - accuracy: 0.9653\n","Epoch 47/100\n","597/597 [==============================] - 3s 4ms/step - loss: 0.0550 - accuracy: 0.9655\n","Epoch 48/100\n","597/597 [==============================] - 3s 6ms/step - loss: 0.0596 - accuracy: 0.9648\n","Epoch 49/100\n","597/597 [==============================] - 3s 4ms/step - loss: 0.0562 - accuracy: 0.9663\n","Epoch 50/100\n","597/597 [==============================] - 2s 4ms/step - loss: 0.0546 - accuracy: 0.9659\n","Epoch 51/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0559 - accuracy: 0.9651\n","Epoch 52/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0541 - accuracy: 0.9652\n","Epoch 53/100\n","597/597 [==============================] - 4s 6ms/step - loss: 0.0544 - accuracy: 0.9657\n","Epoch 54/100\n","597/597 [==============================] - 3s 4ms/step - loss: 0.0529 - accuracy: 0.9655\n","Epoch 55/100\n","597/597 [==============================] - 3s 4ms/step - loss: 0.0556 - accuracy: 0.9658\n","Epoch 56/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0565 - accuracy: 0.9654\n","Epoch 57/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0545 - accuracy: 0.9664\n","Epoch 58/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0593 - accuracy: 0.9654\n","Epoch 59/100\n","597/597 [==============================] - 3s 4ms/step - loss: 0.0534 - accuracy: 0.9657\n","Epoch 60/100\n","597/597 [==============================] - 3s 4ms/step - loss: 0.0528 - accuracy: 0.9658\n","Epoch 61/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0555 - accuracy: 0.9660\n","Epoch 62/100\n","597/597 [==============================] - 4s 6ms/step - loss: 0.0565 - accuracy: 0.9653\n","Epoch 63/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0544 - accuracy: 0.9662\n","Epoch 64/100\n","597/597 [==============================] - 3s 4ms/step - loss: 0.0588 - accuracy: 0.9650\n","Epoch 65/100\n","597/597 [==============================] - 2s 4ms/step - loss: 0.0574 - accuracy: 0.9652\n","Epoch 66/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0567 - accuracy: 0.9653\n","Epoch 67/100\n","597/597 [==============================] - 3s 6ms/step - loss: 0.0548 - accuracy: 0.9651\n","Epoch 68/100\n","597/597 [==============================] - 2s 4ms/step - loss: 0.0543 - accuracy: 0.9652\n","Epoch 69/100\n","597/597 [==============================] - 2s 4ms/step - loss: 0.0538 - accuracy: 0.9658\n","Epoch 70/100\n","597/597 [==============================] - 2s 4ms/step - loss: 0.0560 - accuracy: 0.9667\n","Epoch 71/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0559 - accuracy: 0.9646\n","Epoch 72/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0558 - accuracy: 0.9652\n","Epoch 73/100\n","597/597 [==============================] - 2s 4ms/step - loss: 0.0529 - accuracy: 0.9662\n","Epoch 74/100\n","597/597 [==============================] - 3s 4ms/step - loss: 0.0531 - accuracy: 0.9654\n","Epoch 75/100\n","597/597 [==============================] - 3s 4ms/step - loss: 0.0546 - accuracy: 0.9664\n","Epoch 76/100\n","597/597 [==============================] - 3s 6ms/step - loss: 0.0560 - accuracy: 0.9668\n","Epoch 77/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0559 - accuracy: 0.9652\n","Epoch 78/100\n","597/597 [==============================] - 3s 4ms/step - loss: 0.0555 - accuracy: 0.9654\n","Epoch 79/100\n","597/597 [==============================] - 3s 4ms/step - loss: 0.0589 - accuracy: 0.9646\n","Epoch 80/100\n","597/597 [==============================] - 2s 4ms/step - loss: 0.0592 - accuracy: 0.9653\n","Epoch 81/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0538 - accuracy: 0.9649\n","Epoch 82/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0536 - accuracy: 0.9662\n","Epoch 83/100\n","597/597 [==============================] - 2s 4ms/step - loss: 0.0554 - accuracy: 0.9654\n","Epoch 84/100\n","597/597 [==============================] - 2s 4ms/step - loss: 0.0560 - accuracy: 0.9648\n","Epoch 85/100\n","597/597 [==============================] - 2s 4ms/step - loss: 0.0533 - accuracy: 0.9653\n","Epoch 86/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0546 - accuracy: 0.9641\n","Epoch 87/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0555 - accuracy: 0.9672\n","Epoch 88/100\n","597/597 [==============================] - 3s 4ms/step - loss: 0.0555 - accuracy: 0.9662\n","Epoch 89/100\n","597/597 [==============================] - 3s 4ms/step - loss: 0.0562 - accuracy: 0.9659\n","Epoch 90/100\n","597/597 [==============================] - 2s 4ms/step - loss: 0.0552 - accuracy: 0.9656\n","Epoch 91/100\n","597/597 [==============================] - 4s 6ms/step - loss: 0.0557 - accuracy: 0.9660\n","Epoch 92/100\n","597/597 [==============================] - 2s 4ms/step - loss: 0.0550 - accuracy: 0.9654\n","Epoch 93/100\n","597/597 [==============================] - 2s 4ms/step - loss: 0.0523 - accuracy: 0.9677\n","Epoch 94/100\n","597/597 [==============================] - 3s 4ms/step - loss: 0.0547 - accuracy: 0.9658\n","Epoch 95/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0552 - accuracy: 0.9659\n","Epoch 96/100\n","597/597 [==============================] - 3s 6ms/step - loss: 0.0535 - accuracy: 0.9666\n","Epoch 97/100\n","597/597 [==============================] - 3s 4ms/step - loss: 0.0595 - accuracy: 0.9651\n","Epoch 98/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0543 - accuracy: 0.9656\n","Epoch 99/100\n","597/597 [==============================] - 2s 4ms/step - loss: 0.0534 - accuracy: 0.9664\n","Epoch 100/100\n","597/597 [==============================] - 3s 5ms/step - loss: 0.0545 - accuracy: 0.9651\n","299/299 - 1s - loss: 4.4859 - accuracy: 0.7910 - 863ms/epoch - 3ms/step\n","Test accuracy: 0.7910463213920593\n"]}]},{"cell_type":"code","source":["# Train the model\n","model2.fit(train_sequences, train_labels, epochs=100, batch_size=32)\n","\n","# Evaluate the model\n","test_loss, test_acc = model2.evaluate(test_sequences, test_labels, verbose=2)\n","print('Test accuracy:', test_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yg0jmoMG4P-1","executionInfo":{"status":"ok","timestamp":1681478763476,"user_tz":-330,"elapsed":563174,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"85dc3f6f-73ba-4cfa-a0e7-acb5ed53762e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0581 - accuracy: 0.9658\n","Epoch 2/100\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.0630 - accuracy: 0.9644\n","Epoch 3/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0592 - accuracy: 0.9658\n","Epoch 4/100\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.0626 - accuracy: 0.9644\n","Epoch 5/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0587 - accuracy: 0.9647\n","Epoch 6/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0599 - accuracy: 0.9645\n","Epoch 7/100\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.0613 - accuracy: 0.9643\n","Epoch 8/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0620 - accuracy: 0.9657\n","Epoch 9/100\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.0563 - accuracy: 0.9653\n","Epoch 10/100\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.0659 - accuracy: 0.9641\n","Epoch 11/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0617 - accuracy: 0.9646\n","Epoch 12/100\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.0598 - accuracy: 0.9643\n","Epoch 13/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0596 - accuracy: 0.9642\n","Epoch 14/100\n","1193/1193 [==============================] - 5s 5ms/step - loss: 0.0580 - accuracy: 0.9654\n","Epoch 15/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0620 - accuracy: 0.9644\n","Epoch 16/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0611 - accuracy: 0.9630\n","Epoch 17/100\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.0572 - accuracy: 0.9651\n","Epoch 18/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0606 - accuracy: 0.9650\n","Epoch 19/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0640 - accuracy: 0.9645\n","Epoch 20/100\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.0605 - accuracy: 0.9643\n","Epoch 21/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0568 - accuracy: 0.9656\n","Epoch 22/100\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.0596 - accuracy: 0.9641\n","Epoch 23/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0563 - accuracy: 0.9656\n","Epoch 24/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0606 - accuracy: 0.9655\n","Epoch 25/100\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.0591 - accuracy: 0.9657\n","Epoch 26/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0586 - accuracy: 0.9646\n","Epoch 27/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0569 - accuracy: 0.9656\n","Epoch 28/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0612 - accuracy: 0.9646\n","Epoch 29/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0624 - accuracy: 0.9646\n","Epoch 30/100\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.0612 - accuracy: 0.9642\n","Epoch 31/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0570 - accuracy: 0.9663\n","Epoch 32/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0587 - accuracy: 0.9652\n","Epoch 33/100\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.0598 - accuracy: 0.9651\n","Epoch 34/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0591 - accuracy: 0.9642\n","Epoch 35/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0589 - accuracy: 0.9649\n","Epoch 36/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0605 - accuracy: 0.9652\n","Epoch 37/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0593 - accuracy: 0.9649\n","Epoch 38/100\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.0580 - accuracy: 0.9656\n","Epoch 39/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0608 - accuracy: 0.9648\n","Epoch 40/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0582 - accuracy: 0.9656\n","Epoch 41/100\n","1193/1193 [==============================] - 5s 5ms/step - loss: 0.0597 - accuracy: 0.9641\n","Epoch 42/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0615 - accuracy: 0.9644\n","Epoch 43/100\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.0593 - accuracy: 0.9648\n","Epoch 44/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0587 - accuracy: 0.9652\n","Epoch 45/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0573 - accuracy: 0.9656\n","Epoch 46/100\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.0575 - accuracy: 0.9656\n","Epoch 47/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0580 - accuracy: 0.9652\n","Epoch 48/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0621 - accuracy: 0.9654\n","Epoch 49/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0621 - accuracy: 0.9657\n","Epoch 50/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0564 - accuracy: 0.9653\n","Epoch 51/100\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.0593 - accuracy: 0.9647\n","Epoch 52/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0574 - accuracy: 0.9661\n","Epoch 53/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0581 - accuracy: 0.9653\n","Epoch 54/100\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.0593 - accuracy: 0.9657\n","Epoch 55/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0623 - accuracy: 0.9655\n","Epoch 56/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0584 - accuracy: 0.9655\n","Epoch 57/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0586 - accuracy: 0.9659\n","Epoch 58/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0587 - accuracy: 0.9658\n","Epoch 59/100\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.0586 - accuracy: 0.9649\n","Epoch 60/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0583 - accuracy: 0.9646\n","Epoch 61/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0581 - accuracy: 0.9660\n","Epoch 62/100\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.0611 - accuracy: 0.9655\n","Epoch 63/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0614 - accuracy: 0.9639\n","Epoch 64/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0598 - accuracy: 0.9644\n","Epoch 65/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0604 - accuracy: 0.9652\n","Epoch 66/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0582 - accuracy: 0.9657\n","Epoch 67/100\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.0550 - accuracy: 0.9657\n","Epoch 68/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0635 - accuracy: 0.9647\n","Epoch 69/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0599 - accuracy: 0.9650\n","Epoch 70/100\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.0586 - accuracy: 0.9651\n","Epoch 71/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0604 - accuracy: 0.9646\n","Epoch 72/100\n","1193/1193 [==============================] - 5s 5ms/step - loss: 0.0567 - accuracy: 0.9660\n","Epoch 73/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0600 - accuracy: 0.9644\n","Epoch 74/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0573 - accuracy: 0.9656\n","Epoch 75/100\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.0553 - accuracy: 0.9658\n","Epoch 76/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0587 - accuracy: 0.9651\n","Epoch 77/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0581 - accuracy: 0.9655\n","Epoch 78/100\n","1193/1193 [==============================] - 5s 5ms/step - loss: 0.0565 - accuracy: 0.9658\n","Epoch 79/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0590 - accuracy: 0.9653\n","Epoch 80/100\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.0614 - accuracy: 0.9657\n","Epoch 81/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0593 - accuracy: 0.9652\n","Epoch 82/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0579 - accuracy: 0.9656\n","Epoch 83/100\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.0603 - accuracy: 0.9646\n","Epoch 84/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0586 - accuracy: 0.9647\n","Epoch 85/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0578 - accuracy: 0.9645\n","Epoch 86/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0567 - accuracy: 0.9651\n","Epoch 87/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0600 - accuracy: 0.9665\n","Epoch 88/100\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.0642 - accuracy: 0.9638\n","Epoch 89/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0595 - accuracy: 0.9651\n","Epoch 90/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0577 - accuracy: 0.9656\n","Epoch 91/100\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.0569 - accuracy: 0.9659\n","Epoch 92/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0614 - accuracy: 0.9659\n","Epoch 93/100\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.0573 - accuracy: 0.9659\n","Epoch 94/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0577 - accuracy: 0.9668\n","Epoch 95/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0553 - accuracy: 0.9647\n","Epoch 96/100\n","1193/1193 [==============================] - 6s 5ms/step - loss: 0.0576 - accuracy: 0.9655\n","Epoch 97/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0618 - accuracy: 0.9649\n","Epoch 98/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0538 - accuracy: 0.9671\n","Epoch 99/100\n","1193/1193 [==============================] - 5s 5ms/step - loss: 0.0620 - accuracy: 0.9655\n","Epoch 100/100\n","1193/1193 [==============================] - 5s 4ms/step - loss: 0.0574 - accuracy: 0.9671\n","299/299 - 1s - loss: 5.5124 - accuracy: 0.7914 - 621ms/epoch - 2ms/step\n","Test accuracy: 0.7913608551025391\n"]}]},{"cell_type":"code","source":["#RNN"],"metadata":{"id":"qrfsIv9R-CKq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rnndata = pd.read_csv('./cyberbullying_tweets.csv',encoding='ISO-8859-1')"],"metadata":{"id":"qrHuqz-P-D_D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","import re\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer\n","nltk.download(\"stopwords\")\n","def data_clean(X):\n","  ps = PorterStemmer()\n","  corpus = []\n","  for i in range(len(X)):\n","    print(i)\n","    news = re.sub('[^a-zA-Z]', ' ', X[i])\n","    news = re.sub(r'http\\S+', '', news)\n","    news = re.sub(r'@\\S+', '', news)\n","    news = re.sub(r'#\\S+', '', news)\n","    news = re.sub(r\"(?:\\@|https?\\://)\\S+\",\"\",news) #remove links and mentions\n","    news = re.sub(r'[^\\x00-\\x7f]',r'',news)\n","    news = re.sub(\"\\s\\s+\",\" \",news)\n","    news = news.lower()\n","    news = news.split()\n","    news = [ps.stem(word) for word in news if word not in stopwords.words('english')]\n","    news = ' '.join(news)\n","    corpus.append(news)\n","  return corpus\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3alfcJgUVtqr","executionInfo":{"status":"ok","timestamp":1681536306236,"user_tz":-330,"elapsed":1489,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"b6606be8-9869-49e3-8c23-6cdc95b8c7d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","source":["rnncorpus = data_clean(rnndata['tweet_text'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ldeazY8jX8Lv","executionInfo":{"status":"ok","timestamp":1681536509300,"user_tz":-330,"elapsed":160149,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"034760b1-5b55-4fc9-eed5-b0f5910d05e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","42692\n","42693\n","42694\n","42695\n","42696\n","42697\n","42698\n","42699\n","42700\n","42701\n","42702\n","42703\n","42704\n","42705\n","42706\n","42707\n","42708\n","42709\n","42710\n","42711\n","42712\n","42713\n","42714\n","42715\n","42716\n","42717\n","42718\n","42719\n","42720\n","42721\n","42722\n","42723\n","42724\n","42725\n","42726\n","42727\n","42728\n","42729\n","42730\n","42731\n","42732\n","42733\n","42734\n","42735\n","42736\n","42737\n","42738\n","42739\n","42740\n","42741\n","42742\n","42743\n","42744\n","42745\n","42746\n","42747\n","42748\n","42749\n","42750\n","42751\n","42752\n","42753\n","42754\n","42755\n","42756\n","42757\n","42758\n","42759\n","42760\n","42761\n","42762\n","42763\n","42764\n","42765\n","42766\n","42767\n","42768\n","42769\n","42770\n","42771\n","42772\n","42773\n","42774\n","42775\n","42776\n","42777\n","42778\n","42779\n","42780\n","42781\n","42782\n","42783\n","42784\n","42785\n","42786\n","42787\n","42788\n","42789\n","42790\n","42791\n","42792\n","42793\n","42794\n","42795\n","42796\n","42797\n","42798\n","42799\n","42800\n","42801\n","42802\n","42803\n","42804\n","42805\n","42806\n","42807\n","42808\n","42809\n","42810\n","42811\n","42812\n","42813\n","42814\n","42815\n","42816\n","42817\n","42818\n","42819\n","42820\n","42821\n","42822\n","42823\n","42824\n","42825\n","42826\n","42827\n","42828\n","42829\n","42830\n","42831\n","42832\n","42833\n","42834\n","42835\n","42836\n","42837\n","42838\n","42839\n","42840\n","42841\n","42842\n","42843\n","42844\n","42845\n","42846\n","42847\n","42848\n","42849\n","42850\n","42851\n","42852\n","42853\n","42854\n","42855\n","42856\n","42857\n","42858\n","42859\n","42860\n","42861\n","42862\n","42863\n","42864\n","42865\n","42866\n","42867\n","42868\n","42869\n","42870\n","42871\n","42872\n","42873\n","42874\n","42875\n","42876\n","42877\n","42878\n","42879\n","42880\n","42881\n","42882\n","42883\n","42884\n","42885\n","42886\n","42887\n","42888\n","42889\n","42890\n","42891\n","42892\n","42893\n","42894\n","42895\n","42896\n","42897\n","42898\n","42899\n","42900\n","42901\n","42902\n","42903\n","42904\n","42905\n","42906\n","42907\n","42908\n","42909\n","42910\n","42911\n","42912\n","42913\n","42914\n","42915\n","42916\n","42917\n","42918\n","42919\n","42920\n","42921\n","42922\n","42923\n","42924\n","42925\n","42926\n","42927\n","42928\n","42929\n","42930\n","42931\n","42932\n","42933\n","42934\n","42935\n","42936\n","42937\n","42938\n","42939\n","42940\n","42941\n","42942\n","42943\n","42944\n","42945\n","42946\n","42947\n","42948\n","42949\n","42950\n","42951\n","42952\n","42953\n","42954\n","42955\n","42956\n","42957\n","42958\n","42959\n","42960\n","42961\n","42962\n","42963\n","42964\n","42965\n","42966\n","42967\n","42968\n","42969\n","42970\n","42971\n","42972\n","42973\n","42974\n","42975\n","42976\n","42977\n","42978\n","42979\n","42980\n","42981\n","42982\n","42983\n","42984\n","42985\n","42986\n","42987\n","42988\n","42989\n","42990\n","42991\n","42992\n","42993\n","42994\n","42995\n","42996\n","42997\n","42998\n","42999\n","43000\n","43001\n","43002\n","43003\n","43004\n","43005\n","43006\n","43007\n","43008\n","43009\n","43010\n","43011\n","43012\n","43013\n","43014\n","43015\n","43016\n","43017\n","43018\n","43019\n","43020\n","43021\n","43022\n","43023\n","43024\n","43025\n","43026\n","43027\n","43028\n","43029\n","43030\n","43031\n","43032\n","43033\n","43034\n","43035\n","43036\n","43037\n","43038\n","43039\n","43040\n","43041\n","43042\n","43043\n","43044\n","43045\n","43046\n","43047\n","43048\n","43049\n","43050\n","43051\n","43052\n","43053\n","43054\n","43055\n","43056\n","43057\n","43058\n","43059\n","43060\n","43061\n","43062\n","43063\n","43064\n","43065\n","43066\n","43067\n","43068\n","43069\n","43070\n","43071\n","43072\n","43073\n","43074\n","43075\n","43076\n","43077\n","43078\n","43079\n","43080\n","43081\n","43082\n","43083\n","43084\n","43085\n","43086\n","43087\n","43088\n","43089\n","43090\n","43091\n","43092\n","43093\n","43094\n","43095\n","43096\n","43097\n","43098\n","43099\n","43100\n","43101\n","43102\n","43103\n","43104\n","43105\n","43106\n","43107\n","43108\n","43109\n","43110\n","43111\n","43112\n","43113\n","43114\n","43115\n","43116\n","43117\n","43118\n","43119\n","43120\n","43121\n","43122\n","43123\n","43124\n","43125\n","43126\n","43127\n","43128\n","43129\n","43130\n","43131\n","43132\n","43133\n","43134\n","43135\n","43136\n","43137\n","43138\n","43139\n","43140\n","43141\n","43142\n","43143\n","43144\n","43145\n","43146\n","43147\n","43148\n","43149\n","43150\n","43151\n","43152\n","43153\n","43154\n","43155\n","43156\n","43157\n","43158\n","43159\n","43160\n","43161\n","43162\n","43163\n","43164\n","43165\n","43166\n","43167\n","43168\n","43169\n","43170\n","43171\n","43172\n","43173\n","43174\n","43175\n","43176\n","43177\n","43178\n","43179\n","43180\n","43181\n","43182\n","43183\n","43184\n","43185\n","43186\n","43187\n","43188\n","43189\n","43190\n","43191\n","43192\n","43193\n","43194\n","43195\n","43196\n","43197\n","43198\n","43199\n","43200\n","43201\n","43202\n","43203\n","43204\n","43205\n","43206\n","43207\n","43208\n","43209\n","43210\n","43211\n","43212\n","43213\n","43214\n","43215\n","43216\n","43217\n","43218\n","43219\n","43220\n","43221\n","43222\n","43223\n","43224\n","43225\n","43226\n","43227\n","43228\n","43229\n","43230\n","43231\n","43232\n","43233\n","43234\n","43235\n","43236\n","43237\n","43238\n","43239\n","43240\n","43241\n","43242\n","43243\n","43244\n","43245\n","43246\n","43247\n","43248\n","43249\n","43250\n","43251\n","43252\n","43253\n","43254\n","43255\n","43256\n","43257\n","43258\n","43259\n","43260\n","43261\n","43262\n","43263\n","43264\n","43265\n","43266\n","43267\n","43268\n","43269\n","43270\n","43271\n","43272\n","43273\n","43274\n","43275\n","43276\n","43277\n","43278\n","43279\n","43280\n","43281\n","43282\n","43283\n","43284\n","43285\n","43286\n","43287\n","43288\n","43289\n","43290\n","43291\n","43292\n","43293\n","43294\n","43295\n","43296\n","43297\n","43298\n","43299\n","43300\n","43301\n","43302\n","43303\n","43304\n","43305\n","43306\n","43307\n","43308\n","43309\n","43310\n","43311\n","43312\n","43313\n","43314\n","43315\n","43316\n","43317\n","43318\n","43319\n","43320\n","43321\n","43322\n","43323\n","43324\n","43325\n","43326\n","43327\n","43328\n","43329\n","43330\n","43331\n","43332\n","43333\n","43334\n","43335\n","43336\n","43337\n","43338\n","43339\n","43340\n","43341\n","43342\n","43343\n","43344\n","43345\n","43346\n","43347\n","43348\n","43349\n","43350\n","43351\n","43352\n","43353\n","43354\n","43355\n","43356\n","43357\n","43358\n","43359\n","43360\n","43361\n","43362\n","43363\n","43364\n","43365\n","43366\n","43367\n","43368\n","43369\n","43370\n","43371\n","43372\n","43373\n","43374\n","43375\n","43376\n","43377\n","43378\n","43379\n","43380\n","43381\n","43382\n","43383\n","43384\n","43385\n","43386\n","43387\n","43388\n","43389\n","43390\n","43391\n","43392\n","43393\n","43394\n","43395\n","43396\n","43397\n","43398\n","43399\n","43400\n","43401\n","43402\n","43403\n","43404\n","43405\n","43406\n","43407\n","43408\n","43409\n","43410\n","43411\n","43412\n","43413\n","43414\n","43415\n","43416\n","43417\n","43418\n","43419\n","43420\n","43421\n","43422\n","43423\n","43424\n","43425\n","43426\n","43427\n","43428\n","43429\n","43430\n","43431\n","43432\n","43433\n","43434\n","43435\n","43436\n","43437\n","43438\n","43439\n","43440\n","43441\n","43442\n","43443\n","43444\n","43445\n","43446\n","43447\n","43448\n","43449\n","43450\n","43451\n","43452\n","43453\n","43454\n","43455\n","43456\n","43457\n","43458\n","43459\n","43460\n","43461\n","43462\n","43463\n","43464\n","43465\n","43466\n","43467\n","43468\n","43469\n","43470\n","43471\n","43472\n","43473\n","43474\n","43475\n","43476\n","43477\n","43478\n","43479\n","43480\n","43481\n","43482\n","43483\n","43484\n","43485\n","43486\n","43487\n","43488\n","43489\n","43490\n","43491\n","43492\n","43493\n","43494\n","43495\n","43496\n","43497\n","43498\n","43499\n","43500\n","43501\n","43502\n","43503\n","43504\n","43505\n","43506\n","43507\n","43508\n","43509\n","43510\n","43511\n","43512\n","43513\n","43514\n","43515\n","43516\n","43517\n","43518\n","43519\n","43520\n","43521\n","43522\n","43523\n","43524\n","43525\n","43526\n","43527\n","43528\n","43529\n","43530\n","43531\n","43532\n","43533\n","43534\n","43535\n","43536\n","43537\n","43538\n","43539\n","43540\n","43541\n","43542\n","43543\n","43544\n","43545\n","43546\n","43547\n","43548\n","43549\n","43550\n","43551\n","43552\n","43553\n","43554\n","43555\n","43556\n","43557\n","43558\n","43559\n","43560\n","43561\n","43562\n","43563\n","43564\n","43565\n","43566\n","43567\n","43568\n","43569\n","43570\n","43571\n","43572\n","43573\n","43574\n","43575\n","43576\n","43577\n","43578\n","43579\n","43580\n","43581\n","43582\n","43583\n","43584\n","43585\n","43586\n","43587\n","43588\n","43589\n","43590\n","43591\n","43592\n","43593\n","43594\n","43595\n","43596\n","43597\n","43598\n","43599\n","43600\n","43601\n","43602\n","43603\n","43604\n","43605\n","43606\n","43607\n","43608\n","43609\n","43610\n","43611\n","43612\n","43613\n","43614\n","43615\n","43616\n","43617\n","43618\n","43619\n","43620\n","43621\n","43622\n","43623\n","43624\n","43625\n","43626\n","43627\n","43628\n","43629\n","43630\n","43631\n","43632\n","43633\n","43634\n","43635\n","43636\n","43637\n","43638\n","43639\n","43640\n","43641\n","43642\n","43643\n","43644\n","43645\n","43646\n","43647\n","43648\n","43649\n","43650\n","43651\n","43652\n","43653\n","43654\n","43655\n","43656\n","43657\n","43658\n","43659\n","43660\n","43661\n","43662\n","43663\n","43664\n","43665\n","43666\n","43667\n","43668\n","43669\n","43670\n","43671\n","43672\n","43673\n","43674\n","43675\n","43676\n","43677\n","43678\n","43679\n","43680\n","43681\n","43682\n","43683\n","43684\n","43685\n","43686\n","43687\n","43688\n","43689\n","43690\n","43691\n","43692\n","43693\n","43694\n","43695\n","43696\n","43697\n","43698\n","43699\n","43700\n","43701\n","43702\n","43703\n","43704\n","43705\n","43706\n","43707\n","43708\n","43709\n","43710\n","43711\n","43712\n","43713\n","43714\n","43715\n","43716\n","43717\n","43718\n","43719\n","43720\n","43721\n","43722\n","43723\n","43724\n","43725\n","43726\n","43727\n","43728\n","43729\n","43730\n","43731\n","43732\n","43733\n","43734\n","43735\n","43736\n","43737\n","43738\n","43739\n","43740\n","43741\n","43742\n","43743\n","43744\n","43745\n","43746\n","43747\n","43748\n","43749\n","43750\n","43751\n","43752\n","43753\n","43754\n","43755\n","43756\n","43757\n","43758\n","43759\n","43760\n","43761\n","43762\n","43763\n","43764\n","43765\n","43766\n","43767\n","43768\n","43769\n","43770\n","43771\n","43772\n","43773\n","43774\n","43775\n","43776\n","43777\n","43778\n","43779\n","43780\n","43781\n","43782\n","43783\n","43784\n","43785\n","43786\n","43787\n","43788\n","43789\n","43790\n","43791\n","43792\n","43793\n","43794\n","43795\n","43796\n","43797\n","43798\n","43799\n","43800\n","43801\n","43802\n","43803\n","43804\n","43805\n","43806\n","43807\n","43808\n","43809\n","43810\n","43811\n","43812\n","43813\n","43814\n","43815\n","43816\n","43817\n","43818\n","43819\n","43820\n","43821\n","43822\n","43823\n","43824\n","43825\n","43826\n","43827\n","43828\n","43829\n","43830\n","43831\n","43832\n","43833\n","43834\n","43835\n","43836\n","43837\n","43838\n","43839\n","43840\n","43841\n","43842\n","43843\n","43844\n","43845\n","43846\n","43847\n","43848\n","43849\n","43850\n","43851\n","43852\n","43853\n","43854\n","43855\n","43856\n","43857\n","43858\n","43859\n","43860\n","43861\n","43862\n","43863\n","43864\n","43865\n","43866\n","43867\n","43868\n","43869\n","43870\n","43871\n","43872\n","43873\n","43874\n","43875\n","43876\n","43877\n","43878\n","43879\n","43880\n","43881\n","43882\n","43883\n","43884\n","43885\n","43886\n","43887\n","43888\n","43889\n","43890\n","43891\n","43892\n","43893\n","43894\n","43895\n","43896\n","43897\n","43898\n","43899\n","43900\n","43901\n","43902\n","43903\n","43904\n","43905\n","43906\n","43907\n","43908\n","43909\n","43910\n","43911\n","43912\n","43913\n","43914\n","43915\n","43916\n","43917\n","43918\n","43919\n","43920\n","43921\n","43922\n","43923\n","43924\n","43925\n","43926\n","43927\n","43928\n","43929\n","43930\n","43931\n","43932\n","43933\n","43934\n","43935\n","43936\n","43937\n","43938\n","43939\n","43940\n","43941\n","43942\n","43943\n","43944\n","43945\n","43946\n","43947\n","43948\n","43949\n","43950\n","43951\n","43952\n","43953\n","43954\n","43955\n","43956\n","43957\n","43958\n","43959\n","43960\n","43961\n","43962\n","43963\n","43964\n","43965\n","43966\n","43967\n","43968\n","43969\n","43970\n","43971\n","43972\n","43973\n","43974\n","43975\n","43976\n","43977\n","43978\n","43979\n","43980\n","43981\n","43982\n","43983\n","43984\n","43985\n","43986\n","43987\n","43988\n","43989\n","43990\n","43991\n","43992\n","43993\n","43994\n","43995\n","43996\n","43997\n","43998\n","43999\n","44000\n","44001\n","44002\n","44003\n","44004\n","44005\n","44006\n","44007\n","44008\n","44009\n","44010\n","44011\n","44012\n","44013\n","44014\n","44015\n","44016\n","44017\n","44018\n","44019\n","44020\n","44021\n","44022\n","44023\n","44024\n","44025\n","44026\n","44027\n","44028\n","44029\n","44030\n","44031\n","44032\n","44033\n","44034\n","44035\n","44036\n","44037\n","44038\n","44039\n","44040\n","44041\n","44042\n","44043\n","44044\n","44045\n","44046\n","44047\n","44048\n","44049\n","44050\n","44051\n","44052\n","44053\n","44054\n","44055\n","44056\n","44057\n","44058\n","44059\n","44060\n","44061\n","44062\n","44063\n","44064\n","44065\n","44066\n","44067\n","44068\n","44069\n","44070\n","44071\n","44072\n","44073\n","44074\n","44075\n","44076\n","44077\n","44078\n","44079\n","44080\n","44081\n","44082\n","44083\n","44084\n","44085\n","44086\n","44087\n","44088\n","44089\n","44090\n","44091\n","44092\n","44093\n","44094\n","44095\n","44096\n","44097\n","44098\n","44099\n","44100\n","44101\n","44102\n","44103\n","44104\n","44105\n","44106\n","44107\n","44108\n","44109\n","44110\n","44111\n","44112\n","44113\n","44114\n","44115\n","44116\n","44117\n","44118\n","44119\n","44120\n","44121\n","44122\n","44123\n","44124\n","44125\n","44126\n","44127\n","44128\n","44129\n","44130\n","44131\n","44132\n","44133\n","44134\n","44135\n","44136\n","44137\n","44138\n","44139\n","44140\n","44141\n","44142\n","44143\n","44144\n","44145\n","44146\n","44147\n","44148\n","44149\n","44150\n","44151\n","44152\n","44153\n","44154\n","44155\n","44156\n","44157\n","44158\n","44159\n","44160\n","44161\n","44162\n","44163\n","44164\n","44165\n","44166\n","44167\n","44168\n","44169\n","44170\n","44171\n","44172\n","44173\n","44174\n","44175\n","44176\n","44177\n","44178\n","44179\n","44180\n","44181\n","44182\n","44183\n","44184\n","44185\n","44186\n","44187\n","44188\n","44189\n","44190\n","44191\n","44192\n","44193\n","44194\n","44195\n","44196\n","44197\n","44198\n","44199\n","44200\n","44201\n","44202\n","44203\n","44204\n","44205\n","44206\n","44207\n","44208\n","44209\n","44210\n","44211\n","44212\n","44213\n","44214\n","44215\n","44216\n","44217\n","44218\n","44219\n","44220\n","44221\n","44222\n","44223\n","44224\n","44225\n","44226\n","44227\n","44228\n","44229\n","44230\n","44231\n","44232\n","44233\n","44234\n","44235\n","44236\n","44237\n","44238\n","44239\n","44240\n","44241\n","44242\n","44243\n","44244\n","44245\n","44246\n","44247\n","44248\n","44249\n","44250\n","44251\n","44252\n","44253\n","44254\n","44255\n","44256\n","44257\n","44258\n","44259\n","44260\n","44261\n","44262\n","44263\n","44264\n","44265\n","44266\n","44267\n","44268\n","44269\n","44270\n","44271\n","44272\n","44273\n","44274\n","44275\n","44276\n","44277\n","44278\n","44279\n","44280\n","44281\n","44282\n","44283\n","44284\n","44285\n","44286\n","44287\n","44288\n","44289\n","44290\n","44291\n","44292\n","44293\n","44294\n","44295\n","44296\n","44297\n","44298\n","44299\n","44300\n","44301\n","44302\n","44303\n","44304\n","44305\n","44306\n","44307\n","44308\n","44309\n","44310\n","44311\n","44312\n","44313\n","44314\n","44315\n","44316\n","44317\n","44318\n","44319\n","44320\n","44321\n","44322\n","44323\n","44324\n","44325\n","44326\n","44327\n","44328\n","44329\n","44330\n","44331\n","44332\n","44333\n","44334\n","44335\n","44336\n","44337\n","44338\n","44339\n","44340\n","44341\n","44342\n","44343\n","44344\n","44345\n","44346\n","44347\n","44348\n","44349\n","44350\n","44351\n","44352\n","44353\n","44354\n","44355\n","44356\n","44357\n","44358\n","44359\n","44360\n","44361\n","44362\n","44363\n","44364\n","44365\n","44366\n","44367\n","44368\n","44369\n","44370\n","44371\n","44372\n","44373\n","44374\n","44375\n","44376\n","44377\n","44378\n","44379\n","44380\n","44381\n","44382\n","44383\n","44384\n","44385\n","44386\n","44387\n","44388\n","44389\n","44390\n","44391\n","44392\n","44393\n","44394\n","44395\n","44396\n","44397\n","44398\n","44399\n","44400\n","44401\n","44402\n","44403\n","44404\n","44405\n","44406\n","44407\n","44408\n","44409\n","44410\n","44411\n","44412\n","44413\n","44414\n","44415\n","44416\n","44417\n","44418\n","44419\n","44420\n","44421\n","44422\n","44423\n","44424\n","44425\n","44426\n","44427\n","44428\n","44429\n","44430\n","44431\n","44432\n","44433\n","44434\n","44435\n","44436\n","44437\n","44438\n","44439\n","44440\n","44441\n","44442\n","44443\n","44444\n","44445\n","44446\n","44447\n","44448\n","44449\n","44450\n","44451\n","44452\n","44453\n","44454\n","44455\n","44456\n","44457\n","44458\n","44459\n","44460\n","44461\n","44462\n","44463\n","44464\n","44465\n","44466\n","44467\n","44468\n","44469\n","44470\n","44471\n","44472\n","44473\n","44474\n","44475\n","44476\n","44477\n","44478\n","44479\n","44480\n","44481\n","44482\n","44483\n","44484\n","44485\n","44486\n","44487\n","44488\n","44489\n","44490\n","44491\n","44492\n","44493\n","44494\n","44495\n","44496\n","44497\n","44498\n","44499\n","44500\n","44501\n","44502\n","44503\n","44504\n","44505\n","44506\n","44507\n","44508\n","44509\n","44510\n","44511\n","44512\n","44513\n","44514\n","44515\n","44516\n","44517\n","44518\n","44519\n","44520\n","44521\n","44522\n","44523\n","44524\n","44525\n","44526\n","44527\n","44528\n","44529\n","44530\n","44531\n","44532\n","44533\n","44534\n","44535\n","44536\n","44537\n","44538\n","44539\n","44540\n","44541\n","44542\n","44543\n","44544\n","44545\n","44546\n","44547\n","44548\n","44549\n","44550\n","44551\n","44552\n","44553\n","44554\n","44555\n","44556\n","44557\n","44558\n","44559\n","44560\n","44561\n","44562\n","44563\n","44564\n","44565\n","44566\n","44567\n","44568\n","44569\n","44570\n","44571\n","44572\n","44573\n","44574\n","44575\n","44576\n","44577\n","44578\n","44579\n","44580\n","44581\n","44582\n","44583\n","44584\n","44585\n","44586\n","44587\n","44588\n","44589\n","44590\n","44591\n","44592\n","44593\n","44594\n","44595\n","44596\n","44597\n","44598\n","44599\n","44600\n","44601\n","44602\n","44603\n","44604\n","44605\n","44606\n","44607\n","44608\n","44609\n","44610\n","44611\n","44612\n","44613\n","44614\n","44615\n","44616\n","44617\n","44618\n","44619\n","44620\n","44621\n","44622\n","44623\n","44624\n","44625\n","44626\n","44627\n","44628\n","44629\n","44630\n","44631\n","44632\n","44633\n","44634\n","44635\n","44636\n","44637\n","44638\n","44639\n","44640\n","44641\n","44642\n","44643\n","44644\n","44645\n","44646\n","44647\n","44648\n","44649\n","44650\n","44651\n","44652\n","44653\n","44654\n","44655\n","44656\n","44657\n","44658\n","44659\n","44660\n","44661\n","44662\n","44663\n","44664\n","44665\n","44666\n","44667\n","44668\n","44669\n","44670\n","44671\n","44672\n","44673\n","44674\n","44675\n","44676\n","44677\n","44678\n","44679\n","44680\n","44681\n","44682\n","44683\n","44684\n","44685\n","44686\n","44687\n","44688\n","44689\n","44690\n","44691\n","44692\n","44693\n","44694\n","44695\n","44696\n","44697\n","44698\n","44699\n","44700\n","44701\n","44702\n","44703\n","44704\n","44705\n","44706\n","44707\n","44708\n","44709\n","44710\n","44711\n","44712\n","44713\n","44714\n","44715\n","44716\n","44717\n","44718\n","44719\n","44720\n","44721\n","44722\n","44723\n","44724\n","44725\n","44726\n","44727\n","44728\n","44729\n","44730\n","44731\n","44732\n","44733\n","44734\n","44735\n","44736\n","44737\n","44738\n","44739\n","44740\n","44741\n","44742\n","44743\n","44744\n","44745\n","44746\n","44747\n","44748\n","44749\n","44750\n","44751\n","44752\n","44753\n","44754\n","44755\n","44756\n","44757\n","44758\n","44759\n","44760\n","44761\n","44762\n","44763\n","44764\n","44765\n","44766\n","44767\n","44768\n","44769\n","44770\n","44771\n","44772\n","44773\n","44774\n","44775\n","44776\n","44777\n","44778\n","44779\n","44780\n","44781\n","44782\n","44783\n","44784\n","44785\n","44786\n","44787\n","44788\n","44789\n","44790\n","44791\n","44792\n","44793\n","44794\n","44795\n","44796\n","44797\n","44798\n","44799\n","44800\n","44801\n","44802\n","44803\n","44804\n","44805\n","44806\n","44807\n","44808\n","44809\n","44810\n","44811\n","44812\n","44813\n","44814\n","44815\n","44816\n","44817\n","44818\n","44819\n","44820\n","44821\n","44822\n","44823\n","44824\n","44825\n","44826\n","44827\n","44828\n","44829\n","44830\n","44831\n","44832\n","44833\n","44834\n","44835\n","44836\n","44837\n","44838\n","44839\n","44840\n","44841\n","44842\n","44843\n","44844\n","44845\n","44846\n","44847\n","44848\n","44849\n","44850\n","44851\n","44852\n","44853\n","44854\n","44855\n","44856\n","44857\n","44858\n","44859\n","44860\n","44861\n","44862\n","44863\n","44864\n","44865\n","44866\n","44867\n","44868\n","44869\n","44870\n","44871\n","44872\n","44873\n","44874\n","44875\n","44876\n","44877\n","44878\n","44879\n","44880\n","44881\n","44882\n","44883\n","44884\n","44885\n","44886\n","44887\n","44888\n","44889\n","44890\n","44891\n","44892\n","44893\n","44894\n","44895\n","44896\n","44897\n","44898\n","44899\n","44900\n","44901\n","44902\n","44903\n","44904\n","44905\n","44906\n","44907\n","44908\n","44909\n","44910\n","44911\n","44912\n","44913\n","44914\n","44915\n","44916\n","44917\n","44918\n","44919\n","44920\n","44921\n","44922\n","44923\n","44924\n","44925\n","44926\n","44927\n","44928\n","44929\n","44930\n","44931\n","44932\n","44933\n","44934\n","44935\n","44936\n","44937\n","44938\n","44939\n","44940\n","44941\n","44942\n","44943\n","44944\n","44945\n","44946\n","44947\n","44948\n","44949\n","44950\n","44951\n","44952\n","44953\n","44954\n","44955\n","44956\n","44957\n","44958\n","44959\n","44960\n","44961\n","44962\n","44963\n","44964\n","44965\n","44966\n","44967\n","44968\n","44969\n","44970\n","44971\n","44972\n","44973\n","44974\n","44975\n","44976\n","44977\n","44978\n","44979\n","44980\n","44981\n","44982\n","44983\n","44984\n","44985\n","44986\n","44987\n","44988\n","44989\n","44990\n","44991\n","44992\n","44993\n","44994\n","44995\n","44996\n","44997\n","44998\n","44999\n","45000\n","45001\n","45002\n","45003\n","45004\n","45005\n","45006\n","45007\n","45008\n","45009\n","45010\n","45011\n","45012\n","45013\n","45014\n","45015\n","45016\n","45017\n","45018\n","45019\n","45020\n","45021\n","45022\n","45023\n","45024\n","45025\n","45026\n","45027\n","45028\n","45029\n","45030\n","45031\n","45032\n","45033\n","45034\n","45035\n","45036\n","45037\n","45038\n","45039\n","45040\n","45041\n","45042\n","45043\n","45044\n","45045\n","45046\n","45047\n","45048\n","45049\n","45050\n","45051\n","45052\n","45053\n","45054\n","45055\n","45056\n","45057\n","45058\n","45059\n","45060\n","45061\n","45062\n","45063\n","45064\n","45065\n","45066\n","45067\n","45068\n","45069\n","45070\n","45071\n","45072\n","45073\n","45074\n","45075\n","45076\n","45077\n","45078\n","45079\n","45080\n","45081\n","45082\n","45083\n","45084\n","45085\n","45086\n","45087\n","45088\n","45089\n","45090\n","45091\n","45092\n","45093\n","45094\n","45095\n","45096\n","45097\n","45098\n","45099\n","45100\n","45101\n","45102\n","45103\n","45104\n","45105\n","45106\n","45107\n","45108\n","45109\n","45110\n","45111\n","45112\n","45113\n","45114\n","45115\n","45116\n","45117\n","45118\n","45119\n","45120\n","45121\n","45122\n","45123\n","45124\n","45125\n","45126\n","45127\n","45128\n","45129\n","45130\n","45131\n","45132\n","45133\n","45134\n","45135\n","45136\n","45137\n","45138\n","45139\n","45140\n","45141\n","45142\n","45143\n","45144\n","45145\n","45146\n","45147\n","45148\n","45149\n","45150\n","45151\n","45152\n","45153\n","45154\n","45155\n","45156\n","45157\n","45158\n","45159\n","45160\n","45161\n","45162\n","45163\n","45164\n","45165\n","45166\n","45167\n","45168\n","45169\n","45170\n","45171\n","45172\n","45173\n","45174\n","45175\n","45176\n","45177\n","45178\n","45179\n","45180\n","45181\n","45182\n","45183\n","45184\n","45185\n","45186\n","45187\n","45188\n","45189\n","45190\n","45191\n","45192\n","45193\n","45194\n","45195\n","45196\n","45197\n","45198\n","45199\n","45200\n","45201\n","45202\n","45203\n","45204\n","45205\n","45206\n","45207\n","45208\n","45209\n","45210\n","45211\n","45212\n","45213\n","45214\n","45215\n","45216\n","45217\n","45218\n","45219\n","45220\n","45221\n","45222\n","45223\n","45224\n","45225\n","45226\n","45227\n","45228\n","45229\n","45230\n","45231\n","45232\n","45233\n","45234\n","45235\n","45236\n","45237\n","45238\n","45239\n","45240\n","45241\n","45242\n","45243\n","45244\n","45245\n","45246\n","45247\n","45248\n","45249\n","45250\n","45251\n","45252\n","45253\n","45254\n","45255\n","45256\n","45257\n","45258\n","45259\n","45260\n","45261\n","45262\n","45263\n","45264\n","45265\n","45266\n","45267\n","45268\n","45269\n","45270\n","45271\n","45272\n","45273\n","45274\n","45275\n","45276\n","45277\n","45278\n","45279\n","45280\n","45281\n","45282\n","45283\n","45284\n","45285\n","45286\n","45287\n","45288\n","45289\n","45290\n","45291\n","45292\n","45293\n","45294\n","45295\n","45296\n","45297\n","45298\n","45299\n","45300\n","45301\n","45302\n","45303\n","45304\n","45305\n","45306\n","45307\n","45308\n","45309\n","45310\n","45311\n","45312\n","45313\n","45314\n","45315\n","45316\n","45317\n","45318\n","45319\n","45320\n","45321\n","45322\n","45323\n","45324\n","45325\n","45326\n","45327\n","45328\n","45329\n","45330\n","45331\n","45332\n","45333\n","45334\n","45335\n","45336\n","45337\n","45338\n","45339\n","45340\n","45341\n","45342\n","45343\n","45344\n","45345\n","45346\n","45347\n","45348\n","45349\n","45350\n","45351\n","45352\n","45353\n","45354\n","45355\n","45356\n","45357\n","45358\n","45359\n","45360\n","45361\n","45362\n","45363\n","45364\n","45365\n","45366\n","45367\n","45368\n","45369\n","45370\n","45371\n","45372\n","45373\n","45374\n","45375\n","45376\n","45377\n","45378\n","45379\n","45380\n","45381\n","45382\n","45383\n","45384\n","45385\n","45386\n","45387\n","45388\n","45389\n","45390\n","45391\n","45392\n","45393\n","45394\n","45395\n","45396\n","45397\n","45398\n","45399\n","45400\n","45401\n","45402\n","45403\n","45404\n","45405\n","45406\n","45407\n","45408\n","45409\n","45410\n","45411\n","45412\n","45413\n","45414\n","45415\n","45416\n","45417\n","45418\n","45419\n","45420\n","45421\n","45422\n","45423\n","45424\n","45425\n","45426\n","45427\n","45428\n","45429\n","45430\n","45431\n","45432\n","45433\n","45434\n","45435\n","45436\n","45437\n","45438\n","45439\n","45440\n","45441\n","45442\n","45443\n","45444\n","45445\n","45446\n","45447\n","45448\n","45449\n","45450\n","45451\n","45452\n","45453\n","45454\n","45455\n","45456\n","45457\n","45458\n","45459\n","45460\n","45461\n","45462\n","45463\n","45464\n","45465\n","45466\n","45467\n","45468\n","45469\n","45470\n","45471\n","45472\n","45473\n","45474\n","45475\n","45476\n","45477\n","45478\n","45479\n","45480\n","45481\n","45482\n","45483\n","45484\n","45485\n","45486\n","45487\n","45488\n","45489\n","45490\n","45491\n","45492\n","45493\n","45494\n","45495\n","45496\n","45497\n","45498\n","45499\n","45500\n","45501\n","45502\n","45503\n","45504\n","45505\n","45506\n","45507\n","45508\n","45509\n","45510\n","45511\n","45512\n","45513\n","45514\n","45515\n","45516\n","45517\n","45518\n","45519\n","45520\n","45521\n","45522\n","45523\n","45524\n","45525\n","45526\n","45527\n","45528\n","45529\n","45530\n","45531\n","45532\n","45533\n","45534\n","45535\n","45536\n","45537\n","45538\n","45539\n","45540\n","45541\n","45542\n","45543\n","45544\n","45545\n","45546\n","45547\n","45548\n","45549\n","45550\n","45551\n","45552\n","45553\n","45554\n","45555\n","45556\n","45557\n","45558\n","45559\n","45560\n","45561\n","45562\n","45563\n","45564\n","45565\n","45566\n","45567\n","45568\n","45569\n","45570\n","45571\n","45572\n","45573\n","45574\n","45575\n","45576\n","45577\n","45578\n","45579\n","45580\n","45581\n","45582\n","45583\n","45584\n","45585\n","45586\n","45587\n","45588\n","45589\n","45590\n","45591\n","45592\n","45593\n","45594\n","45595\n","45596\n","45597\n","45598\n","45599\n","45600\n","45601\n","45602\n","45603\n","45604\n","45605\n","45606\n","45607\n","45608\n","45609\n","45610\n","45611\n","45612\n","45613\n","45614\n","45615\n","45616\n","45617\n","45618\n","45619\n","45620\n","45621\n","45622\n","45623\n","45624\n","45625\n","45626\n","45627\n","45628\n","45629\n","45630\n","45631\n","45632\n","45633\n","45634\n","45635\n","45636\n","45637\n","45638\n","45639\n","45640\n","45641\n","45642\n","45643\n","45644\n","45645\n","45646\n","45647\n","45648\n","45649\n","45650\n","45651\n","45652\n","45653\n","45654\n","45655\n","45656\n","45657\n","45658\n","45659\n","45660\n","45661\n","45662\n","45663\n","45664\n","45665\n","45666\n","45667\n","45668\n","45669\n","45670\n","45671\n","45672\n","45673\n","45674\n","45675\n","45676\n","45677\n","45678\n","45679\n","45680\n","45681\n","45682\n","45683\n","45684\n","45685\n","45686\n","45687\n","45688\n","45689\n","45690\n","45691\n","45692\n","45693\n","45694\n","45695\n","45696\n","45697\n","45698\n","45699\n","45700\n","45701\n","45702\n","45703\n","45704\n","45705\n","45706\n","45707\n","45708\n","45709\n","45710\n","45711\n","45712\n","45713\n","45714\n","45715\n","45716\n","45717\n","45718\n","45719\n","45720\n","45721\n","45722\n","45723\n","45724\n","45725\n","45726\n","45727\n","45728\n","45729\n","45730\n","45731\n","45732\n","45733\n","45734\n","45735\n","45736\n","45737\n","45738\n","45739\n","45740\n","45741\n","45742\n","45743\n","45744\n","45745\n","45746\n","45747\n","45748\n","45749\n","45750\n","45751\n","45752\n","45753\n","45754\n","45755\n","45756\n","45757\n","45758\n","45759\n","45760\n","45761\n","45762\n","45763\n","45764\n","45765\n","45766\n","45767\n","45768\n","45769\n","45770\n","45771\n","45772\n","45773\n","45774\n","45775\n","45776\n","45777\n","45778\n","45779\n","45780\n","45781\n","45782\n","45783\n","45784\n","45785\n","45786\n","45787\n","45788\n","45789\n","45790\n","45791\n","45792\n","45793\n","45794\n","45795\n","45796\n","45797\n","45798\n","45799\n","45800\n","45801\n","45802\n","45803\n","45804\n","45805\n","45806\n","45807\n","45808\n","45809\n","45810\n","45811\n","45812\n","45813\n","45814\n","45815\n","45816\n","45817\n","45818\n","45819\n","45820\n","45821\n","45822\n","45823\n","45824\n","45825\n","45826\n","45827\n","45828\n","45829\n","45830\n","45831\n","45832\n","45833\n","45834\n","45835\n","45836\n","45837\n","45838\n","45839\n","45840\n","45841\n","45842\n","45843\n","45844\n","45845\n","45846\n","45847\n","45848\n","45849\n","45850\n","45851\n","45852\n","45853\n","45854\n","45855\n","45856\n","45857\n","45858\n","45859\n","45860\n","45861\n","45862\n","45863\n","45864\n","45865\n","45866\n","45867\n","45868\n","45869\n","45870\n","45871\n","45872\n","45873\n","45874\n","45875\n","45876\n","45877\n","45878\n","45879\n","45880\n","45881\n","45882\n","45883\n","45884\n","45885\n","45886\n","45887\n","45888\n","45889\n","45890\n","45891\n","45892\n","45893\n","45894\n","45895\n","45896\n","45897\n","45898\n","45899\n","45900\n","45901\n","45902\n","45903\n","45904\n","45905\n","45906\n","45907\n","45908\n","45909\n","45910\n","45911\n","45912\n","45913\n","45914\n","45915\n","45916\n","45917\n","45918\n","45919\n","45920\n","45921\n","45922\n","45923\n","45924\n","45925\n","45926\n","45927\n","45928\n","45929\n","45930\n","45931\n","45932\n","45933\n","45934\n","45935\n","45936\n","45937\n","45938\n","45939\n","45940\n","45941\n","45942\n","45943\n","45944\n","45945\n","45946\n","45947\n","45948\n","45949\n","45950\n","45951\n","45952\n","45953\n","45954\n","45955\n","45956\n","45957\n","45958\n","45959\n","45960\n","45961\n","45962\n","45963\n","45964\n","45965\n","45966\n","45967\n","45968\n","45969\n","45970\n","45971\n","45972\n","45973\n","45974\n","45975\n","45976\n","45977\n","45978\n","45979\n","45980\n","45981\n","45982\n","45983\n","45984\n","45985\n","45986\n","45987\n","45988\n","45989\n","45990\n","45991\n","45992\n","45993\n","45994\n","45995\n","45996\n","45997\n","45998\n","45999\n","46000\n","46001\n","46002\n","46003\n","46004\n","46005\n","46006\n","46007\n","46008\n","46009\n","46010\n","46011\n","46012\n","46013\n","46014\n","46015\n","46016\n","46017\n","46018\n","46019\n","46020\n","46021\n","46022\n","46023\n","46024\n","46025\n","46026\n","46027\n","46028\n","46029\n","46030\n","46031\n","46032\n","46033\n","46034\n","46035\n","46036\n","46037\n","46038\n","46039\n","46040\n","46041\n","46042\n","46043\n","46044\n","46045\n","46046\n","46047\n","46048\n","46049\n","46050\n","46051\n","46052\n","46053\n","46054\n","46055\n","46056\n","46057\n","46058\n","46059\n","46060\n","46061\n","46062\n","46063\n","46064\n","46065\n","46066\n","46067\n","46068\n","46069\n","46070\n","46071\n","46072\n","46073\n","46074\n","46075\n","46076\n","46077\n","46078\n","46079\n","46080\n","46081\n","46082\n","46083\n","46084\n","46085\n","46086\n","46087\n","46088\n","46089\n","46090\n","46091\n","46092\n","46093\n","46094\n","46095\n","46096\n","46097\n","46098\n","46099\n","46100\n","46101\n","46102\n","46103\n","46104\n","46105\n","46106\n","46107\n","46108\n","46109\n","46110\n","46111\n","46112\n","46113\n","46114\n","46115\n","46116\n","46117\n","46118\n","46119\n","46120\n","46121\n","46122\n","46123\n","46124\n","46125\n","46126\n","46127\n","46128\n","46129\n","46130\n","46131\n","46132\n","46133\n","46134\n","46135\n","46136\n","46137\n","46138\n","46139\n","46140\n","46141\n","46142\n","46143\n","46144\n","46145\n","46146\n","46147\n","46148\n","46149\n","46150\n","46151\n","46152\n","46153\n","46154\n","46155\n","46156\n","46157\n","46158\n","46159\n","46160\n","46161\n","46162\n","46163\n","46164\n","46165\n","46166\n","46167\n","46168\n","46169\n","46170\n","46171\n","46172\n","46173\n","46174\n","46175\n","46176\n","46177\n","46178\n","46179\n","46180\n","46181\n","46182\n","46183\n","46184\n","46185\n","46186\n","46187\n","46188\n","46189\n","46190\n","46191\n","46192\n","46193\n","46194\n","46195\n","46196\n","46197\n","46198\n","46199\n","46200\n","46201\n","46202\n","46203\n","46204\n","46205\n","46206\n","46207\n","46208\n","46209\n","46210\n","46211\n","46212\n","46213\n","46214\n","46215\n","46216\n","46217\n","46218\n","46219\n","46220\n","46221\n","46222\n","46223\n","46224\n","46225\n","46226\n","46227\n","46228\n","46229\n","46230\n","46231\n","46232\n","46233\n","46234\n","46235\n","46236\n","46237\n","46238\n","46239\n","46240\n","46241\n","46242\n","46243\n","46244\n","46245\n","46246\n","46247\n","46248\n","46249\n","46250\n","46251\n","46252\n","46253\n","46254\n","46255\n","46256\n","46257\n","46258\n","46259\n","46260\n","46261\n","46262\n","46263\n","46264\n","46265\n","46266\n","46267\n","46268\n","46269\n","46270\n","46271\n","46272\n","46273\n","46274\n","46275\n","46276\n","46277\n","46278\n","46279\n","46280\n","46281\n","46282\n","46283\n","46284\n","46285\n","46286\n","46287\n","46288\n","46289\n","46290\n","46291\n","46292\n","46293\n","46294\n","46295\n","46296\n","46297\n","46298\n","46299\n","46300\n","46301\n","46302\n","46303\n","46304\n","46305\n","46306\n","46307\n","46308\n","46309\n","46310\n","46311\n","46312\n","46313\n","46314\n","46315\n","46316\n","46317\n","46318\n","46319\n","46320\n","46321\n","46322\n","46323\n","46324\n","46325\n","46326\n","46327\n","46328\n","46329\n","46330\n","46331\n","46332\n","46333\n","46334\n","46335\n","46336\n","46337\n","46338\n","46339\n","46340\n","46341\n","46342\n","46343\n","46344\n","46345\n","46346\n","46347\n","46348\n","46349\n","46350\n","46351\n","46352\n","46353\n","46354\n","46355\n","46356\n","46357\n","46358\n","46359\n","46360\n","46361\n","46362\n","46363\n","46364\n","46365\n","46366\n","46367\n","46368\n","46369\n","46370\n","46371\n","46372\n","46373\n","46374\n","46375\n","46376\n","46377\n","46378\n","46379\n","46380\n","46381\n","46382\n","46383\n","46384\n","46385\n","46386\n","46387\n","46388\n","46389\n","46390\n","46391\n","46392\n","46393\n","46394\n","46395\n","46396\n","46397\n","46398\n","46399\n","46400\n","46401\n","46402\n","46403\n","46404\n","46405\n","46406\n","46407\n","46408\n","46409\n","46410\n","46411\n","46412\n","46413\n","46414\n","46415\n","46416\n","46417\n","46418\n","46419\n","46420\n","46421\n","46422\n","46423\n","46424\n","46425\n","46426\n","46427\n","46428\n","46429\n","46430\n","46431\n","46432\n","46433\n","46434\n","46435\n","46436\n","46437\n","46438\n","46439\n","46440\n","46441\n","46442\n","46443\n","46444\n","46445\n","46446\n","46447\n","46448\n","46449\n","46450\n","46451\n","46452\n","46453\n","46454\n","46455\n","46456\n","46457\n","46458\n","46459\n","46460\n","46461\n","46462\n","46463\n","46464\n","46465\n","46466\n","46467\n","46468\n","46469\n","46470\n","46471\n","46472\n","46473\n","46474\n","46475\n","46476\n","46477\n","46478\n","46479\n","46480\n","46481\n","46482\n","46483\n","46484\n","46485\n","46486\n","46487\n","46488\n","46489\n","46490\n","46491\n","46492\n","46493\n","46494\n","46495\n","46496\n","46497\n","46498\n","46499\n","46500\n","46501\n","46502\n","46503\n","46504\n","46505\n","46506\n","46507\n","46508\n","46509\n","46510\n","46511\n","46512\n","46513\n","46514\n","46515\n","46516\n","46517\n","46518\n","46519\n","46520\n","46521\n","46522\n","46523\n","46524\n","46525\n","46526\n","46527\n","46528\n","46529\n","46530\n","46531\n","46532\n","46533\n","46534\n","46535\n","46536\n","46537\n","46538\n","46539\n","46540\n","46541\n","46542\n","46543\n","46544\n","46545\n","46546\n","46547\n","46548\n","46549\n","46550\n","46551\n","46552\n","46553\n","46554\n","46555\n","46556\n","46557\n","46558\n","46559\n","46560\n","46561\n","46562\n","46563\n","46564\n","46565\n","46566\n","46567\n","46568\n","46569\n","46570\n","46571\n","46572\n","46573\n","46574\n","46575\n","46576\n","46577\n","46578\n","46579\n","46580\n","46581\n","46582\n","46583\n","46584\n","46585\n","46586\n","46587\n","46588\n","46589\n","46590\n","46591\n","46592\n","46593\n","46594\n","46595\n","46596\n","46597\n","46598\n","46599\n","46600\n","46601\n","46602\n","46603\n","46604\n","46605\n","46606\n","46607\n","46608\n","46609\n","46610\n","46611\n","46612\n","46613\n","46614\n","46615\n","46616\n","46617\n","46618\n","46619\n","46620\n","46621\n","46622\n","46623\n","46624\n","46625\n","46626\n","46627\n","46628\n","46629\n","46630\n","46631\n","46632\n","46633\n","46634\n","46635\n","46636\n","46637\n","46638\n","46639\n","46640\n","46641\n","46642\n","46643\n","46644\n","46645\n","46646\n","46647\n","46648\n","46649\n","46650\n","46651\n","46652\n","46653\n","46654\n","46655\n","46656\n","46657\n","46658\n","46659\n","46660\n","46661\n","46662\n","46663\n","46664\n","46665\n","46666\n","46667\n","46668\n","46669\n","46670\n","46671\n","46672\n","46673\n","46674\n","46675\n","46676\n","46677\n","46678\n","46679\n","46680\n","46681\n","46682\n","46683\n","46684\n","46685\n","46686\n","46687\n","46688\n","46689\n","46690\n","46691\n","46692\n","46693\n","46694\n","46695\n","46696\n","46697\n","46698\n","46699\n","46700\n","46701\n","46702\n","46703\n","46704\n","46705\n","46706\n","46707\n","46708\n","46709\n","46710\n","46711\n","46712\n","46713\n","46714\n","46715\n","46716\n","46717\n","46718\n","46719\n","46720\n","46721\n","46722\n","46723\n","46724\n","46725\n","46726\n","46727\n","46728\n","46729\n","46730\n","46731\n","46732\n","46733\n","46734\n","46735\n","46736\n","46737\n","46738\n","46739\n","46740\n","46741\n","46742\n","46743\n","46744\n","46745\n","46746\n","46747\n","46748\n","46749\n","46750\n","46751\n","46752\n","46753\n","46754\n","46755\n","46756\n","46757\n","46758\n","46759\n","46760\n","46761\n","46762\n","46763\n","46764\n","46765\n","46766\n","46767\n","46768\n","46769\n","46770\n","46771\n","46772\n","46773\n","46774\n","46775\n","46776\n","46777\n","46778\n","46779\n","46780\n","46781\n","46782\n","46783\n","46784\n","46785\n","46786\n","46787\n","46788\n","46789\n","46790\n","46791\n","46792\n","46793\n","46794\n","46795\n","46796\n","46797\n","46798\n","46799\n","46800\n","46801\n","46802\n","46803\n","46804\n","46805\n","46806\n","46807\n","46808\n","46809\n","46810\n","46811\n","46812\n","46813\n","46814\n","46815\n","46816\n","46817\n","46818\n","46819\n","46820\n","46821\n","46822\n","46823\n","46824\n","46825\n","46826\n","46827\n","46828\n","46829\n","46830\n","46831\n","46832\n","46833\n","46834\n","46835\n","46836\n","46837\n","46838\n","46839\n","46840\n","46841\n","46842\n","46843\n","46844\n","46845\n","46846\n","46847\n","46848\n","46849\n","46850\n","46851\n","46852\n","46853\n","46854\n","46855\n","46856\n","46857\n","46858\n","46859\n","46860\n","46861\n","46862\n","46863\n","46864\n","46865\n","46866\n","46867\n","46868\n","46869\n","46870\n","46871\n","46872\n","46873\n","46874\n","46875\n","46876\n","46877\n","46878\n","46879\n","46880\n","46881\n","46882\n","46883\n","46884\n","46885\n","46886\n","46887\n","46888\n","46889\n","46890\n","46891\n","46892\n","46893\n","46894\n","46895\n","46896\n","46897\n","46898\n","46899\n","46900\n","46901\n","46902\n","46903\n","46904\n","46905\n","46906\n","46907\n","46908\n","46909\n","46910\n","46911\n","46912\n","46913\n","46914\n","46915\n","46916\n","46917\n","46918\n","46919\n","46920\n","46921\n","46922\n","46923\n","46924\n","46925\n","46926\n","46927\n","46928\n","46929\n","46930\n","46931\n","46932\n","46933\n","46934\n","46935\n","46936\n","46937\n","46938\n","46939\n","46940\n","46941\n","46942\n","46943\n","46944\n","46945\n","46946\n","46947\n","46948\n","46949\n","46950\n","46951\n","46952\n","46953\n","46954\n","46955\n","46956\n","46957\n","46958\n","46959\n","46960\n","46961\n","46962\n","46963\n","46964\n","46965\n","46966\n","46967\n","46968\n","46969\n","46970\n","46971\n","46972\n","46973\n","46974\n","46975\n","46976\n","46977\n","46978\n","46979\n","46980\n","46981\n","46982\n","46983\n","46984\n","46985\n","46986\n","46987\n","46988\n","46989\n","46990\n","46991\n","46992\n","46993\n","46994\n","46995\n","46996\n","46997\n","46998\n","46999\n","47000\n","47001\n","47002\n","47003\n","47004\n","47005\n","47006\n","47007\n","47008\n","47009\n","47010\n","47011\n","47012\n","47013\n","47014\n","47015\n","47016\n","47017\n","47018\n","47019\n","47020\n","47021\n","47022\n","47023\n","47024\n","47025\n","47026\n","47027\n","47028\n","47029\n","47030\n","47031\n","47032\n","47033\n","47034\n","47035\n","47036\n","47037\n","47038\n","47039\n","47040\n","47041\n","47042\n","47043\n","47044\n","47045\n","47046\n","47047\n","47048\n","47049\n","47050\n","47051\n","47052\n","47053\n","47054\n","47055\n","47056\n","47057\n","47058\n","47059\n","47060\n","47061\n","47062\n","47063\n","47064\n","47065\n","47066\n","47067\n","47068\n","47069\n","47070\n","47071\n","47072\n","47073\n","47074\n","47075\n","47076\n","47077\n","47078\n","47079\n","47080\n","47081\n","47082\n","47083\n","47084\n","47085\n","47086\n","47087\n","47088\n","47089\n","47090\n","47091\n","47092\n","47093\n","47094\n","47095\n","47096\n","47097\n","47098\n","47099\n","47100\n","47101\n","47102\n","47103\n","47104\n","47105\n","47106\n","47107\n","47108\n","47109\n","47110\n","47111\n","47112\n","47113\n","47114\n","47115\n","47116\n","47117\n","47118\n","47119\n","47120\n","47121\n","47122\n","47123\n","47124\n","47125\n","47126\n","47127\n","47128\n","47129\n","47130\n","47131\n","47132\n","47133\n","47134\n","47135\n","47136\n","47137\n","47138\n","47139\n","47140\n","47141\n","47142\n","47143\n","47144\n","47145\n","47146\n","47147\n","47148\n","47149\n","47150\n","47151\n","47152\n","47153\n","47154\n","47155\n","47156\n","47157\n","47158\n","47159\n","47160\n","47161\n","47162\n","47163\n","47164\n","47165\n","47166\n","47167\n","47168\n","47169\n","47170\n","47171\n","47172\n","47173\n","47174\n","47175\n","47176\n","47177\n","47178\n","47179\n","47180\n","47181\n","47182\n","47183\n","47184\n","47185\n","47186\n","47187\n","47188\n","47189\n","47190\n","47191\n","47192\n","47193\n","47194\n","47195\n","47196\n","47197\n","47198\n","47199\n","47200\n","47201\n","47202\n","47203\n","47204\n","47205\n","47206\n","47207\n","47208\n","47209\n","47210\n","47211\n","47212\n","47213\n","47214\n","47215\n","47216\n","47217\n","47218\n","47219\n","47220\n","47221\n","47222\n","47223\n","47224\n","47225\n","47226\n","47227\n","47228\n","47229\n","47230\n","47231\n","47232\n","47233\n","47234\n","47235\n","47236\n","47237\n","47238\n","47239\n","47240\n","47241\n","47242\n","47243\n","47244\n","47245\n","47246\n","47247\n","47248\n","47249\n","47250\n","47251\n","47252\n","47253\n","47254\n","47255\n","47256\n","47257\n","47258\n","47259\n","47260\n","47261\n","47262\n","47263\n","47264\n","47265\n","47266\n","47267\n","47268\n","47269\n","47270\n","47271\n","47272\n","47273\n","47274\n","47275\n","47276\n","47277\n","47278\n","47279\n","47280\n","47281\n","47282\n","47283\n","47284\n","47285\n","47286\n","47287\n","47288\n","47289\n","47290\n","47291\n","47292\n","47293\n","47294\n","47295\n","47296\n","47297\n","47298\n","47299\n","47300\n","47301\n","47302\n","47303\n","47304\n","47305\n","47306\n","47307\n","47308\n","47309\n","47310\n","47311\n","47312\n","47313\n","47314\n","47315\n","47316\n","47317\n","47318\n","47319\n","47320\n","47321\n","47322\n","47323\n","47324\n","47325\n","47326\n","47327\n","47328\n","47329\n","47330\n","47331\n","47332\n","47333\n","47334\n","47335\n","47336\n","47337\n","47338\n","47339\n","47340\n","47341\n","47342\n","47343\n","47344\n","47345\n","47346\n","47347\n","47348\n","47349\n","47350\n","47351\n","47352\n","47353\n","47354\n","47355\n","47356\n","47357\n","47358\n","47359\n","47360\n","47361\n","47362\n","47363\n","47364\n","47365\n","47366\n","47367\n","47368\n","47369\n","47370\n","47371\n","47372\n","47373\n","47374\n","47375\n","47376\n","47377\n","47378\n","47379\n","47380\n","47381\n","47382\n","47383\n","47384\n","47385\n","47386\n","47387\n","47388\n","47389\n","47390\n","47391\n","47392\n","47393\n","47394\n","47395\n","47396\n","47397\n","47398\n","47399\n","47400\n","47401\n","47402\n","47403\n","47404\n","47405\n","47406\n","47407\n","47408\n","47409\n","47410\n","47411\n","47412\n","47413\n","47414\n","47415\n","47416\n","47417\n","47418\n","47419\n","47420\n","47421\n","47422\n","47423\n","47424\n","47425\n","47426\n","47427\n","47428\n","47429\n","47430\n","47431\n","47432\n","47433\n","47434\n","47435\n","47436\n","47437\n","47438\n","47439\n","47440\n","47441\n","47442\n","47443\n","47444\n","47445\n","47446\n","47447\n","47448\n","47449\n","47450\n","47451\n","47452\n","47453\n","47454\n","47455\n","47456\n","47457\n","47458\n","47459\n","47460\n","47461\n","47462\n","47463\n","47464\n","47465\n","47466\n","47467\n","47468\n","47469\n","47470\n","47471\n","47472\n","47473\n","47474\n","47475\n","47476\n","47477\n","47478\n","47479\n","47480\n","47481\n","47482\n","47483\n","47484\n","47485\n","47486\n","47487\n","47488\n","47489\n","47490\n","47491\n","47492\n","47493\n","47494\n","47495\n","47496\n","47497\n","47498\n","47499\n","47500\n","47501\n","47502\n","47503\n","47504\n","47505\n","47506\n","47507\n","47508\n","47509\n","47510\n","47511\n","47512\n","47513\n","47514\n","47515\n","47516\n","47517\n","47518\n","47519\n","47520\n","47521\n","47522\n","47523\n","47524\n","47525\n","47526\n","47527\n","47528\n","47529\n","47530\n","47531\n","47532\n","47533\n","47534\n","47535\n","47536\n","47537\n","47538\n","47539\n","47540\n","47541\n","47542\n","47543\n","47544\n","47545\n","47546\n","47547\n","47548\n","47549\n","47550\n","47551\n","47552\n","47553\n","47554\n","47555\n","47556\n","47557\n","47558\n","47559\n","47560\n","47561\n","47562\n","47563\n","47564\n","47565\n","47566\n","47567\n","47568\n","47569\n","47570\n","47571\n","47572\n","47573\n","47574\n","47575\n","47576\n","47577\n","47578\n","47579\n","47580\n","47581\n","47582\n","47583\n","47584\n","47585\n","47586\n","47587\n","47588\n","47589\n","47590\n","47591\n","47592\n","47593\n","47594\n","47595\n","47596\n","47597\n","47598\n","47599\n","47600\n","47601\n","47602\n","47603\n","47604\n","47605\n","47606\n","47607\n","47608\n","47609\n","47610\n","47611\n","47612\n","47613\n","47614\n","47615\n","47616\n","47617\n","47618\n","47619\n","47620\n","47621\n","47622\n","47623\n","47624\n","47625\n","47626\n","47627\n","47628\n","47629\n","47630\n","47631\n","47632\n","47633\n","47634\n","47635\n","47636\n","47637\n","47638\n","47639\n","47640\n","47641\n","47642\n","47643\n","47644\n","47645\n","47646\n","47647\n","47648\n","47649\n","47650\n","47651\n","47652\n","47653\n","47654\n","47655\n","47656\n","47657\n","47658\n","47659\n","47660\n","47661\n","47662\n","47663\n","47664\n","47665\n","47666\n","47667\n","47668\n","47669\n","47670\n","47671\n","47672\n","47673\n","47674\n","47675\n","47676\n","47677\n","47678\n","47679\n","47680\n","47681\n","47682\n","47683\n","47684\n","47685\n","47686\n","47687\n","47688\n","47689\n","47690\n","47691\n"]}]},{"cell_type":"code","source":["import tensorflow\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, LSTM, Embedding, Bidirectional\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","max_words = 10000\n","max_len = 100\n","tokenizer = Tokenizer(num_words=max_words)\n","tokenizer.fit_on_texts(rnncorpus)\n","sequences = tokenizer.texts_to_sequences(rnncorpus)\n","word_index = tokenizer.word_index\n","rnndata_sequence = pad_sequences(sequences, maxlen=max_len)"],"metadata":{"id":"DP6gJSRWYHCf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","model.add(Embedding(max_words, 100, input_length=max_len))\n","model.add(Bidirectional(LSTM(64, recurrent_dropout=0.2)))\n","model.add(Dense(1, activation='sigmoid'))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TFDE7zc1aePY","executionInfo":{"status":"ok","timestamp":1681538732307,"user_tz":-330,"elapsed":868,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"03bf22cb-d319-4ed0-f96a-0afc8351f00b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]}]},{"cell_type":"code","source":["model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"],"metadata":{"id":"zp-fFjCFbL4S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rnndata['cyberbullying_type'] = rnndata['cyberbullying_type'].apply(lambda x: 0 if x=='not_cyberbullying' else 1)\n","print(rnndata.head(2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ogyhs9RybQSq","executionInfo":{"status":"ok","timestamp":1681538745161,"user_tz":-330,"elapsed":604,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"7c623b01-ac5b-4a0c-85a0-491d0905ba04"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                          tweet_text  cyberbullying_type\n","0  In other words #katandandre, your food was cra...                   0\n","1  Why is #aussietv so white? #MKR #theblock #ImA...                   0\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","rnnXtrain,rnnXtest,rnnYtrain,rnnYtest = train_test_split(rnndata_sequence,rnndata['cyberbullying_type'],test_size=0.2,random_state=42)\n","rnnXtrain,rnnXval,rnnYtrain,rnnYval = train_test_split(rnnXtrain,rnnYtrain,test_size=0.2,random_state=42)"],"metadata":{"id":"8ch41BB9cB2i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["early_stop = EarlyStopping(monitor='val_loss', patience=3)\n","history = model.fit(rnnXtrain, rnnYtrain, epochs=10, batch_size=512, validation_data=(rnnXval, rnnYval), callbacks=[early_stop])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p36gjcitdSjI","executionInfo":{"status":"ok","timestamp":1681541589273,"user_tz":-330,"elapsed":189216,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"7dc94d31-d5fd-46df-c47a-72fb2c0d21e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","60/60 [==============================] - 48s 805ms/step - loss: 0.0910 - accuracy: 0.9538 - val_loss: 0.6265 - val_accuracy: 0.8500\n","Epoch 2/10\n","60/60 [==============================] - 45s 752ms/step - loss: 0.0848 - accuracy: 0.9555 - val_loss: 0.6685 - val_accuracy: 0.8506\n","Epoch 3/10\n","60/60 [==============================] - 47s 783ms/step - loss: 0.0805 - accuracy: 0.9569 - val_loss: 0.7181 - val_accuracy: 0.8505\n","Epoch 4/10\n","60/60 [==============================] - 49s 801ms/step - loss: 0.0780 - accuracy: 0.9583 - val_loss: 0.7367 - val_accuracy: 0.8459\n"]}]},{"cell_type":"code","source":["test_loss, test_acc = model.evaluate(rnnXtest,rnnYtest)\n","print('Test accuracy:', test_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xtfIv1e6dgXX","executionInfo":{"status":"ok","timestamp":1681541683687,"user_tz":-330,"elapsed":76170,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"00b3efad-0d87-4f4a-b876-bf379df491ee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["299/299 [==============================] - 18s 59ms/step - loss: 0.7903 - accuracy: 0.8378\n","Test accuracy: 0.8378236889839172\n"]}]},{"cell_type":"code","source":["#Rnn multiclassification\n"],"metadata":{"id":"D18ADmHndTqY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rnnmultidata = pd.read_csv('./cyberbullying_tweets.csv',encoding='ISO-8859-1')\n","rnnmultidata.head(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"id":"l-ltLz1Vs12e","executionInfo":{"status":"ok","timestamp":1681542718029,"user_tz":-330,"elapsed":1929,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"cbfb0f08-2b5f-4f98-f4c4-3b63252d399f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                          tweet_text cyberbullying_type\n","0  In other words #katandandre, your food was cra...  not_cyberbullying\n","1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying"],"text/html":["\n","  <div id=\"df-66f9e06a-c985-4e1b-b73a-c77813376605\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet_text</th>\n","      <th>cyberbullying_type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>In other words #katandandre, your food was cra...</td>\n","      <td>not_cyberbullying</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n","      <td>not_cyberbullying</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66f9e06a-c985-4e1b-b73a-c77813376605')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-66f9e06a-c985-4e1b-b73a-c77813376605 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-66f9e06a-c985-4e1b-b73a-c77813376605');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["#rnnmultidata['cyberbullying_type'] = rnnmultidata['cyberbullying_type'].replace({'not_cyberbullying':0,'gender':1,'religion':2,'age':3,'ethnicity':4,'other_cyberbullying':5})\n","rnnmultidata.head(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"id":"kuyCd3fctYk8","executionInfo":{"status":"ok","timestamp":1681542727642,"user_tz":-330,"elapsed":1891,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"5e1b9d70-bd58-487f-d3a9-ccdddbe358c7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                          tweet_text cyberbullying_type\n","0  In other words #katandandre, your food was cra...  not_cyberbullying\n","1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying"],"text/html":["\n","  <div id=\"df-b8d09c30-695b-455c-8c6f-c8e2f86c9ac8\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet_text</th>\n","      <th>cyberbullying_type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>In other words #katandandre, your food was cra...</td>\n","      <td>not_cyberbullying</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n","      <td>not_cyberbullying</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8d09c30-695b-455c-8c6f-c8e2f86c9ac8')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b8d09c30-695b-455c-8c6f-c8e2f86c9ac8 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b8d09c30-695b-455c-8c6f-c8e2f86c9ac8');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["rnnmulticorpus = data_clean(rnnmultidata['tweet_text'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HaITr32EtthM","executionInfo":{"status":"ok","timestamp":1681542226136,"user_tz":-330,"elapsed":164172,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"bcaa85b2-9956-4637-b9e9-a00fb004f489"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","42692\n","42693\n","42694\n","42695\n","42696\n","42697\n","42698\n","42699\n","42700\n","42701\n","42702\n","42703\n","42704\n","42705\n","42706\n","42707\n","42708\n","42709\n","42710\n","42711\n","42712\n","42713\n","42714\n","42715\n","42716\n","42717\n","42718\n","42719\n","42720\n","42721\n","42722\n","42723\n","42724\n","42725\n","42726\n","42727\n","42728\n","42729\n","42730\n","42731\n","42732\n","42733\n","42734\n","42735\n","42736\n","42737\n","42738\n","42739\n","42740\n","42741\n","42742\n","42743\n","42744\n","42745\n","42746\n","42747\n","42748\n","42749\n","42750\n","42751\n","42752\n","42753\n","42754\n","42755\n","42756\n","42757\n","42758\n","42759\n","42760\n","42761\n","42762\n","42763\n","42764\n","42765\n","42766\n","42767\n","42768\n","42769\n","42770\n","42771\n","42772\n","42773\n","42774\n","42775\n","42776\n","42777\n","42778\n","42779\n","42780\n","42781\n","42782\n","42783\n","42784\n","42785\n","42786\n","42787\n","42788\n","42789\n","42790\n","42791\n","42792\n","42793\n","42794\n","42795\n","42796\n","42797\n","42798\n","42799\n","42800\n","42801\n","42802\n","42803\n","42804\n","42805\n","42806\n","42807\n","42808\n","42809\n","42810\n","42811\n","42812\n","42813\n","42814\n","42815\n","42816\n","42817\n","42818\n","42819\n","42820\n","42821\n","42822\n","42823\n","42824\n","42825\n","42826\n","42827\n","42828\n","42829\n","42830\n","42831\n","42832\n","42833\n","42834\n","42835\n","42836\n","42837\n","42838\n","42839\n","42840\n","42841\n","42842\n","42843\n","42844\n","42845\n","42846\n","42847\n","42848\n","42849\n","42850\n","42851\n","42852\n","42853\n","42854\n","42855\n","42856\n","42857\n","42858\n","42859\n","42860\n","42861\n","42862\n","42863\n","42864\n","42865\n","42866\n","42867\n","42868\n","42869\n","42870\n","42871\n","42872\n","42873\n","42874\n","42875\n","42876\n","42877\n","42878\n","42879\n","42880\n","42881\n","42882\n","42883\n","42884\n","42885\n","42886\n","42887\n","42888\n","42889\n","42890\n","42891\n","42892\n","42893\n","42894\n","42895\n","42896\n","42897\n","42898\n","42899\n","42900\n","42901\n","42902\n","42903\n","42904\n","42905\n","42906\n","42907\n","42908\n","42909\n","42910\n","42911\n","42912\n","42913\n","42914\n","42915\n","42916\n","42917\n","42918\n","42919\n","42920\n","42921\n","42922\n","42923\n","42924\n","42925\n","42926\n","42927\n","42928\n","42929\n","42930\n","42931\n","42932\n","42933\n","42934\n","42935\n","42936\n","42937\n","42938\n","42939\n","42940\n","42941\n","42942\n","42943\n","42944\n","42945\n","42946\n","42947\n","42948\n","42949\n","42950\n","42951\n","42952\n","42953\n","42954\n","42955\n","42956\n","42957\n","42958\n","42959\n","42960\n","42961\n","42962\n","42963\n","42964\n","42965\n","42966\n","42967\n","42968\n","42969\n","42970\n","42971\n","42972\n","42973\n","42974\n","42975\n","42976\n","42977\n","42978\n","42979\n","42980\n","42981\n","42982\n","42983\n","42984\n","42985\n","42986\n","42987\n","42988\n","42989\n","42990\n","42991\n","42992\n","42993\n","42994\n","42995\n","42996\n","42997\n","42998\n","42999\n","43000\n","43001\n","43002\n","43003\n","43004\n","43005\n","43006\n","43007\n","43008\n","43009\n","43010\n","43011\n","43012\n","43013\n","43014\n","43015\n","43016\n","43017\n","43018\n","43019\n","43020\n","43021\n","43022\n","43023\n","43024\n","43025\n","43026\n","43027\n","43028\n","43029\n","43030\n","43031\n","43032\n","43033\n","43034\n","43035\n","43036\n","43037\n","43038\n","43039\n","43040\n","43041\n","43042\n","43043\n","43044\n","43045\n","43046\n","43047\n","43048\n","43049\n","43050\n","43051\n","43052\n","43053\n","43054\n","43055\n","43056\n","43057\n","43058\n","43059\n","43060\n","43061\n","43062\n","43063\n","43064\n","43065\n","43066\n","43067\n","43068\n","43069\n","43070\n","43071\n","43072\n","43073\n","43074\n","43075\n","43076\n","43077\n","43078\n","43079\n","43080\n","43081\n","43082\n","43083\n","43084\n","43085\n","43086\n","43087\n","43088\n","43089\n","43090\n","43091\n","43092\n","43093\n","43094\n","43095\n","43096\n","43097\n","43098\n","43099\n","43100\n","43101\n","43102\n","43103\n","43104\n","43105\n","43106\n","43107\n","43108\n","43109\n","43110\n","43111\n","43112\n","43113\n","43114\n","43115\n","43116\n","43117\n","43118\n","43119\n","43120\n","43121\n","43122\n","43123\n","43124\n","43125\n","43126\n","43127\n","43128\n","43129\n","43130\n","43131\n","43132\n","43133\n","43134\n","43135\n","43136\n","43137\n","43138\n","43139\n","43140\n","43141\n","43142\n","43143\n","43144\n","43145\n","43146\n","43147\n","43148\n","43149\n","43150\n","43151\n","43152\n","43153\n","43154\n","43155\n","43156\n","43157\n","43158\n","43159\n","43160\n","43161\n","43162\n","43163\n","43164\n","43165\n","43166\n","43167\n","43168\n","43169\n","43170\n","43171\n","43172\n","43173\n","43174\n","43175\n","43176\n","43177\n","43178\n","43179\n","43180\n","43181\n","43182\n","43183\n","43184\n","43185\n","43186\n","43187\n","43188\n","43189\n","43190\n","43191\n","43192\n","43193\n","43194\n","43195\n","43196\n","43197\n","43198\n","43199\n","43200\n","43201\n","43202\n","43203\n","43204\n","43205\n","43206\n","43207\n","43208\n","43209\n","43210\n","43211\n","43212\n","43213\n","43214\n","43215\n","43216\n","43217\n","43218\n","43219\n","43220\n","43221\n","43222\n","43223\n","43224\n","43225\n","43226\n","43227\n","43228\n","43229\n","43230\n","43231\n","43232\n","43233\n","43234\n","43235\n","43236\n","43237\n","43238\n","43239\n","43240\n","43241\n","43242\n","43243\n","43244\n","43245\n","43246\n","43247\n","43248\n","43249\n","43250\n","43251\n","43252\n","43253\n","43254\n","43255\n","43256\n","43257\n","43258\n","43259\n","43260\n","43261\n","43262\n","43263\n","43264\n","43265\n","43266\n","43267\n","43268\n","43269\n","43270\n","43271\n","43272\n","43273\n","43274\n","43275\n","43276\n","43277\n","43278\n","43279\n","43280\n","43281\n","43282\n","43283\n","43284\n","43285\n","43286\n","43287\n","43288\n","43289\n","43290\n","43291\n","43292\n","43293\n","43294\n","43295\n","43296\n","43297\n","43298\n","43299\n","43300\n","43301\n","43302\n","43303\n","43304\n","43305\n","43306\n","43307\n","43308\n","43309\n","43310\n","43311\n","43312\n","43313\n","43314\n","43315\n","43316\n","43317\n","43318\n","43319\n","43320\n","43321\n","43322\n","43323\n","43324\n","43325\n","43326\n","43327\n","43328\n","43329\n","43330\n","43331\n","43332\n","43333\n","43334\n","43335\n","43336\n","43337\n","43338\n","43339\n","43340\n","43341\n","43342\n","43343\n","43344\n","43345\n","43346\n","43347\n","43348\n","43349\n","43350\n","43351\n","43352\n","43353\n","43354\n","43355\n","43356\n","43357\n","43358\n","43359\n","43360\n","43361\n","43362\n","43363\n","43364\n","43365\n","43366\n","43367\n","43368\n","43369\n","43370\n","43371\n","43372\n","43373\n","43374\n","43375\n","43376\n","43377\n","43378\n","43379\n","43380\n","43381\n","43382\n","43383\n","43384\n","43385\n","43386\n","43387\n","43388\n","43389\n","43390\n","43391\n","43392\n","43393\n","43394\n","43395\n","43396\n","43397\n","43398\n","43399\n","43400\n","43401\n","43402\n","43403\n","43404\n","43405\n","43406\n","43407\n","43408\n","43409\n","43410\n","43411\n","43412\n","43413\n","43414\n","43415\n","43416\n","43417\n","43418\n","43419\n","43420\n","43421\n","43422\n","43423\n","43424\n","43425\n","43426\n","43427\n","43428\n","43429\n","43430\n","43431\n","43432\n","43433\n","43434\n","43435\n","43436\n","43437\n","43438\n","43439\n","43440\n","43441\n","43442\n","43443\n","43444\n","43445\n","43446\n","43447\n","43448\n","43449\n","43450\n","43451\n","43452\n","43453\n","43454\n","43455\n","43456\n","43457\n","43458\n","43459\n","43460\n","43461\n","43462\n","43463\n","43464\n","43465\n","43466\n","43467\n","43468\n","43469\n","43470\n","43471\n","43472\n","43473\n","43474\n","43475\n","43476\n","43477\n","43478\n","43479\n","43480\n","43481\n","43482\n","43483\n","43484\n","43485\n","43486\n","43487\n","43488\n","43489\n","43490\n","43491\n","43492\n","43493\n","43494\n","43495\n","43496\n","43497\n","43498\n","43499\n","43500\n","43501\n","43502\n","43503\n","43504\n","43505\n","43506\n","43507\n","43508\n","43509\n","43510\n","43511\n","43512\n","43513\n","43514\n","43515\n","43516\n","43517\n","43518\n","43519\n","43520\n","43521\n","43522\n","43523\n","43524\n","43525\n","43526\n","43527\n","43528\n","43529\n","43530\n","43531\n","43532\n","43533\n","43534\n","43535\n","43536\n","43537\n","43538\n","43539\n","43540\n","43541\n","43542\n","43543\n","43544\n","43545\n","43546\n","43547\n","43548\n","43549\n","43550\n","43551\n","43552\n","43553\n","43554\n","43555\n","43556\n","43557\n","43558\n","43559\n","43560\n","43561\n","43562\n","43563\n","43564\n","43565\n","43566\n","43567\n","43568\n","43569\n","43570\n","43571\n","43572\n","43573\n","43574\n","43575\n","43576\n","43577\n","43578\n","43579\n","43580\n","43581\n","43582\n","43583\n","43584\n","43585\n","43586\n","43587\n","43588\n","43589\n","43590\n","43591\n","43592\n","43593\n","43594\n","43595\n","43596\n","43597\n","43598\n","43599\n","43600\n","43601\n","43602\n","43603\n","43604\n","43605\n","43606\n","43607\n","43608\n","43609\n","43610\n","43611\n","43612\n","43613\n","43614\n","43615\n","43616\n","43617\n","43618\n","43619\n","43620\n","43621\n","43622\n","43623\n","43624\n","43625\n","43626\n","43627\n","43628\n","43629\n","43630\n","43631\n","43632\n","43633\n","43634\n","43635\n","43636\n","43637\n","43638\n","43639\n","43640\n","43641\n","43642\n","43643\n","43644\n","43645\n","43646\n","43647\n","43648\n","43649\n","43650\n","43651\n","43652\n","43653\n","43654\n","43655\n","43656\n","43657\n","43658\n","43659\n","43660\n","43661\n","43662\n","43663\n","43664\n","43665\n","43666\n","43667\n","43668\n","43669\n","43670\n","43671\n","43672\n","43673\n","43674\n","43675\n","43676\n","43677\n","43678\n","43679\n","43680\n","43681\n","43682\n","43683\n","43684\n","43685\n","43686\n","43687\n","43688\n","43689\n","43690\n","43691\n","43692\n","43693\n","43694\n","43695\n","43696\n","43697\n","43698\n","43699\n","43700\n","43701\n","43702\n","43703\n","43704\n","43705\n","43706\n","43707\n","43708\n","43709\n","43710\n","43711\n","43712\n","43713\n","43714\n","43715\n","43716\n","43717\n","43718\n","43719\n","43720\n","43721\n","43722\n","43723\n","43724\n","43725\n","43726\n","43727\n","43728\n","43729\n","43730\n","43731\n","43732\n","43733\n","43734\n","43735\n","43736\n","43737\n","43738\n","43739\n","43740\n","43741\n","43742\n","43743\n","43744\n","43745\n","43746\n","43747\n","43748\n","43749\n","43750\n","43751\n","43752\n","43753\n","43754\n","43755\n","43756\n","43757\n","43758\n","43759\n","43760\n","43761\n","43762\n","43763\n","43764\n","43765\n","43766\n","43767\n","43768\n","43769\n","43770\n","43771\n","43772\n","43773\n","43774\n","43775\n","43776\n","43777\n","43778\n","43779\n","43780\n","43781\n","43782\n","43783\n","43784\n","43785\n","43786\n","43787\n","43788\n","43789\n","43790\n","43791\n","43792\n","43793\n","43794\n","43795\n","43796\n","43797\n","43798\n","43799\n","43800\n","43801\n","43802\n","43803\n","43804\n","43805\n","43806\n","43807\n","43808\n","43809\n","43810\n","43811\n","43812\n","43813\n","43814\n","43815\n","43816\n","43817\n","43818\n","43819\n","43820\n","43821\n","43822\n","43823\n","43824\n","43825\n","43826\n","43827\n","43828\n","43829\n","43830\n","43831\n","43832\n","43833\n","43834\n","43835\n","43836\n","43837\n","43838\n","43839\n","43840\n","43841\n","43842\n","43843\n","43844\n","43845\n","43846\n","43847\n","43848\n","43849\n","43850\n","43851\n","43852\n","43853\n","43854\n","43855\n","43856\n","43857\n","43858\n","43859\n","43860\n","43861\n","43862\n","43863\n","43864\n","43865\n","43866\n","43867\n","43868\n","43869\n","43870\n","43871\n","43872\n","43873\n","43874\n","43875\n","43876\n","43877\n","43878\n","43879\n","43880\n","43881\n","43882\n","43883\n","43884\n","43885\n","43886\n","43887\n","43888\n","43889\n","43890\n","43891\n","43892\n","43893\n","43894\n","43895\n","43896\n","43897\n","43898\n","43899\n","43900\n","43901\n","43902\n","43903\n","43904\n","43905\n","43906\n","43907\n","43908\n","43909\n","43910\n","43911\n","43912\n","43913\n","43914\n","43915\n","43916\n","43917\n","43918\n","43919\n","43920\n","43921\n","43922\n","43923\n","43924\n","43925\n","43926\n","43927\n","43928\n","43929\n","43930\n","43931\n","43932\n","43933\n","43934\n","43935\n","43936\n","43937\n","43938\n","43939\n","43940\n","43941\n","43942\n","43943\n","43944\n","43945\n","43946\n","43947\n","43948\n","43949\n","43950\n","43951\n","43952\n","43953\n","43954\n","43955\n","43956\n","43957\n","43958\n","43959\n","43960\n","43961\n","43962\n","43963\n","43964\n","43965\n","43966\n","43967\n","43968\n","43969\n","43970\n","43971\n","43972\n","43973\n","43974\n","43975\n","43976\n","43977\n","43978\n","43979\n","43980\n","43981\n","43982\n","43983\n","43984\n","43985\n","43986\n","43987\n","43988\n","43989\n","43990\n","43991\n","43992\n","43993\n","43994\n","43995\n","43996\n","43997\n","43998\n","43999\n","44000\n","44001\n","44002\n","44003\n","44004\n","44005\n","44006\n","44007\n","44008\n","44009\n","44010\n","44011\n","44012\n","44013\n","44014\n","44015\n","44016\n","44017\n","44018\n","44019\n","44020\n","44021\n","44022\n","44023\n","44024\n","44025\n","44026\n","44027\n","44028\n","44029\n","44030\n","44031\n","44032\n","44033\n","44034\n","44035\n","44036\n","44037\n","44038\n","44039\n","44040\n","44041\n","44042\n","44043\n","44044\n","44045\n","44046\n","44047\n","44048\n","44049\n","44050\n","44051\n","44052\n","44053\n","44054\n","44055\n","44056\n","44057\n","44058\n","44059\n","44060\n","44061\n","44062\n","44063\n","44064\n","44065\n","44066\n","44067\n","44068\n","44069\n","44070\n","44071\n","44072\n","44073\n","44074\n","44075\n","44076\n","44077\n","44078\n","44079\n","44080\n","44081\n","44082\n","44083\n","44084\n","44085\n","44086\n","44087\n","44088\n","44089\n","44090\n","44091\n","44092\n","44093\n","44094\n","44095\n","44096\n","44097\n","44098\n","44099\n","44100\n","44101\n","44102\n","44103\n","44104\n","44105\n","44106\n","44107\n","44108\n","44109\n","44110\n","44111\n","44112\n","44113\n","44114\n","44115\n","44116\n","44117\n","44118\n","44119\n","44120\n","44121\n","44122\n","44123\n","44124\n","44125\n","44126\n","44127\n","44128\n","44129\n","44130\n","44131\n","44132\n","44133\n","44134\n","44135\n","44136\n","44137\n","44138\n","44139\n","44140\n","44141\n","44142\n","44143\n","44144\n","44145\n","44146\n","44147\n","44148\n","44149\n","44150\n","44151\n","44152\n","44153\n","44154\n","44155\n","44156\n","44157\n","44158\n","44159\n","44160\n","44161\n","44162\n","44163\n","44164\n","44165\n","44166\n","44167\n","44168\n","44169\n","44170\n","44171\n","44172\n","44173\n","44174\n","44175\n","44176\n","44177\n","44178\n","44179\n","44180\n","44181\n","44182\n","44183\n","44184\n","44185\n","44186\n","44187\n","44188\n","44189\n","44190\n","44191\n","44192\n","44193\n","44194\n","44195\n","44196\n","44197\n","44198\n","44199\n","44200\n","44201\n","44202\n","44203\n","44204\n","44205\n","44206\n","44207\n","44208\n","44209\n","44210\n","44211\n","44212\n","44213\n","44214\n","44215\n","44216\n","44217\n","44218\n","44219\n","44220\n","44221\n","44222\n","44223\n","44224\n","44225\n","44226\n","44227\n","44228\n","44229\n","44230\n","44231\n","44232\n","44233\n","44234\n","44235\n","44236\n","44237\n","44238\n","44239\n","44240\n","44241\n","44242\n","44243\n","44244\n","44245\n","44246\n","44247\n","44248\n","44249\n","44250\n","44251\n","44252\n","44253\n","44254\n","44255\n","44256\n","44257\n","44258\n","44259\n","44260\n","44261\n","44262\n","44263\n","44264\n","44265\n","44266\n","44267\n","44268\n","44269\n","44270\n","44271\n","44272\n","44273\n","44274\n","44275\n","44276\n","44277\n","44278\n","44279\n","44280\n","44281\n","44282\n","44283\n","44284\n","44285\n","44286\n","44287\n","44288\n","44289\n","44290\n","44291\n","44292\n","44293\n","44294\n","44295\n","44296\n","44297\n","44298\n","44299\n","44300\n","44301\n","44302\n","44303\n","44304\n","44305\n","44306\n","44307\n","44308\n","44309\n","44310\n","44311\n","44312\n","44313\n","44314\n","44315\n","44316\n","44317\n","44318\n","44319\n","44320\n","44321\n","44322\n","44323\n","44324\n","44325\n","44326\n","44327\n","44328\n","44329\n","44330\n","44331\n","44332\n","44333\n","44334\n","44335\n","44336\n","44337\n","44338\n","44339\n","44340\n","44341\n","44342\n","44343\n","44344\n","44345\n","44346\n","44347\n","44348\n","44349\n","44350\n","44351\n","44352\n","44353\n","44354\n","44355\n","44356\n","44357\n","44358\n","44359\n","44360\n","44361\n","44362\n","44363\n","44364\n","44365\n","44366\n","44367\n","44368\n","44369\n","44370\n","44371\n","44372\n","44373\n","44374\n","44375\n","44376\n","44377\n","44378\n","44379\n","44380\n","44381\n","44382\n","44383\n","44384\n","44385\n","44386\n","44387\n","44388\n","44389\n","44390\n","44391\n","44392\n","44393\n","44394\n","44395\n","44396\n","44397\n","44398\n","44399\n","44400\n","44401\n","44402\n","44403\n","44404\n","44405\n","44406\n","44407\n","44408\n","44409\n","44410\n","44411\n","44412\n","44413\n","44414\n","44415\n","44416\n","44417\n","44418\n","44419\n","44420\n","44421\n","44422\n","44423\n","44424\n","44425\n","44426\n","44427\n","44428\n","44429\n","44430\n","44431\n","44432\n","44433\n","44434\n","44435\n","44436\n","44437\n","44438\n","44439\n","44440\n","44441\n","44442\n","44443\n","44444\n","44445\n","44446\n","44447\n","44448\n","44449\n","44450\n","44451\n","44452\n","44453\n","44454\n","44455\n","44456\n","44457\n","44458\n","44459\n","44460\n","44461\n","44462\n","44463\n","44464\n","44465\n","44466\n","44467\n","44468\n","44469\n","44470\n","44471\n","44472\n","44473\n","44474\n","44475\n","44476\n","44477\n","44478\n","44479\n","44480\n","44481\n","44482\n","44483\n","44484\n","44485\n","44486\n","44487\n","44488\n","44489\n","44490\n","44491\n","44492\n","44493\n","44494\n","44495\n","44496\n","44497\n","44498\n","44499\n","44500\n","44501\n","44502\n","44503\n","44504\n","44505\n","44506\n","44507\n","44508\n","44509\n","44510\n","44511\n","44512\n","44513\n","44514\n","44515\n","44516\n","44517\n","44518\n","44519\n","44520\n","44521\n","44522\n","44523\n","44524\n","44525\n","44526\n","44527\n","44528\n","44529\n","44530\n","44531\n","44532\n","44533\n","44534\n","44535\n","44536\n","44537\n","44538\n","44539\n","44540\n","44541\n","44542\n","44543\n","44544\n","44545\n","44546\n","44547\n","44548\n","44549\n","44550\n","44551\n","44552\n","44553\n","44554\n","44555\n","44556\n","44557\n","44558\n","44559\n","44560\n","44561\n","44562\n","44563\n","44564\n","44565\n","44566\n","44567\n","44568\n","44569\n","44570\n","44571\n","44572\n","44573\n","44574\n","44575\n","44576\n","44577\n","44578\n","44579\n","44580\n","44581\n","44582\n","44583\n","44584\n","44585\n","44586\n","44587\n","44588\n","44589\n","44590\n","44591\n","44592\n","44593\n","44594\n","44595\n","44596\n","44597\n","44598\n","44599\n","44600\n","44601\n","44602\n","44603\n","44604\n","44605\n","44606\n","44607\n","44608\n","44609\n","44610\n","44611\n","44612\n","44613\n","44614\n","44615\n","44616\n","44617\n","44618\n","44619\n","44620\n","44621\n","44622\n","44623\n","44624\n","44625\n","44626\n","44627\n","44628\n","44629\n","44630\n","44631\n","44632\n","44633\n","44634\n","44635\n","44636\n","44637\n","44638\n","44639\n","44640\n","44641\n","44642\n","44643\n","44644\n","44645\n","44646\n","44647\n","44648\n","44649\n","44650\n","44651\n","44652\n","44653\n","44654\n","44655\n","44656\n","44657\n","44658\n","44659\n","44660\n","44661\n","44662\n","44663\n","44664\n","44665\n","44666\n","44667\n","44668\n","44669\n","44670\n","44671\n","44672\n","44673\n","44674\n","44675\n","44676\n","44677\n","44678\n","44679\n","44680\n","44681\n","44682\n","44683\n","44684\n","44685\n","44686\n","44687\n","44688\n","44689\n","44690\n","44691\n","44692\n","44693\n","44694\n","44695\n","44696\n","44697\n","44698\n","44699\n","44700\n","44701\n","44702\n","44703\n","44704\n","44705\n","44706\n","44707\n","44708\n","44709\n","44710\n","44711\n","44712\n","44713\n","44714\n","44715\n","44716\n","44717\n","44718\n","44719\n","44720\n","44721\n","44722\n","44723\n","44724\n","44725\n","44726\n","44727\n","44728\n","44729\n","44730\n","44731\n","44732\n","44733\n","44734\n","44735\n","44736\n","44737\n","44738\n","44739\n","44740\n","44741\n","44742\n","44743\n","44744\n","44745\n","44746\n","44747\n","44748\n","44749\n","44750\n","44751\n","44752\n","44753\n","44754\n","44755\n","44756\n","44757\n","44758\n","44759\n","44760\n","44761\n","44762\n","44763\n","44764\n","44765\n","44766\n","44767\n","44768\n","44769\n","44770\n","44771\n","44772\n","44773\n","44774\n","44775\n","44776\n","44777\n","44778\n","44779\n","44780\n","44781\n","44782\n","44783\n","44784\n","44785\n","44786\n","44787\n","44788\n","44789\n","44790\n","44791\n","44792\n","44793\n","44794\n","44795\n","44796\n","44797\n","44798\n","44799\n","44800\n","44801\n","44802\n","44803\n","44804\n","44805\n","44806\n","44807\n","44808\n","44809\n","44810\n","44811\n","44812\n","44813\n","44814\n","44815\n","44816\n","44817\n","44818\n","44819\n","44820\n","44821\n","44822\n","44823\n","44824\n","44825\n","44826\n","44827\n","44828\n","44829\n","44830\n","44831\n","44832\n","44833\n","44834\n","44835\n","44836\n","44837\n","44838\n","44839\n","44840\n","44841\n","44842\n","44843\n","44844\n","44845\n","44846\n","44847\n","44848\n","44849\n","44850\n","44851\n","44852\n","44853\n","44854\n","44855\n","44856\n","44857\n","44858\n","44859\n","44860\n","44861\n","44862\n","44863\n","44864\n","44865\n","44866\n","44867\n","44868\n","44869\n","44870\n","44871\n","44872\n","44873\n","44874\n","44875\n","44876\n","44877\n","44878\n","44879\n","44880\n","44881\n","44882\n","44883\n","44884\n","44885\n","44886\n","44887\n","44888\n","44889\n","44890\n","44891\n","44892\n","44893\n","44894\n","44895\n","44896\n","44897\n","44898\n","44899\n","44900\n","44901\n","44902\n","44903\n","44904\n","44905\n","44906\n","44907\n","44908\n","44909\n","44910\n","44911\n","44912\n","44913\n","44914\n","44915\n","44916\n","44917\n","44918\n","44919\n","44920\n","44921\n","44922\n","44923\n","44924\n","44925\n","44926\n","44927\n","44928\n","44929\n","44930\n","44931\n","44932\n","44933\n","44934\n","44935\n","44936\n","44937\n","44938\n","44939\n","44940\n","44941\n","44942\n","44943\n","44944\n","44945\n","44946\n","44947\n","44948\n","44949\n","44950\n","44951\n","44952\n","44953\n","44954\n","44955\n","44956\n","44957\n","44958\n","44959\n","44960\n","44961\n","44962\n","44963\n","44964\n","44965\n","44966\n","44967\n","44968\n","44969\n","44970\n","44971\n","44972\n","44973\n","44974\n","44975\n","44976\n","44977\n","44978\n","44979\n","44980\n","44981\n","44982\n","44983\n","44984\n","44985\n","44986\n","44987\n","44988\n","44989\n","44990\n","44991\n","44992\n","44993\n","44994\n","44995\n","44996\n","44997\n","44998\n","44999\n","45000\n","45001\n","45002\n","45003\n","45004\n","45005\n","45006\n","45007\n","45008\n","45009\n","45010\n","45011\n","45012\n","45013\n","45014\n","45015\n","45016\n","45017\n","45018\n","45019\n","45020\n","45021\n","45022\n","45023\n","45024\n","45025\n","45026\n","45027\n","45028\n","45029\n","45030\n","45031\n","45032\n","45033\n","45034\n","45035\n","45036\n","45037\n","45038\n","45039\n","45040\n","45041\n","45042\n","45043\n","45044\n","45045\n","45046\n","45047\n","45048\n","45049\n","45050\n","45051\n","45052\n","45053\n","45054\n","45055\n","45056\n","45057\n","45058\n","45059\n","45060\n","45061\n","45062\n","45063\n","45064\n","45065\n","45066\n","45067\n","45068\n","45069\n","45070\n","45071\n","45072\n","45073\n","45074\n","45075\n","45076\n","45077\n","45078\n","45079\n","45080\n","45081\n","45082\n","45083\n","45084\n","45085\n","45086\n","45087\n","45088\n","45089\n","45090\n","45091\n","45092\n","45093\n","45094\n","45095\n","45096\n","45097\n","45098\n","45099\n","45100\n","45101\n","45102\n","45103\n","45104\n","45105\n","45106\n","45107\n","45108\n","45109\n","45110\n","45111\n","45112\n","45113\n","45114\n","45115\n","45116\n","45117\n","45118\n","45119\n","45120\n","45121\n","45122\n","45123\n","45124\n","45125\n","45126\n","45127\n","45128\n","45129\n","45130\n","45131\n","45132\n","45133\n","45134\n","45135\n","45136\n","45137\n","45138\n","45139\n","45140\n","45141\n","45142\n","45143\n","45144\n","45145\n","45146\n","45147\n","45148\n","45149\n","45150\n","45151\n","45152\n","45153\n","45154\n","45155\n","45156\n","45157\n","45158\n","45159\n","45160\n","45161\n","45162\n","45163\n","45164\n","45165\n","45166\n","45167\n","45168\n","45169\n","45170\n","45171\n","45172\n","45173\n","45174\n","45175\n","45176\n","45177\n","45178\n","45179\n","45180\n","45181\n","45182\n","45183\n","45184\n","45185\n","45186\n","45187\n","45188\n","45189\n","45190\n","45191\n","45192\n","45193\n","45194\n","45195\n","45196\n","45197\n","45198\n","45199\n","45200\n","45201\n","45202\n","45203\n","45204\n","45205\n","45206\n","45207\n","45208\n","45209\n","45210\n","45211\n","45212\n","45213\n","45214\n","45215\n","45216\n","45217\n","45218\n","45219\n","45220\n","45221\n","45222\n","45223\n","45224\n","45225\n","45226\n","45227\n","45228\n","45229\n","45230\n","45231\n","45232\n","45233\n","45234\n","45235\n","45236\n","45237\n","45238\n","45239\n","45240\n","45241\n","45242\n","45243\n","45244\n","45245\n","45246\n","45247\n","45248\n","45249\n","45250\n","45251\n","45252\n","45253\n","45254\n","45255\n","45256\n","45257\n","45258\n","45259\n","45260\n","45261\n","45262\n","45263\n","45264\n","45265\n","45266\n","45267\n","45268\n","45269\n","45270\n","45271\n","45272\n","45273\n","45274\n","45275\n","45276\n","45277\n","45278\n","45279\n","45280\n","45281\n","45282\n","45283\n","45284\n","45285\n","45286\n","45287\n","45288\n","45289\n","45290\n","45291\n","45292\n","45293\n","45294\n","45295\n","45296\n","45297\n","45298\n","45299\n","45300\n","45301\n","45302\n","45303\n","45304\n","45305\n","45306\n","45307\n","45308\n","45309\n","45310\n","45311\n","45312\n","45313\n","45314\n","45315\n","45316\n","45317\n","45318\n","45319\n","45320\n","45321\n","45322\n","45323\n","45324\n","45325\n","45326\n","45327\n","45328\n","45329\n","45330\n","45331\n","45332\n","45333\n","45334\n","45335\n","45336\n","45337\n","45338\n","45339\n","45340\n","45341\n","45342\n","45343\n","45344\n","45345\n","45346\n","45347\n","45348\n","45349\n","45350\n","45351\n","45352\n","45353\n","45354\n","45355\n","45356\n","45357\n","45358\n","45359\n","45360\n","45361\n","45362\n","45363\n","45364\n","45365\n","45366\n","45367\n","45368\n","45369\n","45370\n","45371\n","45372\n","45373\n","45374\n","45375\n","45376\n","45377\n","45378\n","45379\n","45380\n","45381\n","45382\n","45383\n","45384\n","45385\n","45386\n","45387\n","45388\n","45389\n","45390\n","45391\n","45392\n","45393\n","45394\n","45395\n","45396\n","45397\n","45398\n","45399\n","45400\n","45401\n","45402\n","45403\n","45404\n","45405\n","45406\n","45407\n","45408\n","45409\n","45410\n","45411\n","45412\n","45413\n","45414\n","45415\n","45416\n","45417\n","45418\n","45419\n","45420\n","45421\n","45422\n","45423\n","45424\n","45425\n","45426\n","45427\n","45428\n","45429\n","45430\n","45431\n","45432\n","45433\n","45434\n","45435\n","45436\n","45437\n","45438\n","45439\n","45440\n","45441\n","45442\n","45443\n","45444\n","45445\n","45446\n","45447\n","45448\n","45449\n","45450\n","45451\n","45452\n","45453\n","45454\n","45455\n","45456\n","45457\n","45458\n","45459\n","45460\n","45461\n","45462\n","45463\n","45464\n","45465\n","45466\n","45467\n","45468\n","45469\n","45470\n","45471\n","45472\n","45473\n","45474\n","45475\n","45476\n","45477\n","45478\n","45479\n","45480\n","45481\n","45482\n","45483\n","45484\n","45485\n","45486\n","45487\n","45488\n","45489\n","45490\n","45491\n","45492\n","45493\n","45494\n","45495\n","45496\n","45497\n","45498\n","45499\n","45500\n","45501\n","45502\n","45503\n","45504\n","45505\n","45506\n","45507\n","45508\n","45509\n","45510\n","45511\n","45512\n","45513\n","45514\n","45515\n","45516\n","45517\n","45518\n","45519\n","45520\n","45521\n","45522\n","45523\n","45524\n","45525\n","45526\n","45527\n","45528\n","45529\n","45530\n","45531\n","45532\n","45533\n","45534\n","45535\n","45536\n","45537\n","45538\n","45539\n","45540\n","45541\n","45542\n","45543\n","45544\n","45545\n","45546\n","45547\n","45548\n","45549\n","45550\n","45551\n","45552\n","45553\n","45554\n","45555\n","45556\n","45557\n","45558\n","45559\n","45560\n","45561\n","45562\n","45563\n","45564\n","45565\n","45566\n","45567\n","45568\n","45569\n","45570\n","45571\n","45572\n","45573\n","45574\n","45575\n","45576\n","45577\n","45578\n","45579\n","45580\n","45581\n","45582\n","45583\n","45584\n","45585\n","45586\n","45587\n","45588\n","45589\n","45590\n","45591\n","45592\n","45593\n","45594\n","45595\n","45596\n","45597\n","45598\n","45599\n","45600\n","45601\n","45602\n","45603\n","45604\n","45605\n","45606\n","45607\n","45608\n","45609\n","45610\n","45611\n","45612\n","45613\n","45614\n","45615\n","45616\n","45617\n","45618\n","45619\n","45620\n","45621\n","45622\n","45623\n","45624\n","45625\n","45626\n","45627\n","45628\n","45629\n","45630\n","45631\n","45632\n","45633\n","45634\n","45635\n","45636\n","45637\n","45638\n","45639\n","45640\n","45641\n","45642\n","45643\n","45644\n","45645\n","45646\n","45647\n","45648\n","45649\n","45650\n","45651\n","45652\n","45653\n","45654\n","45655\n","45656\n","45657\n","45658\n","45659\n","45660\n","45661\n","45662\n","45663\n","45664\n","45665\n","45666\n","45667\n","45668\n","45669\n","45670\n","45671\n","45672\n","45673\n","45674\n","45675\n","45676\n","45677\n","45678\n","45679\n","45680\n","45681\n","45682\n","45683\n","45684\n","45685\n","45686\n","45687\n","45688\n","45689\n","45690\n","45691\n","45692\n","45693\n","45694\n","45695\n","45696\n","45697\n","45698\n","45699\n","45700\n","45701\n","45702\n","45703\n","45704\n","45705\n","45706\n","45707\n","45708\n","45709\n","45710\n","45711\n","45712\n","45713\n","45714\n","45715\n","45716\n","45717\n","45718\n","45719\n","45720\n","45721\n","45722\n","45723\n","45724\n","45725\n","45726\n","45727\n","45728\n","45729\n","45730\n","45731\n","45732\n","45733\n","45734\n","45735\n","45736\n","45737\n","45738\n","45739\n","45740\n","45741\n","45742\n","45743\n","45744\n","45745\n","45746\n","45747\n","45748\n","45749\n","45750\n","45751\n","45752\n","45753\n","45754\n","45755\n","45756\n","45757\n","45758\n","45759\n","45760\n","45761\n","45762\n","45763\n","45764\n","45765\n","45766\n","45767\n","45768\n","45769\n","45770\n","45771\n","45772\n","45773\n","45774\n","45775\n","45776\n","45777\n","45778\n","45779\n","45780\n","45781\n","45782\n","45783\n","45784\n","45785\n","45786\n","45787\n","45788\n","45789\n","45790\n","45791\n","45792\n","45793\n","45794\n","45795\n","45796\n","45797\n","45798\n","45799\n","45800\n","45801\n","45802\n","45803\n","45804\n","45805\n","45806\n","45807\n","45808\n","45809\n","45810\n","45811\n","45812\n","45813\n","45814\n","45815\n","45816\n","45817\n","45818\n","45819\n","45820\n","45821\n","45822\n","45823\n","45824\n","45825\n","45826\n","45827\n","45828\n","45829\n","45830\n","45831\n","45832\n","45833\n","45834\n","45835\n","45836\n","45837\n","45838\n","45839\n","45840\n","45841\n","45842\n","45843\n","45844\n","45845\n","45846\n","45847\n","45848\n","45849\n","45850\n","45851\n","45852\n","45853\n","45854\n","45855\n","45856\n","45857\n","45858\n","45859\n","45860\n","45861\n","45862\n","45863\n","45864\n","45865\n","45866\n","45867\n","45868\n","45869\n","45870\n","45871\n","45872\n","45873\n","45874\n","45875\n","45876\n","45877\n","45878\n","45879\n","45880\n","45881\n","45882\n","45883\n","45884\n","45885\n","45886\n","45887\n","45888\n","45889\n","45890\n","45891\n","45892\n","45893\n","45894\n","45895\n","45896\n","45897\n","45898\n","45899\n","45900\n","45901\n","45902\n","45903\n","45904\n","45905\n","45906\n","45907\n","45908\n","45909\n","45910\n","45911\n","45912\n","45913\n","45914\n","45915\n","45916\n","45917\n","45918\n","45919\n","45920\n","45921\n","45922\n","45923\n","45924\n","45925\n","45926\n","45927\n","45928\n","45929\n","45930\n","45931\n","45932\n","45933\n","45934\n","45935\n","45936\n","45937\n","45938\n","45939\n","45940\n","45941\n","45942\n","45943\n","45944\n","45945\n","45946\n","45947\n","45948\n","45949\n","45950\n","45951\n","45952\n","45953\n","45954\n","45955\n","45956\n","45957\n","45958\n","45959\n","45960\n","45961\n","45962\n","45963\n","45964\n","45965\n","45966\n","45967\n","45968\n","45969\n","45970\n","45971\n","45972\n","45973\n","45974\n","45975\n","45976\n","45977\n","45978\n","45979\n","45980\n","45981\n","45982\n","45983\n","45984\n","45985\n","45986\n","45987\n","45988\n","45989\n","45990\n","45991\n","45992\n","45993\n","45994\n","45995\n","45996\n","45997\n","45998\n","45999\n","46000\n","46001\n","46002\n","46003\n","46004\n","46005\n","46006\n","46007\n","46008\n","46009\n","46010\n","46011\n","46012\n","46013\n","46014\n","46015\n","46016\n","46017\n","46018\n","46019\n","46020\n","46021\n","46022\n","46023\n","46024\n","46025\n","46026\n","46027\n","46028\n","46029\n","46030\n","46031\n","46032\n","46033\n","46034\n","46035\n","46036\n","46037\n","46038\n","46039\n","46040\n","46041\n","46042\n","46043\n","46044\n","46045\n","46046\n","46047\n","46048\n","46049\n","46050\n","46051\n","46052\n","46053\n","46054\n","46055\n","46056\n","46057\n","46058\n","46059\n","46060\n","46061\n","46062\n","46063\n","46064\n","46065\n","46066\n","46067\n","46068\n","46069\n","46070\n","46071\n","46072\n","46073\n","46074\n","46075\n","46076\n","46077\n","46078\n","46079\n","46080\n","46081\n","46082\n","46083\n","46084\n","46085\n","46086\n","46087\n","46088\n","46089\n","46090\n","46091\n","46092\n","46093\n","46094\n","46095\n","46096\n","46097\n","46098\n","46099\n","46100\n","46101\n","46102\n","46103\n","46104\n","46105\n","46106\n","46107\n","46108\n","46109\n","46110\n","46111\n","46112\n","46113\n","46114\n","46115\n","46116\n","46117\n","46118\n","46119\n","46120\n","46121\n","46122\n","46123\n","46124\n","46125\n","46126\n","46127\n","46128\n","46129\n","46130\n","46131\n","46132\n","46133\n","46134\n","46135\n","46136\n","46137\n","46138\n","46139\n","46140\n","46141\n","46142\n","46143\n","46144\n","46145\n","46146\n","46147\n","46148\n","46149\n","46150\n","46151\n","46152\n","46153\n","46154\n","46155\n","46156\n","46157\n","46158\n","46159\n","46160\n","46161\n","46162\n","46163\n","46164\n","46165\n","46166\n","46167\n","46168\n","46169\n","46170\n","46171\n","46172\n","46173\n","46174\n","46175\n","46176\n","46177\n","46178\n","46179\n","46180\n","46181\n","46182\n","46183\n","46184\n","46185\n","46186\n","46187\n","46188\n","46189\n","46190\n","46191\n","46192\n","46193\n","46194\n","46195\n","46196\n","46197\n","46198\n","46199\n","46200\n","46201\n","46202\n","46203\n","46204\n","46205\n","46206\n","46207\n","46208\n","46209\n","46210\n","46211\n","46212\n","46213\n","46214\n","46215\n","46216\n","46217\n","46218\n","46219\n","46220\n","46221\n","46222\n","46223\n","46224\n","46225\n","46226\n","46227\n","46228\n","46229\n","46230\n","46231\n","46232\n","46233\n","46234\n","46235\n","46236\n","46237\n","46238\n","46239\n","46240\n","46241\n","46242\n","46243\n","46244\n","46245\n","46246\n","46247\n","46248\n","46249\n","46250\n","46251\n","46252\n","46253\n","46254\n","46255\n","46256\n","46257\n","46258\n","46259\n","46260\n","46261\n","46262\n","46263\n","46264\n","46265\n","46266\n","46267\n","46268\n","46269\n","46270\n","46271\n","46272\n","46273\n","46274\n","46275\n","46276\n","46277\n","46278\n","46279\n","46280\n","46281\n","46282\n","46283\n","46284\n","46285\n","46286\n","46287\n","46288\n","46289\n","46290\n","46291\n","46292\n","46293\n","46294\n","46295\n","46296\n","46297\n","46298\n","46299\n","46300\n","46301\n","46302\n","46303\n","46304\n","46305\n","46306\n","46307\n","46308\n","46309\n","46310\n","46311\n","46312\n","46313\n","46314\n","46315\n","46316\n","46317\n","46318\n","46319\n","46320\n","46321\n","46322\n","46323\n","46324\n","46325\n","46326\n","46327\n","46328\n","46329\n","46330\n","46331\n","46332\n","46333\n","46334\n","46335\n","46336\n","46337\n","46338\n","46339\n","46340\n","46341\n","46342\n","46343\n","46344\n","46345\n","46346\n","46347\n","46348\n","46349\n","46350\n","46351\n","46352\n","46353\n","46354\n","46355\n","46356\n","46357\n","46358\n","46359\n","46360\n","46361\n","46362\n","46363\n","46364\n","46365\n","46366\n","46367\n","46368\n","46369\n","46370\n","46371\n","46372\n","46373\n","46374\n","46375\n","46376\n","46377\n","46378\n","46379\n","46380\n","46381\n","46382\n","46383\n","46384\n","46385\n","46386\n","46387\n","46388\n","46389\n","46390\n","46391\n","46392\n","46393\n","46394\n","46395\n","46396\n","46397\n","46398\n","46399\n","46400\n","46401\n","46402\n","46403\n","46404\n","46405\n","46406\n","46407\n","46408\n","46409\n","46410\n","46411\n","46412\n","46413\n","46414\n","46415\n","46416\n","46417\n","46418\n","46419\n","46420\n","46421\n","46422\n","46423\n","46424\n","46425\n","46426\n","46427\n","46428\n","46429\n","46430\n","46431\n","46432\n","46433\n","46434\n","46435\n","46436\n","46437\n","46438\n","46439\n","46440\n","46441\n","46442\n","46443\n","46444\n","46445\n","46446\n","46447\n","46448\n","46449\n","46450\n","46451\n","46452\n","46453\n","46454\n","46455\n","46456\n","46457\n","46458\n","46459\n","46460\n","46461\n","46462\n","46463\n","46464\n","46465\n","46466\n","46467\n","46468\n","46469\n","46470\n","46471\n","46472\n","46473\n","46474\n","46475\n","46476\n","46477\n","46478\n","46479\n","46480\n","46481\n","46482\n","46483\n","46484\n","46485\n","46486\n","46487\n","46488\n","46489\n","46490\n","46491\n","46492\n","46493\n","46494\n","46495\n","46496\n","46497\n","46498\n","46499\n","46500\n","46501\n","46502\n","46503\n","46504\n","46505\n","46506\n","46507\n","46508\n","46509\n","46510\n","46511\n","46512\n","46513\n","46514\n","46515\n","46516\n","46517\n","46518\n","46519\n","46520\n","46521\n","46522\n","46523\n","46524\n","46525\n","46526\n","46527\n","46528\n","46529\n","46530\n","46531\n","46532\n","46533\n","46534\n","46535\n","46536\n","46537\n","46538\n","46539\n","46540\n","46541\n","46542\n","46543\n","46544\n","46545\n","46546\n","46547\n","46548\n","46549\n","46550\n","46551\n","46552\n","46553\n","46554\n","46555\n","46556\n","46557\n","46558\n","46559\n","46560\n","46561\n","46562\n","46563\n","46564\n","46565\n","46566\n","46567\n","46568\n","46569\n","46570\n","46571\n","46572\n","46573\n","46574\n","46575\n","46576\n","46577\n","46578\n","46579\n","46580\n","46581\n","46582\n","46583\n","46584\n","46585\n","46586\n","46587\n","46588\n","46589\n","46590\n","46591\n","46592\n","46593\n","46594\n","46595\n","46596\n","46597\n","46598\n","46599\n","46600\n","46601\n","46602\n","46603\n","46604\n","46605\n","46606\n","46607\n","46608\n","46609\n","46610\n","46611\n","46612\n","46613\n","46614\n","46615\n","46616\n","46617\n","46618\n","46619\n","46620\n","46621\n","46622\n","46623\n","46624\n","46625\n","46626\n","46627\n","46628\n","46629\n","46630\n","46631\n","46632\n","46633\n","46634\n","46635\n","46636\n","46637\n","46638\n","46639\n","46640\n","46641\n","46642\n","46643\n","46644\n","46645\n","46646\n","46647\n","46648\n","46649\n","46650\n","46651\n","46652\n","46653\n","46654\n","46655\n","46656\n","46657\n","46658\n","46659\n","46660\n","46661\n","46662\n","46663\n","46664\n","46665\n","46666\n","46667\n","46668\n","46669\n","46670\n","46671\n","46672\n","46673\n","46674\n","46675\n","46676\n","46677\n","46678\n","46679\n","46680\n","46681\n","46682\n","46683\n","46684\n","46685\n","46686\n","46687\n","46688\n","46689\n","46690\n","46691\n","46692\n","46693\n","46694\n","46695\n","46696\n","46697\n","46698\n","46699\n","46700\n","46701\n","46702\n","46703\n","46704\n","46705\n","46706\n","46707\n","46708\n","46709\n","46710\n","46711\n","46712\n","46713\n","46714\n","46715\n","46716\n","46717\n","46718\n","46719\n","46720\n","46721\n","46722\n","46723\n","46724\n","46725\n","46726\n","46727\n","46728\n","46729\n","46730\n","46731\n","46732\n","46733\n","46734\n","46735\n","46736\n","46737\n","46738\n","46739\n","46740\n","46741\n","46742\n","46743\n","46744\n","46745\n","46746\n","46747\n","46748\n","46749\n","46750\n","46751\n","46752\n","46753\n","46754\n","46755\n","46756\n","46757\n","46758\n","46759\n","46760\n","46761\n","46762\n","46763\n","46764\n","46765\n","46766\n","46767\n","46768\n","46769\n","46770\n","46771\n","46772\n","46773\n","46774\n","46775\n","46776\n","46777\n","46778\n","46779\n","46780\n","46781\n","46782\n","46783\n","46784\n","46785\n","46786\n","46787\n","46788\n","46789\n","46790\n","46791\n","46792\n","46793\n","46794\n","46795\n","46796\n","46797\n","46798\n","46799\n","46800\n","46801\n","46802\n","46803\n","46804\n","46805\n","46806\n","46807\n","46808\n","46809\n","46810\n","46811\n","46812\n","46813\n","46814\n","46815\n","46816\n","46817\n","46818\n","46819\n","46820\n","46821\n","46822\n","46823\n","46824\n","46825\n","46826\n","46827\n","46828\n","46829\n","46830\n","46831\n","46832\n","46833\n","46834\n","46835\n","46836\n","46837\n","46838\n","46839\n","46840\n","46841\n","46842\n","46843\n","46844\n","46845\n","46846\n","46847\n","46848\n","46849\n","46850\n","46851\n","46852\n","46853\n","46854\n","46855\n","46856\n","46857\n","46858\n","46859\n","46860\n","46861\n","46862\n","46863\n","46864\n","46865\n","46866\n","46867\n","46868\n","46869\n","46870\n","46871\n","46872\n","46873\n","46874\n","46875\n","46876\n","46877\n","46878\n","46879\n","46880\n","46881\n","46882\n","46883\n","46884\n","46885\n","46886\n","46887\n","46888\n","46889\n","46890\n","46891\n","46892\n","46893\n","46894\n","46895\n","46896\n","46897\n","46898\n","46899\n","46900\n","46901\n","46902\n","46903\n","46904\n","46905\n","46906\n","46907\n","46908\n","46909\n","46910\n","46911\n","46912\n","46913\n","46914\n","46915\n","46916\n","46917\n","46918\n","46919\n","46920\n","46921\n","46922\n","46923\n","46924\n","46925\n","46926\n","46927\n","46928\n","46929\n","46930\n","46931\n","46932\n","46933\n","46934\n","46935\n","46936\n","46937\n","46938\n","46939\n","46940\n","46941\n","46942\n","46943\n","46944\n","46945\n","46946\n","46947\n","46948\n","46949\n","46950\n","46951\n","46952\n","46953\n","46954\n","46955\n","46956\n","46957\n","46958\n","46959\n","46960\n","46961\n","46962\n","46963\n","46964\n","46965\n","46966\n","46967\n","46968\n","46969\n","46970\n","46971\n","46972\n","46973\n","46974\n","46975\n","46976\n","46977\n","46978\n","46979\n","46980\n","46981\n","46982\n","46983\n","46984\n","46985\n","46986\n","46987\n","46988\n","46989\n","46990\n","46991\n","46992\n","46993\n","46994\n","46995\n","46996\n","46997\n","46998\n","46999\n","47000\n","47001\n","47002\n","47003\n","47004\n","47005\n","47006\n","47007\n","47008\n","47009\n","47010\n","47011\n","47012\n","47013\n","47014\n","47015\n","47016\n","47017\n","47018\n","47019\n","47020\n","47021\n","47022\n","47023\n","47024\n","47025\n","47026\n","47027\n","47028\n","47029\n","47030\n","47031\n","47032\n","47033\n","47034\n","47035\n","47036\n","47037\n","47038\n","47039\n","47040\n","47041\n","47042\n","47043\n","47044\n","47045\n","47046\n","47047\n","47048\n","47049\n","47050\n","47051\n","47052\n","47053\n","47054\n","47055\n","47056\n","47057\n","47058\n","47059\n","47060\n","47061\n","47062\n","47063\n","47064\n","47065\n","47066\n","47067\n","47068\n","47069\n","47070\n","47071\n","47072\n","47073\n","47074\n","47075\n","47076\n","47077\n","47078\n","47079\n","47080\n","47081\n","47082\n","47083\n","47084\n","47085\n","47086\n","47087\n","47088\n","47089\n","47090\n","47091\n","47092\n","47093\n","47094\n","47095\n","47096\n","47097\n","47098\n","47099\n","47100\n","47101\n","47102\n","47103\n","47104\n","47105\n","47106\n","47107\n","47108\n","47109\n","47110\n","47111\n","47112\n","47113\n","47114\n","47115\n","47116\n","47117\n","47118\n","47119\n","47120\n","47121\n","47122\n","47123\n","47124\n","47125\n","47126\n","47127\n","47128\n","47129\n","47130\n","47131\n","47132\n","47133\n","47134\n","47135\n","47136\n","47137\n","47138\n","47139\n","47140\n","47141\n","47142\n","47143\n","47144\n","47145\n","47146\n","47147\n","47148\n","47149\n","47150\n","47151\n","47152\n","47153\n","47154\n","47155\n","47156\n","47157\n","47158\n","47159\n","47160\n","47161\n","47162\n","47163\n","47164\n","47165\n","47166\n","47167\n","47168\n","47169\n","47170\n","47171\n","47172\n","47173\n","47174\n","47175\n","47176\n","47177\n","47178\n","47179\n","47180\n","47181\n","47182\n","47183\n","47184\n","47185\n","47186\n","47187\n","47188\n","47189\n","47190\n","47191\n","47192\n","47193\n","47194\n","47195\n","47196\n","47197\n","47198\n","47199\n","47200\n","47201\n","47202\n","47203\n","47204\n","47205\n","47206\n","47207\n","47208\n","47209\n","47210\n","47211\n","47212\n","47213\n","47214\n","47215\n","47216\n","47217\n","47218\n","47219\n","47220\n","47221\n","47222\n","47223\n","47224\n","47225\n","47226\n","47227\n","47228\n","47229\n","47230\n","47231\n","47232\n","47233\n","47234\n","47235\n","47236\n","47237\n","47238\n","47239\n","47240\n","47241\n","47242\n","47243\n","47244\n","47245\n","47246\n","47247\n","47248\n","47249\n","47250\n","47251\n","47252\n","47253\n","47254\n","47255\n","47256\n","47257\n","47258\n","47259\n","47260\n","47261\n","47262\n","47263\n","47264\n","47265\n","47266\n","47267\n","47268\n","47269\n","47270\n","47271\n","47272\n","47273\n","47274\n","47275\n","47276\n","47277\n","47278\n","47279\n","47280\n","47281\n","47282\n","47283\n","47284\n","47285\n","47286\n","47287\n","47288\n","47289\n","47290\n","47291\n","47292\n","47293\n","47294\n","47295\n","47296\n","47297\n","47298\n","47299\n","47300\n","47301\n","47302\n","47303\n","47304\n","47305\n","47306\n","47307\n","47308\n","47309\n","47310\n","47311\n","47312\n","47313\n","47314\n","47315\n","47316\n","47317\n","47318\n","47319\n","47320\n","47321\n","47322\n","47323\n","47324\n","47325\n","47326\n","47327\n","47328\n","47329\n","47330\n","47331\n","47332\n","47333\n","47334\n","47335\n","47336\n","47337\n","47338\n","47339\n","47340\n","47341\n","47342\n","47343\n","47344\n","47345\n","47346\n","47347\n","47348\n","47349\n","47350\n","47351\n","47352\n","47353\n","47354\n","47355\n","47356\n","47357\n","47358\n","47359\n","47360\n","47361\n","47362\n","47363\n","47364\n","47365\n","47366\n","47367\n","47368\n","47369\n","47370\n","47371\n","47372\n","47373\n","47374\n","47375\n","47376\n","47377\n","47378\n","47379\n","47380\n","47381\n","47382\n","47383\n","47384\n","47385\n","47386\n","47387\n","47388\n","47389\n","47390\n","47391\n","47392\n","47393\n","47394\n","47395\n","47396\n","47397\n","47398\n","47399\n","47400\n","47401\n","47402\n","47403\n","47404\n","47405\n","47406\n","47407\n","47408\n","47409\n","47410\n","47411\n","47412\n","47413\n","47414\n","47415\n","47416\n","47417\n","47418\n","47419\n","47420\n","47421\n","47422\n","47423\n","47424\n","47425\n","47426\n","47427\n","47428\n","47429\n","47430\n","47431\n","47432\n","47433\n","47434\n","47435\n","47436\n","47437\n","47438\n","47439\n","47440\n","47441\n","47442\n","47443\n","47444\n","47445\n","47446\n","47447\n","47448\n","47449\n","47450\n","47451\n","47452\n","47453\n","47454\n","47455\n","47456\n","47457\n","47458\n","47459\n","47460\n","47461\n","47462\n","47463\n","47464\n","47465\n","47466\n","47467\n","47468\n","47469\n","47470\n","47471\n","47472\n","47473\n","47474\n","47475\n","47476\n","47477\n","47478\n","47479\n","47480\n","47481\n","47482\n","47483\n","47484\n","47485\n","47486\n","47487\n","47488\n","47489\n","47490\n","47491\n","47492\n","47493\n","47494\n","47495\n","47496\n","47497\n","47498\n","47499\n","47500\n","47501\n","47502\n","47503\n","47504\n","47505\n","47506\n","47507\n","47508\n","47509\n","47510\n","47511\n","47512\n","47513\n","47514\n","47515\n","47516\n","47517\n","47518\n","47519\n","47520\n","47521\n","47522\n","47523\n","47524\n","47525\n","47526\n","47527\n","47528\n","47529\n","47530\n","47531\n","47532\n","47533\n","47534\n","47535\n","47536\n","47537\n","47538\n","47539\n","47540\n","47541\n","47542\n","47543\n","47544\n","47545\n","47546\n","47547\n","47548\n","47549\n","47550\n","47551\n","47552\n","47553\n","47554\n","47555\n","47556\n","47557\n","47558\n","47559\n","47560\n","47561\n","47562\n","47563\n","47564\n","47565\n","47566\n","47567\n","47568\n","47569\n","47570\n","47571\n","47572\n","47573\n","47574\n","47575\n","47576\n","47577\n","47578\n","47579\n","47580\n","47581\n","47582\n","47583\n","47584\n","47585\n","47586\n","47587\n","47588\n","47589\n","47590\n","47591\n","47592\n","47593\n","47594\n","47595\n","47596\n","47597\n","47598\n","47599\n","47600\n","47601\n","47602\n","47603\n","47604\n","47605\n","47606\n","47607\n","47608\n","47609\n","47610\n","47611\n","47612\n","47613\n","47614\n","47615\n","47616\n","47617\n","47618\n","47619\n","47620\n","47621\n","47622\n","47623\n","47624\n","47625\n","47626\n","47627\n","47628\n","47629\n","47630\n","47631\n","47632\n","47633\n","47634\n","47635\n","47636\n","47637\n","47638\n","47639\n","47640\n","47641\n","47642\n","47643\n","47644\n","47645\n","47646\n","47647\n","47648\n","47649\n","47650\n","47651\n","47652\n","47653\n","47654\n","47655\n","47656\n","47657\n","47658\n","47659\n","47660\n","47661\n","47662\n","47663\n","47664\n","47665\n","47666\n","47667\n","47668\n","47669\n","47670\n","47671\n","47672\n","47673\n","47674\n","47675\n","47676\n","47677\n","47678\n","47679\n","47680\n","47681\n","47682\n","47683\n","47684\n","47685\n","47686\n","47687\n","47688\n","47689\n","47690\n","47691\n"]}]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","from keras.utils import to_categorical\n","max_words = 10000\n","max_len = 100\n","tokenizer = Tokenizer(num_words=max_words)\n","tokenizer.fit_on_texts(rnnmulticorpus)\n","sequences_multi = tokenizer.texts_to_sequences(rnnmulticorpus)\n","word_index = tokenizer.word_index\n","data = pad_sequences(sequences_multi, maxlen=max_len)\n","\n","# Encode labels\n","encoder = LabelEncoder()\n","encoder.fit(rnnmultidata['cyberbullying_type'])\n","encoded_labels = encoder.transform(rnnmultidata['cyberbullying_type'])\n","num_classes = len(encoder.classes_)\n","one_hot_labels = to_categorical(encoded_labels, num_classes=num_classes)\n","\n","# Split data into training, validation, and test sets\n","rnnmultiXtrain, rnnmultiXtest, rnnmultiYtrain, rnnmultiYtest = train_test_split(data, one_hot_labels, test_size=0.2, random_state=42)\n","rnnmultiXtrain, rnnmultiXval, rnnmultiYtrain, rnnmultiYval = train_test_split(rnnmultiXtrain, rnnmultiYtrain, test_size=0.2, random_state=42)\n","\n","# Create model\n","model2rnn = Sequential()\n","model2rnn.add(Embedding(max_words, 100, input_length=max_len))\n","model2rnn.add(Bidirectional(LSTM(64)))\n","model2rnn.add(Dense(num_classes, activation='softmax'))\n","\n","model2rnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"],"metadata":{"id":"0f2ES3iit5w8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["early_stop = EarlyStopping(monitor='val_loss', patience=3)\n","history = model2rnn.fit(rnnmultiXtrain, rnnmultiYtrain, epochs=10, batch_size=512, validation_data=(rnnmultiXval, rnnmultiYval))#, callbacks=[early_stop])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jut3ziqAxJlg","executionInfo":{"status":"ok","timestamp":1681543694393,"user_tz":-330,"elapsed":21834,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"4802b7ca-6a72-4135-f5b6-4164b57234de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","60/60 [==============================] - 2s 30ms/step - loss: 0.1197 - accuracy: 0.9494 - val_loss: 0.6292 - val_accuracy: 0.8125\n","Epoch 2/10\n","60/60 [==============================] - 2s 31ms/step - loss: 0.1149 - accuracy: 0.9508 - val_loss: 0.6473 - val_accuracy: 0.8159\n","Epoch 3/10\n","60/60 [==============================] - 2s 40ms/step - loss: 0.1091 - accuracy: 0.9515 - val_loss: 0.6598 - val_accuracy: 0.8108\n","Epoch 4/10\n","60/60 [==============================] - 2s 42ms/step - loss: 0.1046 - accuracy: 0.9522 - val_loss: 0.6984 - val_accuracy: 0.8113\n","Epoch 5/10\n","60/60 [==============================] - 3s 49ms/step - loss: 0.1002 - accuracy: 0.9544 - val_loss: 0.7301 - val_accuracy: 0.8106\n","Epoch 6/10\n","60/60 [==============================] - 2s 31ms/step - loss: 0.0974 - accuracy: 0.9544 - val_loss: 0.7546 - val_accuracy: 0.8034\n","Epoch 7/10\n","60/60 [==============================] - 2s 34ms/step - loss: 0.0943 - accuracy: 0.9552 - val_loss: 0.7664 - val_accuracy: 0.8057\n","Epoch 8/10\n","60/60 [==============================] - 2s 29ms/step - loss: 0.0904 - accuracy: 0.9572 - val_loss: 0.7797 - val_accuracy: 0.8087\n","Epoch 9/10\n","60/60 [==============================] - 2s 27ms/step - loss: 0.0888 - accuracy: 0.9571 - val_loss: 0.7899 - val_accuracy: 0.8057\n","Epoch 10/10\n","60/60 [==============================] - 1s 23ms/step - loss: 0.0858 - accuracy: 0.9582 - val_loss: 0.8488 - val_accuracy: 0.8020\n"]}]},{"cell_type":"code","source":["test_loss2, test_acc2 = model2rnn.evaluate(rnnmultiXtest, rnnmultiYtest)\n","print('Test accuracy:', test_acc2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"klowW2xnxwHG","executionInfo":{"status":"ok","timestamp":1681543699355,"user_tz":-330,"elapsed":2099,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"c81bb4d6-9b28-4fce-b943-7e59cc799960"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["299/299 [==============================] - 2s 6ms/step - loss: 0.8934 - accuracy: 0.7920\n","Test accuracy: 0.7920117378234863\n"]}]},{"cell_type":"code","source":["#BERT"],"metadata":{"id":"mJ66erHnx4tP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aXM-zaD0NSI3","executionInfo":{"status":"ok","timestamp":1683542124898,"user_tz":-330,"elapsed":12412,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"205a9d8b-565c-4e55-d737-6ca74b3070ea"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m108.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from transformers import BertTokenizer, TFBertForSequenceClassification,TFBertModel\n"],"metadata":{"id":"9x8HuWUUMLTZ","executionInfo":{"status":"ok","timestamp":1683542129508,"user_tz":-330,"elapsed":4616,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","bertmodel = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":214,"referenced_widgets":["a2105973ac474a2a8575b70a0de1356d","940e6a02cab045c6990436b7d48384c0","0e559d690bb64af39a4e9888b846f39d","9b49e4ec5d53474f9adcf380fa84c0cd","e2dfc91e87f942648aec26ad13a6fc8a","f70b73b4f78b41c7b2570fe7e84f7728","50024503941445029b5db57a4940a76e","9b4b6881667842298cb953180c284357","0e42369cfeaa42a0ae0ff5ddb197ed2c","a608f1d8343a40b1a1b28188e701705a","f79930077db54d349e780c046c9d63a8","3c460b7ce7fb4110b5969ca5c52810d2","ae9734e19cef4cec8c0e8d7cce90592c","aabcfb6dd80b43d6a6b930bfb7b8913e","d6c9db141f7047f58e5081ae1196538c","1d629fd3afe445468475bb86449660b0","8a5de65b77334ff89d739f477ca06248","6f4b327ce31b48d18d46a21f2264fbc5","af3033c55c7c4f57b7d27282a60635cd","ef7c6c44d34f43e1a3251a3e6c01c1ce","8af0a7bf95144fcaad54159cb7c00235","d2f56efb0c644c39ab5615848c0b3667","98a805fcdae04837aae4e36d0604962c","3dc570e817db4b5b82c3aaac23c831e8","b22d302261d34b4ebde1c0d635dacd72","42667c286e6f4b19baf104c541dea2bc","6c239cf46dcc4ff8ab1d16574418e771","f1388081f0c74afc9fe7dbeae80dd631","854ca46a7955423e9ac5652a710d3468","4e7c8409e6744c619e08fc934902f588","a77aeb658fc942038495e668cdfa52be","43684f7cdf894b65bf449555611a4ec6","141f5409866e4708a43a1f35e833b87f","ae30eb1c358d418f8e71146c19ac3320","64932557b5d444fba1df58ec8c8ccd71","e968d3a1c10b4ad7942a555eb385f207","54fe3f8c47084313b616ae3efbea69ba","9c23277ce0db4a12a1dd1a11e4f2d426","a9aab8a739b64eb5b688fa60d6e230f8","9d70a4a76032469da816f7bdb2bdd9fc","bc3ce726a4934099928abcd7cbadb345","f22c08ac5e9d415aa7cc83d0402645bb","11589c81d22746478a47e05a71353bc7","04dfa0ec049d485e960411fb0917dc5d"]},"id":"QQVSHRD4NOb4","executionInfo":{"status":"ok","timestamp":1683542141141,"user_tz":-330,"elapsed":11643,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"bd948098-34ae-498d-f704-6a422d3764f5"},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2105973ac474a2a8575b70a0de1356d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c460b7ce7fb4110b5969ca5c52810d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98a805fcdae04837aae4e36d0604962c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading tf_model.h5:   0%|          | 0.00/536M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae30eb1c358d418f8e71146c19ac3320"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n","\n","Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["#binary\n","bertdata = pd.read_csv('/content/drive/MyDrive/Minor Project(NLP)/cyberbullying_tweets.csv',encoding='ISO-8859-1')\n","bertdata.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"jp6iewVvNazH","executionInfo":{"status":"ok","timestamp":1683542142690,"user_tz":-330,"elapsed":1554,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"def895a6-66af-4a1a-b2e3-abe473e1d594"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                          tweet_text cyberbullying_type\n","0  In other words #katandandre, your food was cra...  not_cyberbullying\n","1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying\n","2  @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying\n","3  @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying\n","4  @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying"],"text/html":["\n","  <div id=\"df-d777ddf4-45a7-4c6c-8b8c-d505eadd3bfb\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet_text</th>\n","      <th>cyberbullying_type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>In other words #katandandre, your food was cra...</td>\n","      <td>not_cyberbullying</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n","      <td>not_cyberbullying</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n","      <td>not_cyberbullying</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n","      <td>not_cyberbullying</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n","      <td>not_cyberbullying</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d777ddf4-45a7-4c6c-8b8c-d505eadd3bfb')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d777ddf4-45a7-4c6c-8b8c-d505eadd3bfb button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d777ddf4-45a7-4c6c-8b8c-d505eadd3bfb');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["bertdatabinary=bertdata.copy()\n","print(bertdatabinary.head(2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"flfoaAr2NzZz","executionInfo":{"status":"ok","timestamp":1683444020744,"user_tz":-330,"elapsed":25,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"a9e9a5f0-d708-4b6f-97f2-866ef710aecb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                          tweet_text cyberbullying_type\n","0  In other words #katandandre, your food was cra...  not_cyberbullying\n","1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying\n"]}]},{"cell_type":"code","source":["bertdatabinary['cyberbullying_type'] = bertdatabinary['cyberbullying_type'].apply(lambda x: 0 if x=='not_cyberbullying' else 1)\n","bertdatabinary.head(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"id":"JZ2aM_38N8r3","executionInfo":{"status":"ok","timestamp":1683444066670,"user_tz":-330,"elapsed":470,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"43583e97-775e-4497-f9ff-5b80d86b119f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                          tweet_text  cyberbullying_type\n","0  In other words #katandandre, your food was cra...                   0\n","1  Why is #aussietv so white? #MKR #theblock #ImA...                   0"],"text/html":["\n","  <div id=\"df-929c598b-3409-4d4d-9f4a-9d69926aecd2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet_text</th>\n","      <th>cyberbullying_type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>In other words #katandandre, your food was cra...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-929c598b-3409-4d4d-9f4a-9d69926aecd2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-929c598b-3409-4d4d-9f4a-9d69926aecd2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-929c598b-3409-4d4d-9f4a-9d69926aecd2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["texts = bertdatabinary['tweet_text'].values\n","labels = bertdatabinary['cyberbullying_type'].values\n","input_ids=[]\n","attention_masks=[]"],"metadata":{"id":"YwDt__Z1OZyf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for text in texts:\n","    encoded_dict = tokenizer.encode_plus(\n","                        text,                      # text to encode\n","                        add_special_tokens = True, # add [CLS] and [SEP]\n","                        max_length = 64,           # truncate long sentences\n","                        pad_to_max_length = True,  # pad shorter sentences\n","                        return_attention_mask = True, # create attention mask\n","                        return_tensors = 'tf',     # return TensorFlow tensors\n","                   )\n","    input_ids.append(encoded_dict['input_ids'])\n","    attention_masks.append(encoded_dict['attention_mask'])\n","input_ids = tf.concat(input_ids, axis=0)\n","attention_masks = tf.concat(attention_masks, axis=0)\n","labels = tf.constant(labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fokP7W3SOrfm","executionInfo":{"status":"ok","timestamp":1683444124243,"user_tz":-330,"elapsed":52894,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"3e585f53-5894-4adb-b3f4-7c0b2638edca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]}]},{"cell_type":"code","source":["print(input_ids.shape,np.asarray(input_ids))\n","#print(attention_masks.shape,attention_masks.type())\n","#print(labels.shape,labels.type())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U2oGFaAzQv_Y","executionInfo":{"status":"ok","timestamp":1683444128464,"user_tz":-330,"elapsed":450,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"4f475446-fa86-4efa-c25e-f813a7714990"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(47692, 64) [[  101  1999  2060 ...     0     0     0]\n"," [  101  2339  2003 ...     0     0     0]\n"," [  101  1030  1060 ...     0     0     0]\n"," ...\n"," [  101  1045  8415 ...     0     0     0]\n"," [  101  6300  2050 ...     0     0     0]\n"," [  101 22953  1012 ...     0     0     0]]\n"]}]},{"cell_type":"code","source":["train_inputs, test_inputs, train_labels, test_labels = train_test_split(np.asarray(input_ids), np.asarray(labels), test_size=0.2, random_state=42)\n","train_masks, test_masks, _, _ = train_test_split(np.asarray(attention_masks), np.asarray(labels), test_size=0.2, random_state=42)"],"metadata":{"id":"ebe8actROuHO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5, epsilon=1e-8)\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n","bertmodel.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n","bertmodel.fit(x=(train_inputs, train_masks), y=train_labels, batch_size=32, epochs=3, validation_data=((test_inputs, test_masks), test_labels))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TH-7z9uePgAv","executionInfo":{"status":"ok","timestamp":1681554359579,"user_tz":-330,"elapsed":1611483,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"888eff91-56a5-4d9c-97f2-164a0a9b833a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","1193/1193 [==============================] - 582s 442ms/step - loss: 0.2637 - accuracy: 0.8731 - val_loss: 0.2335 - val_accuracy: 0.8889\n","Epoch 2/3\n","1193/1193 [==============================] - 509s 427ms/step - loss: 0.2032 - accuracy: 0.9039 - val_loss: 0.2307 - val_accuracy: 0.8939\n","Epoch 3/3\n","1193/1193 [==============================] - 508s 426ms/step - loss: 0.1594 - accuracy: 0.9282 - val_loss: 0.2644 - val_accuracy: 0.8844\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f3584195790>"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["pred_labels = bertmodel.predict(x=(test_inputs, test_masks))\n","pred_labels = tf.argmax(pred_labels.logits, axis=1).numpy()\n","accuracy = accuracy_score(test_labels, pred_labels)\n","precision = precision_score(test_labels, pred_labels)\n","recall = recall_score(test_labels, pred_labels)\n","f1 = f1_score(test_labels, pred_labels)\n","print('Accuracy:', accuracy)\n","print('Precision:', precision)\n","print('Recall:', recall)\n","print('F1-score:', f1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OjDJRjsUSJRM","executionInfo":{"status":"ok","timestamp":1681554598717,"user_tz":-330,"elapsed":51311,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"316dac61-02c6-4b53-9ac1-637e2f667ee1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["299/299 [==============================] - 51s 143ms/step\n","Accuracy: 0.884369430757941\n","Precision: 0.9080996884735203\n","Recall: 0.9575489576753\n","F1-score: 0.9321689932968452\n"]}]},{"cell_type":"code","source":["#multiclass classification\n"],"metadata":{"id":"8lcplUirdewJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["multibertdata = bertdata.copy()\n","multibertdata['cyberbullying_type'] = multibertdata['cyberbullying_type'].replace({'not_cyberbullying':0,'gender':1,'religion':2,'age':3,'ethnicity':4,'other_cyberbullying':5})\n","multibertdata.head(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"id":"aR6pB07AeWCQ","executionInfo":{"status":"ok","timestamp":1683542142691,"user_tz":-330,"elapsed":20,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"de548a0b-de60-45d1-9134-f987dc1acc46"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                          tweet_text  cyberbullying_type\n","0  In other words #katandandre, your food was cra...                   0\n","1  Why is #aussietv so white? #MKR #theblock #ImA...                   0"],"text/html":["\n","  <div id=\"df-d7301bc0-8091-425c-a433-97002b5afc79\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet_text</th>\n","      <th>cyberbullying_type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>In other words #katandandre, your food was cra...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7301bc0-8091-425c-a433-97002b5afc79')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d7301bc0-8091-425c-a433-97002b5afc79 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d7301bc0-8091-425c-a433-97002b5afc79');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["input_ids_multi = []\n","attention_masks_multi = []\n","for tweet in multibertdata['tweet_text']:\n","    encoded_dict = tokenizer.encode_plus(\n","                        tweet,\n","                        add_special_tokens = True,\n","                        max_length = 128,\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,\n","                        return_tensors = 'tf'\n","                   )\n","    input_ids_multi.append(encoded_dict['input_ids'])\n","    attention_masks_multi.append(encoded_dict['attention_mask'])\n","input_ids_multi = tf.concat(input_ids_multi, axis=0)\n","attention_masks_multi = tf.concat(attention_masks_multi, axis=0)"],"metadata":{"id":"rs7RHleiewqA","executionInfo":{"status":"ok","timestamp":1683542234047,"user_tz":-330,"elapsed":91373,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4f43dbb3-79cc-47e7-a209-1157851520e7"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]}]},{"cell_type":"code","source":["print(input_ids_multi.shape)\n","print(attention_masks_multi.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_4SaBBT0fEk_","executionInfo":{"status":"ok","timestamp":1683542234047,"user_tz":-330,"elapsed":27,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"9d4abf1a-e9c8-4c86-a9b9-c2e814821d78"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["(47692, 128)\n","(47692, 128)\n"]}]},{"cell_type":"code","source":["train_input_ids, test_input_ids, train_attention_masks, test_attention_masks, train_labels, test_labels = train_test_split(np.asarray(input_ids_multi), np.asarray(attention_masks_multi), multibertdata['cyberbullying_type'], test_size=0.2, random_state=42)"],"metadata":{"id":"iIuq6atMfhSn","executionInfo":{"status":"ok","timestamp":1683542234048,"user_tz":-330,"elapsed":6,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["multi_bert_model = TFBertModel.from_pretrained('bert-base-uncased', output_hidden_states=False, output_attentions=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VYZ-b_2Lf4df","executionInfo":{"status":"ok","timestamp":1683542234780,"user_tz":-330,"elapsed":737,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"1413ee18-9e09-4591-c873-d6b99f7e7f6a"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]}]},{"cell_type":"code","source":["input_ids_multi = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name=\"input_ids\")\n","attention_masks_multi = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name=\"attention_masks\")\n","bert_output = multi_bert_model([input_ids_multi, attention_masks_multi])[1]\n","dense_layer_1 = tf.keras.layers.Dense(256, activation='relu')(bert_output)\n","dropout_layer = tf.keras.layers.Dropout(0.1)(dense_layer_1)\n","output_layer = tf.keras.layers.Dense(6, activation='softmax')(dropout_layer)\n","multimodel = tf.keras.models.Model(inputs=[input_ids_multi, attention_masks_multi], outputs=output_layer)"],"metadata":{"id":"ar1pEo3sgPxW","executionInfo":{"status":"ok","timestamp":1683542241302,"user_tz":-330,"elapsed":5359,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["optimizer = tf.keras.optimizers.legacy.Adam(lr=2e-5, epsilon=1e-08, decay=0.01)\n","multimodel.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n"],"metadata":{"id":"lGNlXcLOgpon"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = multimodel.fit(\n","            [train_input_ids, train_attention_masks],\n","            train_labels,\n","            epochs=3,\n","            batch_size=32,\n","            validation_split=0.1\n","         )\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AxNXMrWDgum_","outputId":"73987a0b-e229-422b-c4f4-2c791566f039","executionInfo":{"status":"ok","timestamp":1681585556134,"user_tz":-330,"elapsed":2569564,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","1074/1074 [==============================] - 866s 787ms/step - loss: 0.5191 - accuracy: 0.7947 - val_loss: 0.3882 - val_accuracy: 0.8433\n","Epoch 2/3\n","1074/1074 [==============================] - 852s 793ms/step - loss: 0.3777 - accuracy: 0.8493 - val_loss: 0.3711 - val_accuracy: 0.8485\n","Epoch 3/3\n","1074/1074 [==============================] - 852s 793ms/step - loss: 0.3560 - accuracy: 0.8595 - val_loss: 0.3609 - val_accuracy: 0.8530\n"]}]},{"cell_type":"code","source":["test_loss, test_acc = multimodel.evaluate([test_input_ids, test_attention_masks], test_labels)\n","print('Test accuracy:', test_acc)"],"metadata":{"id":"hR-7Xdn4g8uy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681586019910,"user_tz":-330,"elapsed":82931,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"5797cf7b-5f50-4e29-bf2c-92c590ad5d95"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["299/299 [==============================] - 80s 269ms/step - loss: 0.3738 - accuracy: 0.8527\n","Test accuracy: 0.852709949016571\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/Minor Project(NLP)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n8PF-uXkFwDk","executionInfo":{"status":"ok","timestamp":1683542241302,"user_tz":-330,"elapsed":10,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}},"outputId":"80225739-11d4-4af2-b94f-5985e0c8a3f1"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Minor Project(NLP)\n"]}]},{"cell_type":"code","source":["#fine-tuning BERT model\n","learning_rate = [2e-5,3e-5,5e-5]\n","batches=[16,32]\n","epochs = [2,3,4]\n","for i in epochs:\n","  for j in batches:\n","      optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5, epsilon=1e-8)\n","      loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","      metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n","      bertmodel.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n","      bertmodel.fit(x=(train_inputs, train_masks), y=train_labels, batch_size=j, epochs=i, validation_data=((test_inputs, test_masks), test_labels))\n","      pred_labels = bertmodel.predict(x=(test_inputs, test_masks))\n","      pred_labels = tf.argmax(pred_labels.logits, axis=1).numpy()\n","      accuracy = accuracy_score(test_labels, pred_labels)\n","      precision = precision_score(test_labels, pred_labels)\n","      recall = recall_score(test_labels, pred_labels)\n","      f1 = f1_score(test_labels, pred_labels)\n","      print('---For Epoch ',i,'Batch_size',j,'---')\n","      print('Accuracy:', accuracy)\n","      print('Precision:', precision)\n","      print('Recall:', recall)\n","      print('F1-score:', f1)\n","      mdict = {'Learning_Rate':[2e-5],'Epoch':[i],'Batch-Size':[j],'Accuracy':[accuracy],'Precision' :[precision],'Recall':[recall],'F1-score':[f1]}\n","      mdictpd = pd.DataFrame(mdict)\n","      mdictpd.to_csv('Tuning.csv',mode='a',index='False',header='False')\n","      print('Appended to csv file')"],"metadata":{"id":"A6Rese-kjllk","colab":{"base_uri":"https://localhost:8080/"},"outputId":"470c363a-6ec6-4381-88f4-5f3cab10f89f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","2385/2385 [==============================] - 672s 258ms/step - loss: 0.1553 - accuracy: 0.9329 - val_loss: 0.2741 - val_accuracy: 0.8913\n","Epoch 2/2\n","2385/2385 [==============================] - 596s 250ms/step - loss: 0.1199 - accuracy: 0.9471 - val_loss: 0.3249 - val_accuracy: 0.8842\n","299/299 [==============================] - 47s 145ms/step\n","---For Epoch  2 Batch_size 16 ---\n","Accuracy: 0.8841597651745466\n","Precision: 0.8979663394109397\n","Recall: 0.9706885660138976\n","F1-score: 0.9329123914759273\n","Appended to csv file\n","Epoch 1/2\n","1193/1193 [==============================] - 596s 461ms/step - loss: 0.0906 - accuracy: 0.9587 - val_loss: 0.3786 - val_accuracy: 0.8786\n","Epoch 2/2\n","1193/1193 [==============================] - 575s 482ms/step - loss: 0.0742 - accuracy: 0.9624 - val_loss: 0.4541 - val_accuracy: 0.8703\n","299/299 [==============================] - 46s 146ms/step\n","---For Epoch  2 Batch_size 32 ---\n","Accuracy: 0.8703218366705106\n","Precision: 0.897594665396523\n","Recall: 0.9523689197725838\n","F1-score: 0.924170906638877\n","Appended to csv file\n","Epoch 1/3\n","2385/2385 [==============================] - 692s 271ms/step - loss: 0.0722 - accuracy: 0.9635 - val_loss: 0.4430 - val_accuracy: 0.8658\n","Epoch 2/3\n","2385/2385 [==============================] - 631s 265ms/step - loss: 0.0664 - accuracy: 0.9651 - val_loss: 0.5173 - val_accuracy: 0.8618\n","Epoch 3/3\n","2385/2385 [==============================] - 631s 265ms/step - loss: 0.0632 - accuracy: 0.9650 - val_loss: 0.5551 - val_accuracy: 0.8587\n","299/299 [==============================] - 47s 147ms/step\n","---For Epoch  3 Batch_size 16 ---\n","Accuracy: 0.8586853967921165\n","Precision: 0.914426353653919\n","Recall: 0.9153506001263424\n","F1-score: 0.9148882434650841\n","Appended to csv file\n","Epoch 1/3\n","1193/1193 [==============================] - 626s 486ms/step - loss: 0.0542 - accuracy: 0.9693 - val_loss: 0.6147 - val_accuracy: 0.8746\n","Epoch 2/3\n","1193/1193 [==============================] - 574s 481ms/step - loss: 0.0496 - accuracy: 0.9699 - val_loss: 0.7638 - val_accuracy: 0.8668\n","Epoch 3/3\n","1193/1193 [==============================] - 568s 476ms/step - loss: 0.0467 - accuracy: 0.9701 - val_loss: 0.8127 - val_accuracy: 0.8671\n","299/299 [==============================] - 45s 139ms/step\n","---For Epoch  3 Batch_size 32 ---\n","Accuracy: 0.867072020127896\n","Precision: 0.9095502156500308\n","Recall: 0.9325331648768161\n","F1-score: 0.920898315658141\n","Appended to csv file\n","Epoch 1/4\n","2385/2385 [==============================] - 689s 268ms/step - loss: 0.0513 - accuracy: 0.9696 - val_loss: 0.5974 - val_accuracy: 0.8575\n","Epoch 2/4\n","2385/2385 [==============================] - 628s 263ms/step - loss: 0.0511 - accuracy: 0.9694 - val_loss: 0.7008 - val_accuracy: 0.8680\n","Epoch 3/4\n","2385/2385 [==============================] - 592s 248ms/step - loss: 0.0503 - accuracy: 0.9700 - val_loss: 0.6341 - val_accuracy: 0.8631\n","Epoch 4/4\n","2385/2385 [==============================] - 631s 264ms/step - loss: 0.0497 - accuracy: 0.9711 - val_loss: 0.6180 - val_accuracy: 0.8714\n","299/299 [==============================] - 44s 140ms/step\n","---For Epoch  4 Batch_size 16 ---\n","Accuracy: 0.871370164587483\n","Precision: 0.9112149532710281\n","Recall: 0.936197094125079\n","F1-score: 0.9235371097401384\n","Appended to csv file\n","Epoch 1/4\n","1193/1193 [==============================] - 581s 447ms/step - loss: 0.0473 - accuracy: 0.9705 - val_loss: 0.7305 - val_accuracy: 0.8537\n","Epoch 2/4\n","1193/1193 [==============================] - 574s 481ms/step - loss: 0.0438 - accuracy: 0.9725 - val_loss: 0.8235 - val_accuracy: 0.8549\n","Epoch 3/4\n","1193/1193 [==============================] - 571s 478ms/step - loss: 0.0426 - accuracy: 0.9727 - val_loss: 0.7989 - val_accuracy: 0.8642\n","Epoch 4/4\n","1193/1193 [==============================] - 568s 476ms/step - loss: 0.0418 - accuracy: 0.9727 - val_loss: 0.8634 - val_accuracy: 0.8614\n","299/299 [==============================] - 46s 139ms/step\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n","ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n","ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"output_type":"stream","name":"stdout","text":["---For Epoch  4 Batch_size 32 ---\n","Accuracy: 0.8614110493762449\n","Precision: 0.917860311826594\n","Recall: 0.9148452305748579\n","F1-score: 0.916350291065553\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-31-bc8e6b850b85>\", line 25, in <cell line: 5>\n","    mdictpd.to_csv('Tuning.csv',mode='a',index='False',header='False')\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\", line 211, in wrapper\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\", line 3720, in to_csv\n","    return DataFrameRenderer(formatter).to_csv(\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\", line 211, in wrapper\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\", line 1189, in to_csv\n","    csv_formatter.save()\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\", line 241, in save\n","    with get_handle(\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\", line 734, in get_handle\n","    check_parent_directory(str(handle))\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\", line 596, in check_parent_directory\n","    if not parent.is_dir():\n","  File \"/usr/lib/python3.10/pathlib.py\", line 1305, in is_dir\n","    return S_ISDIR(self.stat().st_mode)\n","  File \"/usr/lib/python3.10/pathlib.py\", line 1097, in stat\n","    return self._accessor.stat(self, follow_symlinks=follow_symlinks)\n","OSError: [Errno 107] Transport endpoint is not connected: '.'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'OSError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-31-bc8e6b850b85>\", line 25, in <cell line: 5>\n","    mdictpd.to_csv('Tuning.csv',mode='a',index='False',header='False')\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\", line 211, in wrapper\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\", line 3720, in to_csv\n","    return DataFrameRenderer(formatter).to_csv(\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\", line 211, in wrapper\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\", line 1189, in to_csv\n","    csv_formatter.save()\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\", line 241, in save\n","    with get_handle(\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\", line 734, in get_handle\n","    check_parent_directory(str(handle))\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\", line 596, in check_parent_directory\n","    if not parent.is_dir():\n","  File \"/usr/lib/python3.10/pathlib.py\", line 1305, in is_dir\n","    return S_ISDIR(self.stat().st_mode)\n","  File \"/usr/lib/python3.10/pathlib.py\", line 1097, in stat\n","    return self._accessor.stat(self, follow_symlinks=follow_symlinks)\n","OSError: [Errno 107] Transport endpoint is not connected: '.'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'OSError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n","    self.showtraceback(running_compiled_code=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-31-bc8e6b850b85>\", line 25, in <cell line: 5>\n","    mdictpd.to_csv('Tuning.csv',mode='a',index='False',header='False')\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\", line 211, in wrapper\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\", line 3720, in to_csv\n","    return DataFrameRenderer(formatter).to_csv(\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\", line 211, in wrapper\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\", line 1189, in to_csv\n","    csv_formatter.save()\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\", line 241, in save\n","    with get_handle(\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\", line 734, in get_handle\n","    check_parent_directory(str(handle))\n","  File \"/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\", line 596, in check_parent_directory\n","    if not parent.is_dir():\n","  File \"/usr/lib/python3.10/pathlib.py\", line 1305, in is_dir\n","    return S_ISDIR(self.stat().st_mode)\n","  File \"/usr/lib/python3.10/pathlib.py\", line 1097, in stat\n","    return self._accessor.stat(self, follow_symlinks=follow_symlinks)\n","OSError: [Errno 107] Transport endpoint is not connected: '.'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'OSError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n","    self.showtraceback(running_compiled_code=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n","    self.showtraceback()\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n","    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"BeuWZko5Q6an"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mdict = {'Learning_Rate':[2e-5],'Epoch':[0],'Batch-Size':[0],'Accuracy':[1]}\n","mdictpd = pd.DataFrame(mdict)\n","mdictpd.to_csv('multiTuning.csv')"],"metadata":{"id":"mw_o45qHFSD7","executionInfo":{"status":"ok","timestamp":1683533201929,"user_tz":-330,"elapsed":5,"user":{"displayName":"ABBARAJU SRINIVAS ADITYA","userId":"04079134027221790822"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["batches=[16,32]\n","epochs = [2,3,4]\n","for i in epochs:\n","  for j in batches:\n","      if i==2 and j==16 : pass\n","      optimizer = tf.keras.optimizers.legacy.Adam(lr=2e-5, epsilon=1e-08, decay=0.01)\n","      multimodel.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","      history = multimodel.fit(\n","            [train_input_ids, train_attention_masks],\n","            train_labels,\n","            epochs=i,\n","            batch_size=j,\n","            validation_split=0.1\n","         )\n","      test_loss, test_acc = multimodel.evaluate([test_input_ids, test_attention_masks], test_labels)\n","      print('Test accuracy for epoch',i,'batch size',j,'is', test_acc)\n","      mdict = {'Learning_Rate':[2e-5],'Epoch':[i],'Batch-Size':[j],'Accuracy':[test_acc]}\n","      mdictpd = pd.DataFrame(mdict)\n","      mdictpd.to_csv('multiTuning.csv',mode='a',index='False',header='False')\n","      print('Appended to csv file')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MB5J4wG1FQ0r","outputId":"ab213d36-277f-4639-bc51-deb492b653a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","2147/2147 [==============================] - 939s 429ms/step - loss: 0.5200 - accuracy: 0.7927 - val_loss: 0.4121 - val_accuracy: 0.8336\n","Epoch 2/2\n","2147/2147 [==============================] - 917s 427ms/step - loss: 0.3985 - accuracy: 0.8399 - val_loss: 0.3973 - val_accuracy: 0.8404\n","299/299 [==============================] - 83s 277ms/step - loss: 0.4050 - accuracy: 0.8422\n","Test accuracy for epoch 2 batch size 16 is 0.8422266244888306\n","Appended to csv file\n","Epoch 1/2\n","1074/1074 [==============================] - 908s 829ms/step - loss: 0.3712 - accuracy: 0.8505 - val_loss: 0.3588 - val_accuracy: 0.8559\n","Epoch 2/2\n","1074/1074 [==============================] - 887s 826ms/step - loss: 0.3240 - accuracy: 0.8717 - val_loss: 0.3489 - val_accuracy: 0.8624\n","299/299 [==============================] - 84s 280ms/step - loss: 0.3651 - accuracy: 0.8572\n","Test accuracy for epoch 2 batch size 32 is 0.8572177290916443\n","Appended to csv file\n","Epoch 1/3\n","2147/2147 [==============================] - 944s 432ms/step - loss: 0.3181 - accuracy: 0.8731 - val_loss: 0.3351 - val_accuracy: 0.8632\n","Epoch 2/3\n","2147/2147 [==============================] - 922s 430ms/step - loss: 0.2805 - accuracy: 0.8898 - val_loss: 0.3375 - val_accuracy: 0.8653\n","Epoch 3/3\n","2147/2147 [==============================] - 922s 429ms/step - loss: 0.2717 - accuracy: 0.8942 - val_loss: 0.3401 - val_accuracy: 0.8677\n","299/299 [==============================] - 84s 281ms/step - loss: 0.3623 - accuracy: 0.8580\n","Test accuracy for epoch 3 batch size 16 is 0.8579515814781189\n","Appended to csv file\n","Epoch 1/3\n","1074/1074 [==============================] - 906s 828ms/step - loss: 0.2814 - accuracy: 0.8885 - val_loss: 0.3301 - val_accuracy: 0.8726\n","Epoch 2/3\n","1074/1074 [==============================] - 886s 825ms/step - loss: 0.2388 - accuracy: 0.9061 - val_loss: 0.3419 - val_accuracy: 0.8721\n","Epoch 3/3\n","1074/1074 [==============================] - 886s 825ms/step - loss: 0.2274 - accuracy: 0.9122 - val_loss: 0.3448 - val_accuracy: 0.8695\n","299/299 [==============================] - 84s 280ms/step - loss: 0.3657 - accuracy: 0.8595\n","Test accuracy for epoch 3 batch size 32 is 0.8595240712165833\n","Appended to csv file\n","Epoch 1/4\n","2147/2147 [==============================] - 938s 429ms/step - loss: 0.2406 - accuracy: 0.9039 - val_loss: 0.3504 - val_accuracy: 0.8700\n","Epoch 2/4\n","2147/2147 [==============================] - 925s 431ms/step - loss: 0.2043 - accuracy: 0.9205 - val_loss: 0.3622 - val_accuracy: 0.8653\n","Epoch 3/4\n","2147/2147 [==============================] - 917s 427ms/step - loss: 0.1958 - accuracy: 0.9236 - val_loss: 0.3630 - val_accuracy: 0.8664\n","Epoch 4/4\n","1298/2147 [=================>............] - ETA: 5:48 - loss: 0.1880 - accuracy: 0.9272"]}]},{"cell_type":"code","source":["batches=[16,32]\n","epochs = [4]\n","for i in epochs:\n","  for j in batches:\n","      optimizer = tf.keras.optimizers.legacy.Adam(lr=2e-5, epsilon=1e-08, decay=0.01)\n","      multimodel.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","      history = multimodel.fit(\n","            [train_input_ids, train_attention_masks],\n","            train_labels,\n","            epochs=i,\n","            batch_size=j,\n","            validation_split=0.1\n","         )\n","      test_loss, test_acc = multimodel.evaluate([test_input_ids, test_attention_masks], test_labels)\n","      print('Test accuracy for epoch',i,'batch size',j,'is', test_acc)\n","      mdict = {'Learning_Rate':[2e-5],'Epoch':[i],'Batch-Size':[j],'Accuracy':[test_acc]}\n","      mdictpd = pd.DataFrame(mdict)\n","      mdictpd.to_csv('multiTuning.csv',mode='a',index='False',header='False')\n","      print('Appended to csv file')"],"metadata":{"id":"9z-hp6tXGdUZ"},"execution_count":null,"outputs":[]}]}